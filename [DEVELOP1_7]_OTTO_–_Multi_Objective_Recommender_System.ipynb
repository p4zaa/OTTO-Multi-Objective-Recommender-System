{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p4zaa/OTTO-Multi-Objective-Recommender-System/blob/main/%5BDEVELOP1_7%5D_OTTO_%E2%80%93_Multi_Objective_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf2nIQqrAy8y"
      },
      "source": [
        "# Version Logs\n",
        "* [View in my Github](https://github.com/p4zaa/OTTO-Multi-Objective-Recommender-System)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTgGyHWwP0wa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGBdYwXz-B9e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "import tqdm\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#import plotly.io as pio\n",
        "#import plotly.express as px\n",
        "#import plotly.graph_objects as go\n",
        "#from plotly.subplots import make_subplots\n",
        "#pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.loader import HGTLoader, NeighborLoader, LinkNeighborLoader\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97P3ABJvXkB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "166e2d1e-e8aa-4b79-cda5-ffc66243b38b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: polars in /usr/local/lib/python3.8/dist-packages (0.15.14)\n",
            "Requirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from polars) (4.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -q torch torchvision torchaudio\n",
        "!pip install -U polars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17ePRXhpuuFE"
      },
      "outputs": [],
      "source": [
        "import polars as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B0nqQodKXs7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29bf578c-6711-45c3-f3de-71b10f4264bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch CUDA Version is  11.6\n"
          ]
        }
      ],
      "source": [
        "print('Pytorch CUDA Version is ', torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwEe6Wxor7uB"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76_LytnFg0vB",
        "outputId": "80cee6e1-a5ba-4be8-e874-225434b23a00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun Jan  8 15:06:26 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   35C    P8     9W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY_7dPR8g30J",
        "outputId": "74044469-4686-4317-fd4c-3b9ad944da1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xlaViVcbYSGa"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5eLnmtjpYCtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a808121-6303-4afc-e151-b0bbb2294c4f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa5S-Yu9b4OL"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j7Gsb6xQ98eL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 475
        },
        "outputId": "e75402f0-f9df-4d5d-98f2-66878d15aee9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c629cf51-2669-4613-995a-445377f0709b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c629cf51-2669-4613-995a-445377f0709b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "ref                                                           title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                     COVID-19 Dataset                                     5MB  2022-11-13 15:47:17          16674        470  1.0              \n",
            "devrimtuner/list-of-moststreamed-songs-on-spotify             Top 100 Spotify Songs👑🎤🎧🎼                            3KB  2022-12-30 05:42:54            867         43  1.0              \n",
            "thedevastator/analyzing-credit-card-spending-habits-in-india  Credit Card Spending Habits in India               319KB  2022-12-14 07:30:37           2269         68  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset            Fifa World Cup 2022: Complete Dataset                7KB  2022-12-18 22:51:11           4140        143  1.0              \n",
            "michals22/coffee-dataset                                      Coffee dataset                                      24KB  2022-12-15 20:02:12           4395         96  1.0              \n",
            "heemalichaudhari/netflix-movies-and-series                    Netflix Movies and Series                            2MB  2022-12-22 13:34:22           1465         39  0.8235294        \n",
            "sejungjenn/spotify-best-songs-of-2022                         Spotify: Winner Tracks Audio Features🎹              38KB  2022-12-28 08:06:49            356         26  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data       E-Commerce Sales Dataset                             6MB  2022-12-03 09:27:17           3708         84  1.0              \n",
            "aklimarimi/qs-world-ranked-universities-20182022              QS World ranked Universities (2018-2022)            51KB  2022-12-28 03:53:39            820         40  1.0              \n",
            "rajeshrampure/black-friday-sale                               Black Friday Sale                                    5MB  2022-12-24 09:37:49           1226         35  1.0              \n",
            "devrimtuner/highestpaid-athletes                              HIGHEST-PAID ATHLETES⚽️🏀🏈⚾️🥎🎾                        1KB  2022-12-29 01:29:51            348         29  1.0              \n",
            "heemalichaudhari/shopping                                     Shopping                                            12KB  2022-12-26 14:25:07            567         29  0.9411765        \n",
            "milanvaddoriya/old-car-price-prediction                       Old car price prediction                           105KB  2022-12-24 15:38:56            619         32  1.0              \n",
            "thedevastator/how-does-daily-yoga-impact-screen-time-habits   How Does Daily Yoga Impact Screen Time Habits       742B  2022-12-14 04:10:56            922         30  1.0              \n",
            "thedevastator/uncovering-factors-that-affect-used-car-prices  Used Cars                                           18MB  2022-12-06 13:36:08           1380         45  1.0              \n",
            "devrimtuner/list-of-mostfollowed-instagram-accounts           (TOP 50)List of most-followed Instagram accounts👑    2KB  2022-12-30 07:52:00            400         28  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                     Salary Prediction                                    3MB  2022-11-16 13:52:31           8790        188  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                         Melbourne Housing Snapshot                         451KB  2018-06-05 12:52:24         103693       1193  0.7058824        \n",
            "mattop/best-selling-game-boy-video-games                      Best Selling Game Boy Video Games                    2KB  2022-12-17 18:41:38            424         27  0.9705882        \n",
            "rajeshrampure/zomato-dataset                                  Zomato Dataset                                      89MB  2022-12-23 07:38:07            764         28  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "421Djk4r4qJy"
      },
      "outputs": [],
      "source": [
        "#!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download 'radek1/otto-train-and-test-data-for-local-validation' -p /content/drive/MyDrive/OTTO-Kaggle-Competition/for-local-validation/ --unzip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HGZUTRH07O5c",
        "outputId": "2ee74e69-26f0-4c7a-f276-c85912dea713"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading otto-train-and-test-data-for-local-validation.zip to /content/drive/MyDrive/OTTO-Kaggle-Competition/for-local-validation\n",
            "100% 870M/873M [00:29<00:00, 30.8MB/s]\n",
            "100% 873M/873M [00:29<00:00, 30.7MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "# Pandas\n",
        "#df = pd.read_parquet('/content/kaggle/train.parquet')\n",
        "\n",
        "# Polars\n",
        "#df = pl.read_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/dataset/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "#df = df.sample(frac=0.01, replace=False)\n",
        "\n",
        "# Polars\n",
        "#df = df.sample(frac=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save 1% dataset\n",
        "#df.write_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/train_frac0.01.parquet')\n",
        "\n",
        "# Load\n",
        "df = pl.read_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/train_frac0.01.parquet')"
      ],
      "metadata": {
        "id": "MUnGtCTd-QoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Q_j2wx7Omc"
      },
      "outputs": [],
      "source": [
        "df = df.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df[df['aid'] == 1517085]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "yLpk5Wg-lj1R",
        "outputId": "2fd7fcf3-8b15-41fa-944d-340bce5457e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            session      aid          ts  type\n",
              "0                 0  1517085  1659304800     0\n",
              "1163104       20742  1517085  1661296618     0\n",
              "1463549       26711  1517085  1659476277     0\n",
              "4541895       87489  1517085  1659903158     0\n",
              "5599839      106776  1517085  1659619933     0\n",
              "...             ...      ...         ...   ...\n",
              "205881619  11593549  1517085  1661277446     0\n",
              "207800194  11814714  1517085  1661353845     0\n",
              "207800195  11814714  1517085  1661353871     0\n",
              "213058448  12445488  1517085  1661593777     0\n",
              "213099237  12450196  1517085  1661594931     0\n",
              "\n",
              "[121 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c7d27bb1-a057-4bb9-99ac-71651dc50844\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1659304800</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1163104</th>\n",
              "      <td>20742</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1661296618</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1463549</th>\n",
              "      <td>26711</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1659476277</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4541895</th>\n",
              "      <td>87489</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1659903158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5599839</th>\n",
              "      <td>106776</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1659619933</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205881619</th>\n",
              "      <td>11593549</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1661277446</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207800194</th>\n",
              "      <td>11814714</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1661353845</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207800195</th>\n",
              "      <td>11814714</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1661353871</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213058448</th>\n",
              "      <td>12445488</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1661593777</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213099237</th>\n",
              "      <td>12450196</td>\n",
              "      <td>1517085</td>\n",
              "      <td>1661594931</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>121 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c7d27bb1-a057-4bb9-99ac-71651dc50844')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c7d27bb1-a057-4bb9-99ac-71651dc50844 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c7d27bb1-a057-4bb9-99ac-71651dc50844');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdB8Tum90sZX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "b4b7b9a8-816e-4cb6-d53e-48ba6b788211"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (216716096, 4)\n",
              "┌──────────┬─────────┬────────────┬──────┐\n",
              "│ session  ┆ aid     ┆ ts         ┆ type │\n",
              "│ ---      ┆ ---     ┆ ---        ┆ ---  │\n",
              "│ i32      ┆ i32     ┆ i32        ┆ u8   │\n",
              "╞══════════╪═════════╪════════════╪══════╡\n",
              "│ 0        ┆ 1517085 ┆ 1659304800 ┆ 0    │\n",
              "│ 0        ┆ 1563459 ┆ 1659304904 ┆ 0    │\n",
              "│ 0        ┆ 1309446 ┆ 1659367439 ┆ 0    │\n",
              "│ 0        ┆ 16246   ┆ 1659367719 ┆ 0    │\n",
              "│ ...      ┆ ...     ┆ ...        ┆ ...  │\n",
              "│ 12899777 ┆ 384045  ┆ 1661723976 ┆ 0    │\n",
              "│ 12899777 ┆ 384045  ┆ 1661723986 ┆ 0    │\n",
              "│ 12899778 ┆ 561560  ┆ 1661723983 ┆ 0    │\n",
              "│ 12899778 ┆ 32070   ┆ 1661723994 ┆ 0    │\n",
              "└──────────┴─────────┴────────────┴──────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        white-space: pre;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-top: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-bottom: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        line-height: 95%;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "<small>shape: (216716096, 4)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "session\n",
              "</th>\n",
              "<th>\n",
              "aid\n",
              "</th>\n",
              "<th>\n",
              "ts\n",
              "</th>\n",
              "<th>\n",
              "type\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "i32\n",
              "</td>\n",
              "<td>\n",
              "i32\n",
              "</td>\n",
              "<td>\n",
              "i32\n",
              "</td>\n",
              "<td>\n",
              "u8\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "1517085\n",
              "</td>\n",
              "<td>\n",
              "1659304800\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "1563459\n",
              "</td>\n",
              "<td>\n",
              "1659304904\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "1309446\n",
              "</td>\n",
              "<td>\n",
              "1659367439\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "16246\n",
              "</td>\n",
              "<td>\n",
              "1659367719\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "1781822\n",
              "</td>\n",
              "<td>\n",
              "1659367871\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "1152674\n",
              "</td>\n",
              "<td>\n",
              "1659367885\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "1649869\n",
              "</td>\n",
              "<td>\n",
              "1659369893\n",
              "</td>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "461689\n",
              "</td>\n",
              "<td>\n",
              "1659369898\n",
              "</td>\n",
              "<td>\n",
              "1\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "305831\n",
              "</td>\n",
              "<td>\n",
              "1659370027\n",
              "</td>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "461689\n",
              "</td>\n",
              "<td>\n",
              "1659370027\n",
              "</td>\n",
              "<td>\n",
              "2\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "362233\n",
              "</td>\n",
              "<td>\n",
              "1659370064\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "<td>\n",
              "1649869\n",
              "</td>\n",
              "<td>\n",
              "1659370067\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899773\n",
              "</td>\n",
              "<td>\n",
              "1311526\n",
              "</td>\n",
              "<td>\n",
              "1661723966\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899773\n",
              "</td>\n",
              "<td>\n",
              "238164\n",
              "</td>\n",
              "<td>\n",
              "1661723977\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899774\n",
              "</td>\n",
              "<td>\n",
              "33035\n",
              "</td>\n",
              "<td>\n",
              "1661723968\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899774\n",
              "</td>\n",
              "<td>\n",
              "1399483\n",
              "</td>\n",
              "<td>\n",
              "1661723976\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899775\n",
              "</td>\n",
              "<td>\n",
              "1743151\n",
              "</td>\n",
              "<td>\n",
              "1661723970\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899775\n",
              "</td>\n",
              "<td>\n",
              "1760714\n",
              "</td>\n",
              "<td>\n",
              "1661723990\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899776\n",
              "</td>\n",
              "<td>\n",
              "548599\n",
              "</td>\n",
              "<td>\n",
              "1661723972\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899776\n",
              "</td>\n",
              "<td>\n",
              "1737908\n",
              "</td>\n",
              "<td>\n",
              "1661723987\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899777\n",
              "</td>\n",
              "<td>\n",
              "384045\n",
              "</td>\n",
              "<td>\n",
              "1661723976\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899777\n",
              "</td>\n",
              "<td>\n",
              "384045\n",
              "</td>\n",
              "<td>\n",
              "1661723986\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899778\n",
              "</td>\n",
              "<td>\n",
              "561560\n",
              "</td>\n",
              "<td>\n",
              "1661723983\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899778\n",
              "</td>\n",
              "<td>\n",
              "32070\n",
              "</td>\n",
              "<td>\n",
              "1661723994\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6SK6ahjEpy9"
      },
      "outputs": [],
      "source": [
        "#df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h8hFppsb5cAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de4ce7bf-bad7-4cc2-d033-5ec0624bd933"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFhgeI-OgFEz"
      },
      "outputs": [],
      "source": [
        "#df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERcykcKRz4Ri"
      },
      "outputs": [],
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "\n",
        "# Load data (deserialize)\n",
        "#with open('/content/drive/MyDrive/OTTO-Kaggle-Competition/source_idx.pkl', 'rb') as file:\n",
        "#    source_idx = pickle.load(file)\n",
        "\n",
        "#with open('/content/drive/MyDrive/OTTO-Kaggle-Competition/target_idx.pkl', 'rb') as file:\n",
        "#    target_idx = pickle.load(file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QvTKqD08lNFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d54c9de-8561-4a35-a7d7-205eeb99e1cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-fdbbf2e7eb54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['session'] = connected['session'].map(source_idx)\n",
            "<ipython-input-25-fdbbf2e7eb54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['aid'] = connected['aid'].map(target_idx)\n"
          ]
        }
      ],
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4L_GWK4hlTWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8bc247f-a3eb-43bc-8f87-fd94f4e4f89c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-23961f25841f>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  edge_index = torch.tensor((source.values, target.values))\n"
          ]
        }
      ],
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del connected\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usXDAgHejMUN",
        "outputId": "f0a46004-5d35-46de-b703-8188a81ee7ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "274"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nl_tLvXkFVmG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e6c73ba-b1f0-47c8-beb5-b52b426935de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          9841405\n",
              "1           748820\n",
              "2          2910988\n",
              "3          6064205\n",
              "4          8863318\n",
              "            ...   \n",
              "2167155     398294\n",
              "2167156     913121\n",
              "2167157      97582\n",
              "2167158    4336715\n",
              "2167159    5517556\n",
              "Name: session, Length: 2167160, dtype: int32"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "df['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "session_id = torch.tensor(list(source_idx.values()), dtype=torch.int64)\n",
        "\n",
        "aid_features = torch.rand((aid_num_nodes, 32)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "aid_id = torch.tensor(list(target_idx.values()), dtype=torch.int64)\n",
        "#aid_features = torch.nn.Embedding(aid_num_nodes, 32)\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "9kR2R3WCvpG_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "35eec889-2b5d-4f47-ca53-3b9faa436999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        #'num_nodes': session_num_nodes,\n",
        "        'node_id': session_id\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features,\n",
        "        'node_id': aid_id\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gGH8Sd8O97x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8c5c224-fe1c-4fb9-924d-fcf3cd1489f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ node_id=[1607917] },\n",
              "  \u001b[1maid\u001b[0m={\n",
              "    x=[569367, 32],\n",
              "    node_id=[569367]\n",
              "  },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 2167160],\n",
              "    edge_label=[2167160]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9F9gevNn-Ms3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c3f4fe0-3a84-4673-ba22-45d94dc62343"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del source, target, edge_index, edge_label\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiKJB1ai_H-z",
        "outputId": "7d94a5cb-c92d-4552-ffd3-637f556dc5ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TArUgtyn-OZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16324ae1-2b7a-4b75-f0f7-6240620ceb5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQNhuNgM-Tar"
      },
      "outputs": [],
      "source": [
        "#print('Isolated nodes?', data.has_isolated_nodes())\n",
        "#print('Self loops?', data.has_self_loops())\n",
        "#print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 32)\n",
        "#data['session'].x = torch.nn.Embedding(data['session'].num_nodes, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d50QCHYyKBNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c74a7ca-b0ab-42fa-d884-41ee7d3d0c1d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    node_id=[1607917],\n",
              "    x=[1607917, 32]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={\n",
              "    x=[569367, 32],\n",
              "    node_id=[569367]\n",
              "  },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 2167160],\n",
              "    edge_label=[2167160]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 2167160] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV6330E6VmlW"
      },
      "source": [
        "### Mini Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bExrskfWXv8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8efc8900-7691-4621-a743-5b7f2cf36f4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    node_id=[639],\n",
            "    x=[639, 32]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={\n",
            "    x=[411, 32],\n",
            "    node_id=[411]\n",
            "  },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 644],\n",
            "    edge_label=[128],\n",
            "    edge_label_index=[2, 128],\n",
            "    input_id=[128]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 777] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define seed edges:\n",
        "edge_label_index = train_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = train_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,  # TODO\n",
        "    num_neighbors=[5, 2],  # TODO\n",
        "    neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Inspect a sample:\n",
        "sampled_data = next(iter(train_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label_index.size(1) == 128\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.min() == 0\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.max() == 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4N6oASmHaoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fb6cb5-b8ab-4e21-8ad7-440a41497a58"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5247, 38.0419])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.ModuleList([\n",
        "            SAGEConv((-1, -1), hidden_channels),\n",
        "            SAGEConv((-1, -1), out_channels)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, edge_index)\n",
        "        return x.relu()\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(2 * hidden_channels, hidden_channels),\n",
        "            torch.nn.BatchNorm1d(hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        return self.layers(z).view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # encoder and decoder\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "        # embedding matrices for sessions and aids\n",
        "        self.aid_lin = torch.nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.session_emb = torch.nn.Embedding(data['session'].num_nodes, hidden_channels)\n",
        "        self.aid_emb = torch.nn.Embedding(data['aid'].num_nodes, hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        #x_dict = {\n",
        "        #    'session': self.session_emb(data['session'].node_id),\n",
        "        #    'aid': self.aid_lin(data['aid'].x.float()) + self.aid_emb(data['aid'].node_id)\n",
        "        #}\n",
        "        #x_dict = x_dict.copy()\n",
        "        #x_dict['session'] = self.session_emb.weight\n",
        "        #x_dict['aid'] = self.aid_emb.weight\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "id": "HShMqjU1wdBC",
        "outputId": "a72741d0-4f15-47d6-9a18-4f4baf739061"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass GNNEncoder(torch.nn.Module):\\n    def __init__(self, hidden_channels, out_channels):\\n        super().__init__()\\n        self.layers = torch.nn.ModuleList([\\n            SAGEConv((-1, -1), hidden_channels),\\n            SAGEConv((-1, -1), out_channels)\\n        ])\\n\\n    def forward(self, x, edge_index):\\n        for layer in self.layers:\\n            x = layer(x, edge_index)\\n        return x.relu()\\n\\nclass EdgeDecoder(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        self.layers = torch.nn.Sequential(\\n            torch.nn.Linear(2 * hidden_channels, hidden_channels),\\n            torch.nn.BatchNorm1d(hidden_channels),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(hidden_channels, 1)\\n        )\\n\\n    def forward(self, z_dict, edge_label_index):\\n        row, col = edge_label_index\\n        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\\n        return self.layers(z).view(-1)\\n\\nclass Model(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        # encoder and decoder\\n        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\\n        self.decoder = EdgeDecoder(hidden_channels)\\n\\n        # embedding matrices for sessions and aids\\n        self.aid_lin = torch.nn.Linear(hidden_channels, hidden_channels)\\n        self.session_emb = torch.nn.Embedding(data['session'].num_nodes, hidden_channels)\\n        self.aid_emb = torch.nn.Embedding(data['aid'].num_nodes, hidden_channels)\\n\\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\\n        #x_dict = {\\n        #    'session': self.session_emb(data['session'].node_id),\\n        #    'aid': self.aid_lin(data['aid'].x.float()) + self.aid_emb(data['aid'].node_id)\\n        #}\\n        #x_dict = x_dict.copy()\\n        #x_dict['session'] = self.session_emb.weight\\n        #x_dict['aid'] = self.aid_emb.weight\\n        z_dict = self.encoder(x_dict, edge_index_dict)\\n        return self.decoder(z_dict, edge_label_index)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # encoder and decoder\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "        # embedding matrices for sessions and aids\n",
        "        self.aid_lin = Linear(hidden_channels, hidden_channels)\n",
        "        self.session_emb = torch.nn.Embedding(data['session'].num_nodes, hidden_channels)\n",
        "        self.aid_emb = torch.nn.Embedding(data['aid'].num_nodes, hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        #x_dict = {\n",
        "        #    'session': self.session_emb(data['session'].node_id.to(device)),\n",
        "        #    'aid': self.aid_lin(data['aid'].x.to(device).float()) + self.aid_emb(data['aid'].node_id.to(device))\n",
        "        #}\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "\n",
        "    def get_embedding(self, x_dict, edge_index_dict):\n",
        "        return self.encoder(x_dict, edge_index_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZENXvG8wealJ"
      },
      "outputs": [],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "\n",
        "sampled = next(iter(train_loader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.encoder(sampled_data.to(device).x_dict, sampled_data.to(device).edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del sampled, optimizer\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsWQWHOHAFGS",
        "outputId": "5db3bcc7-78a2-41be-b7f0-8ffa7d5dce77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "215"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayGHaB6JegtI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "ab36379d-2965-487e-b477-22e501b8ef39"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train():\\n    model.train()\\n    optimizer.zero_grad()\\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\\n                 train_data['session', 'aid'].edge_label_index)\\n    target = train_data['session', 'aid'].edge_label\\n    loss = weighted_mse_loss(pred, target, weight)\\n    loss.backward()\\n    optimizer.step()\\n    return float(loss)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "'''\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RIjLW5AteiWZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "7d15adda-5644-4ad0-a28b-383984a176d3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef test(data):\\n    model.eval()\\n    pred = model(data.x_dict, data.edge_index_dict,\\n                 data['session', 'aid'].edge_label_index)\\n    pred = pred.clamp(min=-1, max=2)\\n    target = data['session', 'aid'].edge_label.float()\\n    rmse = F.mse_loss(pred, target).sqrt()\\n    return float(rmse)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=-1, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG6cTQvOi70X"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(train_data=sampled_data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data[('session', 'event', 'aid')].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight.to(device))\n",
        "    #loss = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "    # Embedding\n",
        "    emb_dict = model.get_embedding(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss), pred, model, emb_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def train(model, train_data):\n",
        "    edge_index_dict, edge_label_index, edge_label = train_data.edge_index_dict, train_data.edge_label_index, train_data.edge_label\n",
        "\n",
        "    pred = model(edge_index_dict, edge_label_index)\n",
        "    loss = F.binary_cross_entropy_with_logits(pred, edge_label.to(device).float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), pred, model\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "xJFuT04qzDBT",
        "outputId": "b94909df-e9b8-492f-d0b7-d14acceb7339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef train(model, train_data):\\n    edge_index_dict, edge_label_index, edge_label = train_data.edge_index_dict, train_data.edge_label_index, train_data.edge_label\\n\\n    pred = model(edge_index_dict, edge_label_index)\\n    loss = F.binary_cross_entropy_with_logits(pred, edge_label.to(device).float())\\n    loss.backward()\\n    optimizer.step()\\n\\n    return loss.item(), pred, model\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31EopkIapWVk"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data=data):\n",
        "    model.eval()\n",
        "    #pred = model(data.x_dict, data.edge_index_dict,\n",
        "    #             data['session', 'aid'].edge_label_index)\n",
        "    pred = model(data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse), pred, target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model=model, data=data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse), pred, target"
      ],
      "metadata": {
        "id": "9zB0PMV-fWVU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZXrZJEknJAo"
      },
      "source": [
        "### [mini-batch] Training Heterogenous Link-level GNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data = data.to(device)"
      ],
      "metadata": {
        "id": "JS_YMaNyxNAM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hbuDkO-Nh8kA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "5e04ab45-7d81-4e1f-830d-86f993a6fd47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n%%time\\nimport torch.nn.functional as F\\n\\n#device = torch.device(\\'cuda\\' if torch.cuda.is_available() else \\'cpu\\')\\nprint(f\"Device: \\'{device}\\'\")\\n\\n#model = Model(hidden_channels=32).to(device)\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\\n\\nfor epoch in range(0, 5):\\n    total_loss = total_examples = 0\\n    for sampled_data in tqdm.tqdm(train_loader):\\n        sampled_data = sampled_data.to(device)\\n        optimizer.zero_grad()\\n        loss, pred, model, emb_dict = train(train_data=sampled_data)\\n        #loss, pred, model = train(model=model, train_data=sampled_data)\\n        # TODO: Move `sampled_data` to the respective `device`\\n        # TODO: Run `forward` pass of the model\\n        # TODO: Apply binary cross entropy via\\n        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\\n\\n        #loss.backward()\\n        #optimizer.step()\\n        total_loss += float(loss) * pred.numel()\\n        total_examples += pred.numel()\\n    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "'''\n",
        "%%time\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "#model = Model(hidden_channels=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(0, 5):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        sampled_data = sampled_data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss, pred, model, emb_dict = train(train_data=sampled_data)\n",
        "        #loss, pred, model = train(model=model, train_data=sampled_data)\n",
        "        # TODO: Move `sampled_data` to the respective `device`\n",
        "        # TODO: Run `forward` pass of the model\n",
        "        # TODO: Apply binary cross entropy via\n",
        "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
        "\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and load trained model"
      ],
      "metadata": {
        "id": "LoQpRVra1wVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/OTTO-Kaggle-Competition/model_frac0.1.pt'"
      ],
      "metadata": {
        "id": "Rh1zgbIocu6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joyCx1zCnzl2"
      },
      "outputs": [],
      "source": [
        "# Save the entire model\n",
        "#torch.save(model, path)\n",
        "#model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FV5XwXrhfbYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cdea3028-2226-4f09-ee97-b211698f9c7c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): Module(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): Module(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              "  (aid_lin): Linear(32, 32, bias=True)\n",
              "  (session_emb): Embedding(6838382, 32)\n",
              "  (aid_emb): Embedding(1492658, 32)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "# Load the entire model\n",
        "model = torch.load(path, map_location=torch.device('cpu'))\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.session_emb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v43RFc65Db3H",
        "outputId": "75fac069-732d-4844-c7f2-afe48d2d54ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Embedding(6838382, 32)"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ia8AeaevVSQH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8d225c0-7f0d-44e8-8525-8e7141527713"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[0.5489, 0.2217, 0.3893,  ..., 0.5141, 0.1052, 0.6284],\n",
              "         [0.7839, 0.3998, 0.0615,  ..., 0.4654, 0.8580, 0.6882],\n",
              "         [0.0771, 0.8429, 0.7703,  ..., 0.8073, 0.1500, 0.3647],\n",
              "         ...,\n",
              "         [0.3696, 0.9836, 0.9336,  ..., 0.0180, 0.9637, 0.0802],\n",
              "         [0.8489, 0.1433, 0.7253,  ..., 0.8944, 0.8172, 0.3645],\n",
              "         [0.8040, 0.3697, 0.9342,  ..., 0.5995, 0.6478, 0.1654]]),\n",
              " 'aid': tensor([[0.9024, 0.7726, 0.4998,  ..., 0.5282, 0.8087, 0.9968],\n",
              "         [0.7033, 0.8734, 0.9517,  ..., 0.6191, 0.8079, 0.4447],\n",
              "         [0.1028, 0.2097, 0.9146,  ..., 0.8266, 0.0273, 0.4725],\n",
              "         ...,\n",
              "         [0.7382, 0.0222, 0.8513,  ..., 0.6854, 0.0893, 0.3610],\n",
              "         [0.6376, 0.5493, 0.4658,  ..., 0.4513, 0.4208, 0.0953],\n",
              "         [0.8167, 0.6925, 0.1868,  ..., 0.4682, 0.7187, 0.5078]])}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "data.x_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24MBuXw64v-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model.get_embedding(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ],
      "metadata": {
        "id": "bBNzMoCZ9BZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fbPqjTSINEG"
      },
      "outputs": [],
      "source": [
        "#model.encoder(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4bbKw80fs7A"
      },
      "outputs": [],
      "source": [
        "#trained_model.encoder(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model(val_data.to(device).x_dict,\n",
        "#      val_data.to(device).edge_index_dict,\n",
        "#      val_data['session', 'aid'].edge_label_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTbyGz6d5Jf8",
        "outputId": "d972e733-2460-4890-cecb-7419574e962c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0536, 1.1028, 1.0545,  ..., 1.0439, 1.0466, 1.0864], device='cuda:0',\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trained_model(val_data.x_dict,\n",
        "#      val_data.edge_index_dict,\n",
        "#      val_data['session', 'aid'].edge_label_index)"
      ],
      "metadata": {
        "id": "OCh1KqnT5msU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqiZlbCxnOcp"
      },
      "source": [
        "### Evaluate a Heterogenous Linklevel GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzCtJihVnWKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9cc6896-b1e2-4578-c3ef-5c75957eac00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    node_id=[5197],\n",
            "    x=[5197, 32]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={\n",
            "    x=[2804, 32],\n",
            "    node_id=[2804]\n",
            "  },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 5028],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    input_id=[384]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 6349] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = val_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,  # TODO\n",
        "    num_neighbors=[20, 10],  # TODO\n",
        "    #neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.min() >= 0\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.max() <= 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFGjR1IWpKqX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d68fca8-161f-4fb9-b9ea-a8bce7f2d4e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 565/565 [00:07<00:00, 76.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.5000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# You need the labels to binarize\n",
        "labels = [0, 1, 2]\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        _, pred, ground_truth = test(model=model, data=sampled_data)\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(ground_truth)\n",
        "        # TODO: Collect predictions and ground-truths and write them into\n",
        "        # `preds` and `ground_truths`.\n",
        "        #raise NotImplementedError\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "\n",
        "# Binarize `pred` with shape (n_samples, n_classes)\n",
        "pred = label_binarize(pred.astype(int), classes=labels)\n",
        "\n",
        "# Binarize `ground_truth` with shape (n_samples, n_classes)\n",
        "ground_truth = label_binarize(ground_truth, classes=labels)\n",
        "\n",
        "#rmse = _\n",
        "auc = roc_auc_score(ground_truth, pred, multi_class='ovo', average='weighted')\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "#print('RMSE: ', rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "wvliA4O-iRzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = train"
      ],
      "metadata": {
        "id": "WDuQfHztjFw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del data\n",
        "#gc.collect()"
      ],
      "metadata": {
        "id": "sdT6MuWSiXjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#trained_model.state_dict()"
      ],
      "metadata": {
        "id": "c7e2S_TJjKcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "id": "-G6SUSA8nPxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8082e664-e440-4a79-b0b8-b491d3e43bc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.1.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.0/648.0 KB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.1-cp38-cp38-linux_x86_64.whl size=394072 sha256=06589d3a5d9d8a5b4a8ac6a8a64a20bea84525e0d580f60e672026b92ef7809b\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/93/19/30511c4a9ae6b4937455a134c34a39e13943e2c6f46fcd2ed2\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "index = AnnoyIndex(32, 'angular')\n",
        "\n",
        "for idx, idx_embedding in enumerate(model.state_dict()['decoder.lin2.weight'].cpu()):\n",
        "  index.add_item(idx, idx_embedding)\n",
        "\n",
        "index.build(10)"
      ],
      "metadata": {
        "id": "THcdpyqPilKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "247eda6c-9778-4dba-df62-cc62f8878396"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 3.33 ms, sys: 1.07 ms, total: 4.39 ms\n",
            "Wall time: 5.81 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del model, loader, optimizer\n",
        "#gc.collect()\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "7C2rm1o7nePf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation/Inference"
      ],
      "metadata": {
        "id": "TEVRPeQOnkjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source_idx -> dict{id:idx}\n",
        "# target_idx -> dict{id:idx}"
      ],
      "metadata": {
        "id": "x3UFmE8srtJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = pl.read_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/dataset/test.parquet')"
      ],
      "metadata": {
        "id": "-_BGTRQysNyE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "jJO64zAQsSBR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 776
        },
        "outputId": "f50fe267-daaf-4c08-99ad-5fec675732c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "shape: (6928123, 4)\n",
              "┌──────────┬─────────┬────────────┬──────┐\n",
              "│ session  ┆ aid     ┆ ts         ┆ type │\n",
              "│ ---      ┆ ---     ┆ ---        ┆ ---  │\n",
              "│ i32      ┆ i32     ┆ i32        ┆ u8   │\n",
              "╞══════════╪═════════╪════════════╪══════╡\n",
              "│ 12899779 ┆ 59625   ┆ 1661724000 ┆ 0    │\n",
              "│ 12899780 ┆ 1142000 ┆ 1661724000 ┆ 0    │\n",
              "│ 12899780 ┆ 582732  ┆ 1661724058 ┆ 0    │\n",
              "│ 12899780 ┆ 973453  ┆ 1661724109 ┆ 0    │\n",
              "│ ...      ┆ ...     ┆ ...        ┆ ...  │\n",
              "│ 14571578 ┆ 519105  ┆ 1662328775 ┆ 0    │\n",
              "│ 14571579 ┆ 739876  ┆ 1662328775 ┆ 0    │\n",
              "│ 14571580 ┆ 202353  ┆ 1662328781 ┆ 0    │\n",
              "│ 14571581 ┆ 1100210 ┆ 1662328791 ┆ 0    │\n",
              "└──────────┴─────────┴────────────┴──────┘"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        white-space: pre;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-top: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        padding-bottom: 0;\n",
              "    }\n",
              "\n",
              "    .dataframe td {\n",
              "        line-height: 95%;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "<small>shape: (6928123, 4)</small>\n",
              "<thead>\n",
              "<tr>\n",
              "<th>\n",
              "session\n",
              "</th>\n",
              "<th>\n",
              "aid\n",
              "</th>\n",
              "<th>\n",
              "ts\n",
              "</th>\n",
              "<th>\n",
              "type\n",
              "</th>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "i32\n",
              "</td>\n",
              "<td>\n",
              "i32\n",
              "</td>\n",
              "<td>\n",
              "i32\n",
              "</td>\n",
              "<td>\n",
              "u8\n",
              "</td>\n",
              "</tr>\n",
              "</thead>\n",
              "<tbody>\n",
              "<tr>\n",
              "<td>\n",
              "12899779\n",
              "</td>\n",
              "<td>\n",
              "59625\n",
              "</td>\n",
              "<td>\n",
              "1661724000\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899780\n",
              "</td>\n",
              "<td>\n",
              "1142000\n",
              "</td>\n",
              "<td>\n",
              "1661724000\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899780\n",
              "</td>\n",
              "<td>\n",
              "582732\n",
              "</td>\n",
              "<td>\n",
              "1661724058\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899780\n",
              "</td>\n",
              "<td>\n",
              "973453\n",
              "</td>\n",
              "<td>\n",
              "1661724109\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899780\n",
              "</td>\n",
              "<td>\n",
              "736515\n",
              "</td>\n",
              "<td>\n",
              "1661724136\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899780\n",
              "</td>\n",
              "<td>\n",
              "1142000\n",
              "</td>\n",
              "<td>\n",
              "1661724155\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899781\n",
              "</td>\n",
              "<td>\n",
              "141736\n",
              "</td>\n",
              "<td>\n",
              "1661724000\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899781\n",
              "</td>\n",
              "<td>\n",
              "199008\n",
              "</td>\n",
              "<td>\n",
              "1661724022\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899781\n",
              "</td>\n",
              "<td>\n",
              "57315\n",
              "</td>\n",
              "<td>\n",
              "1661724170\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899781\n",
              "</td>\n",
              "<td>\n",
              "194067\n",
              "</td>\n",
              "<td>\n",
              "1661724246\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899781\n",
              "</td>\n",
              "<td>\n",
              "199008\n",
              "</td>\n",
              "<td>\n",
              "1661780623\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "12899781\n",
              "</td>\n",
              "<td>\n",
              "199008\n",
              "</td>\n",
              "<td>\n",
              "1661781274\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "<td>\n",
              "...\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571570\n",
              "</td>\n",
              "<td>\n",
              "389613\n",
              "</td>\n",
              "<td>\n",
              "1662328765\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571571\n",
              "</td>\n",
              "<td>\n",
              "60347\n",
              "</td>\n",
              "<td>\n",
              "1662328766\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571572\n",
              "</td>\n",
              "<td>\n",
              "986164\n",
              "</td>\n",
              "<td>\n",
              "1662328766\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571573\n",
              "</td>\n",
              "<td>\n",
              "1823537\n",
              "</td>\n",
              "<td>\n",
              "1662328767\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571574\n",
              "</td>\n",
              "<td>\n",
              "306024\n",
              "</td>\n",
              "<td>\n",
              "1662328769\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571575\n",
              "</td>\n",
              "<td>\n",
              "1257071\n",
              "</td>\n",
              "<td>\n",
              "1662328771\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571576\n",
              "</td>\n",
              "<td>\n",
              "1196256\n",
              "</td>\n",
              "<td>\n",
              "1662328774\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571577\n",
              "</td>\n",
              "<td>\n",
              "1141710\n",
              "</td>\n",
              "<td>\n",
              "1662328774\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571578\n",
              "</td>\n",
              "<td>\n",
              "519105\n",
              "</td>\n",
              "<td>\n",
              "1662328775\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571579\n",
              "</td>\n",
              "<td>\n",
              "739876\n",
              "</td>\n",
              "<td>\n",
              "1662328775\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571580\n",
              "</td>\n",
              "<td>\n",
              "202353\n",
              "</td>\n",
              "<td>\n",
              "1662328781\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "<tr>\n",
              "<td>\n",
              "14571581\n",
              "</td>\n",
              "<td>\n",
              "1100210\n",
              "</td>\n",
              "<td>\n",
              "1662328791\n",
              "</td>\n",
              "<td>\n",
              "0\n",
              "</td>\n",
              "</tr>\n",
              "</tbody>\n",
              "</table>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source_idx[12899779]"
      ],
      "metadata": {
        "id": "fPsH2TIawpwH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "09b435e5-3fc5-48fb-e949-daeb873119be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-79-4f094e55e4d9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msource_idx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m12899779\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m: 12899779"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_idx[1142000]"
      ],
      "metadata": {
        "id": "15vsu91swvlV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test.to_pandas().reset_index(drop=True)\n",
        "\n",
        "test['session'] = test['session'].map(source_idx)\n",
        "test['aid'] = test['aid'].map(target_idx)"
      ],
      "metadata": {
        "id": "sQviEmpkweyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "i5T4HJ0qwhaR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(path,mode=\"validation\",n_neighbors=20):\n",
        "\n",
        "\n",
        "    test = pl.read_parquet(path)\n",
        "    test = test.to_pandas().reset_index(drop=True)\n",
        "\n",
        "    test['session'] = test['session'].map(source_idx)\n",
        "    test['aid'] = test['aid'].map(target_idx)\n",
        "\n",
        "    session_types = ['clicks', 'carts', 'orders']\n",
        "    #test_session_AIDs = test.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
        "    #test_session_types = test.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
        "    test_session_AIDs = test.groupby('session')['aid'].apply(list)\n",
        "    test_session_types = test.groupby('session')['type'].apply(list)\n",
        "\n",
        "    del test\n",
        "    gc.collect()\n",
        "    labels = []\n",
        "\n",
        "    type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
        "\n",
        "    for AIDs, types in zip(test_session_AIDs, test_session_types):\n",
        "        if len(AIDs) >= 20:\n",
        "            # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
        "            weights=np.logspace(0.1,1,len(AIDs),base=2, endpoint=True)-1\n",
        "            aids_temp=defaultdict(lambda: 0)\n",
        "            for aid,w,t in zip(AIDs,weights,types): \n",
        "                aids_temp[aid]+= w * type_weight_multipliers[t]\n",
        "\n",
        "            sorted_aids=[k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
        "            labels.append(sorted_aids[:20])\n",
        "        else:\n",
        "            # here we don't have 20 aids to output -- we will use word2vec embeddings to generate candidates!\n",
        "            AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
        "\n",
        "            # let's grab the most recent aid\n",
        "            most_recent_aid = AIDs[0]\n",
        "\n",
        "            # and look for some neighbors!\n",
        "            nns = [i for i in index.get_nns_by_item(most_recent_aid, n_neighbors+1)[1:]]\n",
        "\n",
        "\n",
        "            labels.append((AIDs+nns)[:n_neighbors])\n",
        "\n",
        "    labels_as_strings = [' '.join([str(l) for l in lls]) for lls in labels]\n",
        "\n",
        "    predictions = pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels_as_strings})\n",
        "\n",
        "    prediction_dfs = []\n",
        "\n",
        "    for st in session_types:\n",
        "        modified_predictions = predictions.copy()\n",
        "        modified_predictions.session_type = modified_predictions.session_type.astype('str') + f'_{st}'\n",
        "        prediction_dfs.append(modified_predictions)\n",
        "\n",
        "    sub = pd.concat(prediction_dfs).reset_index(drop=True)\n",
        "    \n",
        "    del prediction_dfs, predictions,labels_as_strings, labels, test_session_types,test_session_AIDs\n",
        "    gc.collect()\n",
        "    \n",
        "    if mode==\"test\":\n",
        "        sub.to_csv(\"submission.csv\",index=False)\n",
        "        return sub\n",
        "    \n",
        "    else: # validation\n",
        "        sub['labels_2'] = sub['labels'].apply(lambda x : [int(s) for s in x.split(' ')])\n",
        "        submission = pd.DataFrame()\n",
        "        submission['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n",
        "        submission['type'] = sub.session_type.apply(lambda x: x.split('_')[1])\n",
        "        submission['labels'] = sub.labels_2.apply(lambda x : [item for item in x[:] ]) #.apply(lambda x: [int(i) for i in x.split(',')[:20]])\n",
        "        test_labels = pd.read_parquet('/content/dataset/test_labels.parquet')\n",
        "        test_labels = test_labels.merge(submission, how='left', on=['session', 'type'])\n",
        "        del sub,submission\n",
        "        gc.collect()\n",
        "        gc.collect()\n",
        "        test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
        "        test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
        "        recall_per_type = test_labels.groupby(['type'])['hits'].sum() / test_labels.groupby(['type'])['gt_count'].sum() \n",
        "        score = (recall_per_type * pd.Series({'clicks': 0.1, 'carts': 0.30, 'orders': 0.60})).sum()\n",
        "\n",
        "        return score"
      ],
      "metadata": {
        "id": "4P_XMrqdnoQZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ],
      "metadata": {
        "id": "fkgS_6Sqntvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/kaggle/test.parquet'\n",
        "validation_score = evaluate(path,mode=\"validation\",n_neighbors=20)"
      ],
      "metadata": {
        "id": "RaKu5eqLntJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "ae20b978-4a72-490a-f57f-2fd1602bd808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-80-be4b279aedd7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/content/kaggle/test.parquet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidation_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-79-e576a05d6733>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(path, mode, n_neighbors)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mrecall_per_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwargs)\u001b[0m\n\u001b[1;32m   8738\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8739\u001b[0m         )\n\u001b[0;32m-> 8740\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8742\u001b[0m     def applymap(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    686\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 688\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    689\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    690\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 812\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    814\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    826\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-e576a05d6733>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mrecall_per_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: 'float' object is not iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xALYNC0Y8pAz",
        "outputId": "77f887c7-df64-4324-d4e3-c3a7a5da9aaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-79-e576a05d6733>\u001b[0m(76)\u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     74 \u001b[0;31m        \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     75 \u001b[0;31m        \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 76 \u001b[0;31m        \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     77 \u001b[0;31m        \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     78 \u001b[0;31m        \u001b[0mrecall_per_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> test_labels\n",
            "*** NameError: name 'test_labels' is not defined\n",
            "ipdb> up\n",
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m(828)\u001b[0;36mapply_series_generator\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    826 \u001b[0;31m            \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    827 \u001b[0;31m                \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 828 \u001b[0;31m                \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    829 \u001b[0;31m                \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    830 \u001b[0;31m                    \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> up\n",
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m(812)\u001b[0;36mapply_standard\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    810 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    811 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 812 \u001b[0;31m        \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    813 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    814 \u001b[0;31m        \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> up\n",
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/apply.py\u001b[0m(688)\u001b[0;36mapply\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m    686 \u001b[0;31m            \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    687 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m--> 688 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    689 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m    690 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> up\n",
            "> \u001b[0;32m/usr/local/lib/python3.8/dist-packages/pandas/core/frame.py\u001b[0m(8740)\u001b[0;36mapply\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m   8738 \u001b[0;31m            \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   8739 \u001b[0;31m        )\n",
            "\u001b[0m\u001b[0;32m-> 8740 \u001b[0;31m        \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   8741 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m   8742 \u001b[0;31m    def applymap(\n",
            "\u001b[0m\n",
            "ipdb> up\n",
            "> \u001b[0;32m<ipython-input-79-e576a05d6733>\u001b[0m(76)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     74 \u001b[0;31m        \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     75 \u001b[0;31m        \u001b[0mgc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 76 \u001b[0;31m        \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintersection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     77 \u001b[0;31m        \u001b[0mtest_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mground_truth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     78 \u001b[0;31m        \u001b[0mrecall_per_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'hits'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'gt_count'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> test_labels\n",
            "          session    type                                       ground_truth  \\\n",
            "0        11098528  clicks                                          [1679529]   \n",
            "1        11098528   carts                                          [1199737]   \n",
            "2        11098528  orders  [990658, 950341, 1462506, 1561739, 907564, 369...   \n",
            "3        11098529  clicks                                          [1105029]   \n",
            "4        11098530  orders                                           [409236]   \n",
            "...           ...     ...                                                ...   \n",
            "2212687  12899774  clicks                                          [1399483]   \n",
            "2212688  12899775  clicks                                          [1760714]   \n",
            "2212689  12899776  clicks                                          [1737908]   \n",
            "2212690  12899777  clicks                                           [384045]   \n",
            "2212691  12899778  clicks                                            [32070]   \n",
            "\n",
            "         labels  \n",
            "0           NaN  \n",
            "1           NaN  \n",
            "2           NaN  \n",
            "3           NaN  \n",
            "4           NaN  \n",
            "...         ...  \n",
            "2212687     NaN  \n",
            "2212688     NaN  \n",
            "2212689     NaN  \n",
            "2212690     NaN  \n",
            "2212691     NaN  \n",
            "\n",
            "[2212692 rows x 4 columns]\n",
            "ipdb> quit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.8/bdb.py\", line 359, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_score)"
      ],
      "metadata": {
        "id": "2L_kDadTn8hU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "ab96114a-b8aa-41d0-bb75-cdf90207bc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c6a329f7ca58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZw_TNkMQRaq"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFOSPOfhOjYr"
      },
      "source": [
        "Submission File\n",
        "For each `session` id and `type` combination in the test set, you must predict the `aid` values in the `label` column, which is space delimited. You can predict up to 20 `aid` values per row. The file should contain a header and have the following format:\n",
        "\n",
        "```\n",
        "session_type,labels\n",
        "12906577_clicks,135193 129431 119318 ...\n",
        "12906577_carts,135193 129431 119318 ...\n",
        "12906577_orders,135193 129431 119318 ...\n",
        "12906578_clicks, 135193 129431 119318 ...\n",
        "etc.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWyo1qVmOi8E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VKqQxQA0-X44",
        "XHNbZyHebUPV"
      ],
      "provenance": [],
      "mount_file_id": "1OYwFL1Nb0QpBH4AHctdeHqjz_napt5xX",
      "authorship_tag": "ABX9TyM1A1brcgv4IxZHQEzg3dSy",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}