{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p4zaa/OTTO-Multi-Objective-Recommender-System/blob/main/%5BDEVELOP1_4%5D_OTTO_%E2%80%93_Multi_Objective_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version Logs\n",
        "* [View in my Github](https://github.com/p4zaa/OTTO-Multi-Objective-Recommender-System)"
      ],
      "metadata": {
        "id": "yf2nIQqrAy8y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZTgGyHWwP0wa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YGBdYwXz-B9e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j7Gsb6xQ98eL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "5d7f7bcf-67ce-4768-952e-28b8cc721ca9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-8ec24838-5219-4b13-8935-66d27e9e6ad0\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-8ec24838-5219-4b13-8935-66d27e9e6ad0\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "ref                                                             title                                           size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                       COVID-19 Dataset                                 5MB  2022-11-13 15:47:17          13231        375  1.0              \n",
            "thedevastator/analyzing-credit-card-spending-habits-in-india    Credit Card Spending Habits in India           319KB  2022-12-14 07:30:37            772         32  1.0              \n",
            "michals22/coffee-dataset                                        Coffee dataset                                  24KB  2022-12-15 20:02:12           2884         72  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data         E-Commerce Sales Dataset                         6MB  2022-12-03 09:27:17           2159         55  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                       Salary Prediction                                3MB  2022-11-16 13:52:31           7702        168  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset              Fifa World Cup 2022: Complete Dataset            7KB  2022-12-18 22:51:11           2393         98  1.0              \n",
            "mattop/highest-grossing-mobile-games                            Highest Grossing Mobile Games                    3KB  2022-12-19 15:20:22            471         23  1.0              \n",
            "thedevastator/uncover-global-trends-in-mental-health-disorder   Global Trends in Mental Health Disorder          1MB  2022-12-14 05:30:38            703         24  1.0              \n",
            "rajkumarpandey02/fifa-world-cup-attendance-19302022             FIFA World Cup Attendance 1930-2022              5KB  2022-12-19 10:04:26            749         21  1.0              \n",
            "thedevastator/revealing-insights-from-youtube-video-and-channe  YouTube Videos and Channels Metadata            82MB  2022-12-14 02:48:24            446         23  0.9411765        \n",
            "thedevastator/uncovering-insights-to-college-majors-and-their   College Majors and their Graduates              39KB  2022-12-06 16:06:52           1105         32  1.0              \n",
            "mvieira101/global-cost-of-living                                Global Cost of Living                            1MB  2022-12-03 16:37:53           3554         73  0.9705882        \n",
            "anashamoutni/students-employability-dataset                     Students' Employability Dataset - Philippines   97KB  2022-12-18 15:51:39            658         28  0.88235295       \n",
            "swaptr/fifa-world-cup-2022-statistics                           FIFA World Cup 2022 Team Data                   15KB  2022-12-19 00:29:15           2719         61  0.9705882        \n",
            "thedevastator/the-ultimate-netflix-tv-shows-and-movies-dataset  Netflix TV Shows and Movies (2022 Updated)       2MB  2022-11-27 20:41:41           2532         46  1.0              \n",
            "whenamancodes/predict-diabities                                 Predict Diabetes                                 9KB  2022-11-09 12:18:49           8010        122  1.0              \n",
            "kulturehire/understanding-career-aspirations-of-genz            Understanding Career Aspirations of GenZ         8KB  2022-12-21 13:44:32            242         23  0.9117647        \n",
            "thedevastator/uncovering-wage-disparities-in-pennsylvania-s-hi  Higher Education Wages                         223KB  2022-12-04 15:42:36           1287         40  1.0              \n",
            "laibaanwer/superstore-sales-dataset                             SuperStore Sales Dataset                         2MB  2022-12-07 08:53:32           1510         37  1.0              \n",
            "catherinerasgaitis/mxmh-survey-results                          Music & Mental Health Survey Results            22KB  2022-11-21 10:03:12           3210         75  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "421Djk4r4qJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "342b8ff1-27ee-4ccb-9b40-ce6dff6f0f26"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading otto-full-optimized-memory-footprint.zip to /content/kaggle\n",
            " 99% 1.07G/1.09G [00:06<00:00, 203MB/s]\n",
            "100% 1.09G/1.09G [00:06<00:00, 171MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('/content/kaggle/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "df = df.sample(frac=0.001, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "N-Q_j2wx7Omc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "0e35af12-5e2f-438a-fe59-a7ee70e57ace"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           session      aid          ts  type\n",
              "100186684  3479265   321317  1660051526     0\n",
              "129433089  5104661  1053683  1659884541     0\n",
              "143499463  6008018   795232  1660423516     0\n",
              "85005190   2718783   247375  1659730899     0\n",
              "11037391    216123   298495  1659992027     0\n",
              "...            ...      ...         ...   ...\n",
              "146768061  6247517  1560437  1660677217     0\n",
              "182915720  9296892  1811814  1660656827     0\n",
              "126702454  4944715   194379  1660224525     0\n",
              "137465226  5607554   887081  1660395779     0\n",
              "107956587  3893811  1826736  1660049140     0\n",
              "\n",
              "[216716 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0188a136-bb0c-4f65-a7db-87a20327867e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>100186684</th>\n",
              "      <td>3479265</td>\n",
              "      <td>321317</td>\n",
              "      <td>1660051526</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129433089</th>\n",
              "      <td>5104661</td>\n",
              "      <td>1053683</td>\n",
              "      <td>1659884541</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143499463</th>\n",
              "      <td>6008018</td>\n",
              "      <td>795232</td>\n",
              "      <td>1660423516</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85005190</th>\n",
              "      <td>2718783</td>\n",
              "      <td>247375</td>\n",
              "      <td>1659730899</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11037391</th>\n",
              "      <td>216123</td>\n",
              "      <td>298495</td>\n",
              "      <td>1659992027</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146768061</th>\n",
              "      <td>6247517</td>\n",
              "      <td>1560437</td>\n",
              "      <td>1660677217</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182915720</th>\n",
              "      <td>9296892</td>\n",
              "      <td>1811814</td>\n",
              "      <td>1660656827</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126702454</th>\n",
              "      <td>4944715</td>\n",
              "      <td>194379</td>\n",
              "      <td>1660224525</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137465226</th>\n",
              "      <td>5607554</td>\n",
              "      <td>887081</td>\n",
              "      <td>1660395779</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107956587</th>\n",
              "      <td>3893811</td>\n",
              "      <td>1826736</td>\n",
              "      <td>1660049140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216716 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0188a136-bb0c-4f65-a7db-87a20327867e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0188a136-bb0c-4f65-a7db-87a20327867e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0188a136-bb0c-4f65-a7db-87a20327867e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I6SK6ahjEpy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcffa39f-b57b-41d3-d49c-6d44a2e06c97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session    0\n",
              "aid        0\n",
              "ts         0\n",
              "type       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "h8hFppsb5cAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0a78b96f-a202-4e3a-8540-835975eaba22"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OFhgeI-OgFEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0939d7b0-d750-4c55-85fc-3a3843313240"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 216716 entries, 100186684 to 107956587\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count   Dtype\n",
            "---  ------   --------------   -----\n",
            " 0   session  216716 non-null  int32\n",
            " 1   aid      216716 non-null  int32\n",
            " 2   ts       216716 non-null  int32\n",
            " 3   type     216716 non-null  uint8\n",
            "dtypes: int32(3), uint8(1)\n",
            "memory usage: 4.3 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FriR71pK-hxH"
      },
      "source": [
        "### [Use new code instead] Construct `edge_index`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Jw0zU0aTMZ-G"
      },
      "outputs": [],
      "source": [
        "#def to_tuple(row):\n",
        "#    return tuple(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "D1eMUs7A8qbA"
      },
      "outputs": [],
      "source": [
        "# also drop the ts and type column\n",
        "#connectivity = df.drop(columns=['ts', 'type']).apply(to_tuple, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "h8KsppDI7dvJ"
      },
      "outputs": [],
      "source": [
        "#connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "p2Yv20LW0Bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "e7a1ed79-cf1c-44d1-bb41-a45de2de0502"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# session index dict\\n#session = sorted(df['session'].unique())\\nsession = df['session'].unique()\\nsession_nodes_idx = {id:idx for idx, id in enumerate(session)}\\n\\n# aid(article id) index dict\\n#aid = sorted(df['aid'].unique())\\naid = df['aid'].unique()\\naid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# Old code\n",
        "'''\n",
        "# session index dict\n",
        "#session = sorted(df['session'].unique())\n",
        "session = df['session'].unique()\n",
        "session_nodes_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "#aid = sorted(df['aid'].unique())\n",
        "aid = df['aid'].unique()\n",
        "aid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "xTiXlCrOQYYm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "eace0139-c600-46a3-a6a6-530c40dada2b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef get_node_indices(data, key):\\n  for id in data[key].unique():\\n    yield id, next(i for i, v in enumerate(data[key]) if v == id)\\n\\nsession_nodes_idx = dict(get_node_indices(df, 'session'))\\naid_nodes_idx = dict(get_node_indices(df, 'aid'))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# use this code if the above cause memory crash\n",
        "# very slow but memory good\n",
        "'''\n",
        "def get_node_indices(data, key):\n",
        "  for id in data[key].unique():\n",
        "    yield id, next(i for i, v in enumerate(data[key]) if v == id)\n",
        "\n",
        "session_nodes_idx = dict(get_node_indices(df, 'session'))\n",
        "aid_nodes_idx = dict(get_node_indices(df, 'aid'))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "tpiPnhRYN7X4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "a4ea0b6b-1f00-4e2a-c881-742e51fd545e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni_session = []\\ni_aid = []\\nfor session, aid in connectivity_list:\\n  i_session.append(user_nodes_idx[user])\\n  i_aid.append(item_nodes_idx[item])\\n\\nindice = [i_session, i_aid]\\nedge_index = torch.Tensor(indice).type(torch.long)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# /!\\ this cause memory crashed in a very large data\n",
        "'''\n",
        "i_session = []\n",
        "i_aid = []\n",
        "for session, aid in connectivity_list:\n",
        "  i_session.append(user_nodes_idx[user])\n",
        "  i_aid.append(item_nodes_idx[item])\n",
        "\n",
        "indice = [i_session, i_aid]\n",
        "edge_index = torch.Tensor(indice).type(torch.long)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "My-fApG4OR-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "415b7db9-ebd7-477e-db11-235d1dfb1b0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\\n  for user, item in connectivity_list:\\n    yield user_nodes_idx[user], item_nodes_idx[item]\\n\\nedge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# Work but still got memory crash in very large data\n",
        "'''\n",
        "def get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\n",
        "  for user, item in connectivity_list:\n",
        "    yield user_nodes_idx[user], item_nodes_idx[item]\n",
        "\n",
        "edge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ERcykcKRz4Ri"
      },
      "outputs": [],
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "QvTKqD08lNFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d43b6395-7491-4722-cc7b-1b64d4a3a444"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-fdbbf2e7eb54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['session'] = connected['session'].map(source_idx)\n",
            "<ipython-input-18-fdbbf2e7eb54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['aid'] = connected['aid'].map(target_idx)\n"
          ]
        }
      ],
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4L_GWK4hlTWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adcd6ceb-672f-43c3-e026-4d5730a9d447"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-23961f25841f>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  edge_index = torch.tensor((source.values, target.values))\n"
          ]
        }
      ],
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "Dn3bodEPSWNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fd5fa44-5ee9-4038-d590-5f60ce8aabbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "xXl7YIluHxDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0edf946a-e91b-4df0-c2d0-0410bed8bf37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 216716])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "edge_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "zEQRr1JTIMYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0df429a6-5117-4202-c66b-07e4e256b0bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([127728, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "aid_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TLVPfcmsIThg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "099e2da3-a8e5-4ce0-a982-2f7521be09ac"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "edge_label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "gGH8Sd8O97x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d40974dc-587b-4ca5-b633-163623d3ce37"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ num_nodes=208170 },\n",
              "  \u001b[1maid\u001b[0m={ x=[127728, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "9F9gevNn-Ms3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "616a0a6b-268b-4ba2-becb-64aef6c16266"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "TArUgtyn-OZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e35cb613-5f9e-49fb-f239-43a0d0852f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "wQNhuNgM-Tar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad94dfc-0837-451c-9e9f-1a3d0f392fa2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolated nodes? False\n",
            "Self loops? False\n",
            "Undirected graph?  False\n"
          ]
        }
      ],
      "source": [
        "print('Isolated nodes?', data.has_isolated_nodes())\n",
        "print('Self loops?', data.has_self_loops())\n",
        "print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "d50QCHYyKBNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7a1eeef-7f8f-47a7-d164-a0e7bc279d47"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208170,\n",
              "    x=[208170, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127728, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKqQxQA0-X44"
      },
      "source": [
        "### Calculate Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "5QvT19CNOtUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26f9924a-6bb5-4fec-ed38-c132f0630f1b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "data['session', 'aid'].edge_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "Jlz46YER-Uns"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "\n",
        "counts = torch.bincount(data['session', 'aid'].edge_label)\n",
        "\n",
        "# Set weights normalized by (max count/each count)\n",
        "weight = counts.max() / counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cZEH42kKOl58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7d68215c-c2c6-4c90-98d9-543a6c5554e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([194616,  16908,   5192])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Rw__CF6WOife",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21c03d91-e39b-462f-cd12-5515712c643a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5103, 37.4838])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "nLOdlJzR-hDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "a9ab6d43-a732-4b4d-8c85-555d7932dcd1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"bf66f143-42c3-4106-8dca-59a221f1a4aa\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"bf66f143-42c3-4106-8dca-59a221f1a4aa\")) {                    Plotly.newPlot(                        \"bf66f143-42c3-4106-8dca-59a221f1a4aa\",                        [{\"line\":{\"color\":\"coral\"},\"name\":\"nb rows\",\"x\":[0,1,2,3,4,5],\"y\":[194616,16908,5192],\"type\":\"scatter\"},{\"line\":{\"color\":\"royalblue\"},\"name\":\"weights\",\"x\":[0,1,2,3,4,5],\"y\":[1.0,11.51029109954834,37.483821868896484],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"# rows\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"weights\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('bf66f143-42c3-4106-8dca-59a221f1a4aa');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dict = {'type': (counts, '# rows','coral'), 'weights': (weight, 'weights','royalblue')}\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=counts.detach().cpu().numpy(),\n",
        "               name = 'nb rows', line_color= 'coral'))\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=weight.detach().cpu().numpy(),\n",
        "               name = 'weights', line_color= 'royalblue'),  secondary_y=True)\n",
        "\n",
        "\n",
        "fig.update_yaxes(title_text=\"# rows\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"weights\", secondary_y=True)\n",
        "fig.update_xaxes(title_text=\"Type\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "5kq9vMp3Rxeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cdc9fc0-8d25-4c36-af7d-ce4fc4d19a46"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[  2964,  40252, 190900,  ...,  98245, 102531,  97505],\n",
              "        [  2881,  17633, 119480,  ...,  49186,  72697,   6671]]), 'edge_label': tensor([0, 0, 0,  ..., 0, 0, 1]), 'edge_label_index': tensor([[  2964,  40252, 190900,  ...,  98245, 102531,  97505],\n",
              "        [  2881,  17633, 119480,  ...,  49186,  72697,   6671]])}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "train_data['session','aid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "VzTgyXxUSGfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d7ee726-5d44-4c82-83d1-f5fc88121e0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "train_data['session','aid'].edge_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "4N6oASmHaoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d546f547-85d5-4e4c-9458-e299ad3e9a62"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5025, 37.7202])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "ZENXvG8wealJ"
      },
      "outputs": [],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "with torch.no_grad():\n",
        "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ayGHaB6JegtI"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "RIjLW5AteiWZ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mt5-wzRekay",
        "outputId": "fd69d869-7520-4209-c194-9e02eab90ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 4.2428, Train: 1.9153, Val: 1.1977, Test: 1.2167\n",
            "Epoch: 001, Loss: 5.0976, Train: 0.4163, Val: 0.4136, Test: 0.4058\n",
            "Epoch: 002, Loss: 5.1917, Train: 0.5954, Val: 0.4383, Test: 0.4336\n",
            "Epoch: 003, Loss: 2.2964, Train: 1.2834, Val: 0.6717, Test: 0.6791\n",
            "Epoch: 004, Loss: 2.1217, Train: 1.0288, Val: 0.5956, Test: 0.5992\n",
            "Epoch: 005, Loss: 1.8127, Train: 0.8573, Val: 0.5334, Test: 0.5336\n",
            "Epoch: 006, Loss: 1.8325, Train: 0.8676, Val: 0.5393, Test: 0.5395\n",
            "Epoch: 007, Loss: 1.8255, Train: 1.0637, Val: 0.6053, Test: 0.6088\n",
            "Epoch: 008, Loss: 1.8315, Train: 1.0163, Val: 0.5900, Test: 0.5926\n",
            "Epoch: 009, Loss: 1.8075, Train: 0.9153, Val: 0.5512, Test: 0.5519\n",
            "Epoch: 010, Loss: 1.8039, Train: 0.9032, Val: 0.5413, Test: 0.5417\n",
            "Epoch: 011, Loss: 1.8078, Train: 0.9867, Val: 0.5644, Test: 0.5663\n",
            "Epoch: 012, Loss: 1.7995, Train: 1.0181, Val: 0.5697, Test: 0.5722\n",
            "Epoch: 013, Loss: 1.8080, Train: 0.9395, Val: 0.5377, Test: 0.5386\n",
            "Epoch: 014, Loss: 1.7983, Train: 0.9049, Val: 0.5240, Test: 0.5241\n",
            "Epoch: 015, Loss: 1.8068, Train: 0.9771, Val: 0.5446, Test: 0.5460\n",
            "Epoch: 016, Loss: 1.7977, Train: 1.0106, Val: 0.5538, Test: 0.5557\n",
            "Epoch: 017, Loss: 1.8049, Train: 0.9373, Val: 0.5295, Test: 0.5299\n",
            "Epoch: 018, Loss: 1.7981, Train: 0.9167, Val: 0.5225, Test: 0.5225\n",
            "Epoch: 019, Loss: 1.8024, Train: 0.9880, Val: 0.5427, Test: 0.5439\n",
            "Epoch: 020, Loss: 1.7989, Train: 0.9929, Val: 0.5432, Test: 0.5444\n",
            "Epoch: 021, Loss: 1.7997, Train: 0.9245, Val: 0.5224, Test: 0.5223\n",
            "Epoch: 022, Loss: 1.8002, Train: 0.9402, Val: 0.5260, Test: 0.5260\n",
            "Epoch: 023, Loss: 1.7973, Train: 0.9993, Val: 0.5421, Test: 0.5432\n",
            "Epoch: 024, Loss: 1.8010, Train: 0.9615, Val: 0.5303, Test: 0.5307\n",
            "Epoch: 025, Loss: 1.7959, Train: 0.9231, Val: 0.5194, Test: 0.5190\n",
            "Epoch: 026, Loss: 1.8002, Train: 0.9745, Val: 0.5327, Test: 0.5331\n",
            "Epoch: 027, Loss: 1.7964, Train: 0.9861, Val: 0.5354, Test: 0.5360\n",
            "Epoch: 028, Loss: 1.7979, Train: 0.9318, Val: 0.5204, Test: 0.5200\n",
            "Epoch: 029, Loss: 1.7981, Train: 0.9512, Val: 0.5250, Test: 0.5249\n",
            "Epoch: 030, Loss: 1.7957, Train: 0.9905, Val: 0.5353, Test: 0.5359\n",
            "Epoch: 031, Loss: 1.7985, Train: 0.9472, Val: 0.5234, Test: 0.5232\n",
            "Epoch: 032, Loss: 1.7958, Train: 0.9400, Val: 0.5214, Test: 0.5210\n",
            "Epoch: 033, Loss: 1.7965, Train: 0.9849, Val: 0.5329, Test: 0.5334\n",
            "Epoch: 034, Loss: 1.7972, Train: 0.9586, Val: 0.5258, Test: 0.5257\n",
            "Epoch: 035, Loss: 1.7950, Train: 0.9375, Val: 0.5204, Test: 0.5199\n",
            "Epoch: 036, Loss: 1.7965, Train: 0.9782, Val: 0.5307, Test: 0.5309\n",
            "Epoch: 037, Loss: 1.7959, Train: 0.9640, Val: 0.5268, Test: 0.5268\n",
            "Epoch: 038, Loss: 1.7947, Train: 0.9389, Val: 0.5204, Test: 0.5199\n",
            "Epoch: 039, Loss: 1.7959, Train: 0.9741, Val: 0.5292, Test: 0.5293\n",
            "Epoch: 040, Loss: 1.7951, Train: 0.9647, Val: 0.5264, Test: 0.5263\n",
            "Epoch: 041, Loss: 1.7944, Train: 0.9402, Val: 0.5200, Test: 0.5193\n",
            "Epoch: 042, Loss: 1.7954, Train: 0.9765, Val: 0.5317, Test: 0.5320\n",
            "Epoch: 043, Loss: 1.7950, Train: 0.9586, Val: 0.5300, Test: 0.5301\n",
            "Epoch: 044, Loss: 1.7940, Train: 0.9452, Val: 0.5294, Test: 0.5294\n",
            "Epoch: 045, Loss: 1.7945, Train: 0.9759, Val: 0.5418, Test: 0.5426\n",
            "Epoch: 046, Loss: 1.7946, Train: 0.9541, Val: 0.5382, Test: 0.5388\n",
            "Epoch: 047, Loss: 1.7937, Train: 0.9507, Val: 0.5383, Test: 0.5389\n",
            "Epoch: 048, Loss: 1.7937, Train: 0.9746, Val: 0.5464, Test: 0.5475\n",
            "Epoch: 049, Loss: 1.7941, Train: 0.9491, Val: 0.5387, Test: 0.5394\n",
            "Epoch: 050, Loss: 1.7935, Train: 0.9583, Val: 0.5421, Test: 0.5429\n",
            "Epoch: 051, Loss: 1.7931, Train: 0.9703, Val: 0.5463, Test: 0.5474\n",
            "Epoch: 052, Loss: 1.7933, Train: 0.9464, Val: 0.5390, Test: 0.5397\n",
            "Epoch: 053, Loss: 1.7933, Train: 0.9666, Val: 0.5458, Test: 0.5468\n",
            "Epoch: 054, Loss: 1.7928, Train: 0.9615, Val: 0.5445, Test: 0.5454\n",
            "Epoch: 055, Loss: 1.7925, Train: 0.9499, Val: 0.5411, Test: 0.5418\n",
            "Epoch: 056, Loss: 1.7927, Train: 0.9706, Val: 0.5481, Test: 0.5492\n",
            "Epoch: 057, Loss: 1.7926, Train: 0.9517, Val: 0.5422, Test: 0.5429\n",
            "Epoch: 058, Loss: 1.7923, Train: 0.9602, Val: 0.5451, Test: 0.5461\n",
            "Epoch: 059, Loss: 1.7919, Train: 0.9650, Val: 0.5469, Test: 0.5480\n",
            "Epoch: 060, Loss: 1.7919, Train: 0.9499, Val: 0.5422, Test: 0.5430\n",
            "Epoch: 061, Loss: 1.7919, Train: 0.9686, Val: 0.5485, Test: 0.5496\n",
            "Epoch: 062, Loss: 1.7917, Train: 0.9530, Val: 0.5436, Test: 0.5444\n",
            "Epoch: 063, Loss: 1.7914, Train: 0.9606, Val: 0.5462, Test: 0.5472\n",
            "Epoch: 064, Loss: 1.7911, Train: 0.9624, Val: 0.5469, Test: 0.5480\n",
            "Epoch: 065, Loss: 1.7910, Train: 0.9524, Val: 0.5438, Test: 0.5446\n",
            "Epoch: 066, Loss: 1.7909, Train: 0.9675, Val: 0.5488, Test: 0.5499\n",
            "Epoch: 067, Loss: 1.7908, Train: 0.9508, Val: 0.5434, Test: 0.5442\n",
            "Epoch: 068, Loss: 1.7907, Train: 0.9659, Val: 0.5484, Test: 0.5495\n",
            "Epoch: 069, Loss: 1.7904, Train: 0.9546, Val: 0.5447, Test: 0.5456\n",
            "Epoch: 070, Loss: 1.7901, Train: 0.9609, Val: 0.5468, Test: 0.5478\n",
            "Epoch: 071, Loss: 1.7899, Train: 0.9597, Val: 0.5465, Test: 0.5474\n",
            "Epoch: 072, Loss: 1.7897, Train: 0.9561, Val: 0.5453, Test: 0.5462\n",
            "Epoch: 073, Loss: 1.7895, Train: 0.9638, Val: 0.5479, Test: 0.5489\n",
            "Epoch: 074, Loss: 1.7894, Train: 0.9524, Val: 0.5441, Test: 0.5450\n",
            "Epoch: 075, Loss: 1.7893, Train: 0.9672, Val: 0.5491, Test: 0.5502\n",
            "Epoch: 076, Loss: 1.7891, Train: 0.9485, Val: 0.5429, Test: 0.5437\n",
            "Epoch: 077, Loss: 1.7890, Train: 0.9719, Val: 0.5506, Test: 0.5519\n",
            "Epoch: 078, Loss: 1.7890, Train: 0.9418, Val: 0.5408, Test: 0.5414\n",
            "Epoch: 079, Loss: 1.7892, Train: 0.9814, Val: 0.5538, Test: 0.5552\n",
            "Epoch: 080, Loss: 1.7897, Train: 0.9276, Val: 0.5362, Test: 0.5366\n",
            "Epoch: 081, Loss: 1.7910, Train: 1.0022, Val: 0.5608, Test: 0.5626\n",
            "Epoch: 082, Loss: 1.7937, Train: 0.8973, Val: 0.5267, Test: 0.5266\n",
            "Epoch: 083, Loss: 1.7998, Train: 1.0413, Val: 0.5745, Test: 0.5770\n",
            "Epoch: 084, Loss: 1.8090, Train: 0.8548, Val: 0.5140, Test: 0.5131\n",
            "Epoch: 085, Loss: 1.8229, Train: 1.0624, Val: 0.5824, Test: 0.5854\n",
            "Epoch: 086, Loss: 1.8210, Train: 0.8818, Val: 0.5218, Test: 0.5214\n",
            "Epoch: 087, Loss: 1.8060, Train: 0.9758, Val: 0.5523, Test: 0.5537\n",
            "Epoch: 088, Loss: 1.7872, Train: 1.0044, Val: 0.5625, Test: 0.5646\n",
            "Epoch: 089, Loss: 1.7928, Train: 0.8828, Val: 0.5222, Test: 0.5220\n",
            "Epoch: 090, Loss: 1.8049, Train: 1.0083, Val: 0.5647, Test: 0.5670\n",
            "Epoch: 091, Loss: 1.7936, Train: 0.9661, Val: 0.5503, Test: 0.5517\n",
            "Epoch: 092, Loss: 1.7856, Train: 0.9064, Val: 0.5305, Test: 0.5309\n",
            "Epoch: 093, Loss: 1.7940, Train: 1.0068, Val: 0.5658, Test: 0.5681\n",
            "Epoch: 094, Loss: 1.7924, Train: 0.9520, Val: 0.5468, Test: 0.5481\n",
            "Epoch: 095, Loss: 1.7846, Train: 0.9221, Val: 0.5369, Test: 0.5377\n",
            "Epoch: 096, Loss: 1.7885, Train: 0.9997, Val: 0.5649, Test: 0.5672\n",
            "Epoch: 097, Loss: 1.7896, Train: 0.9474, Val: 0.5465, Test: 0.5478\n",
            "Epoch: 098, Loss: 1.7841, Train: 0.9314, Val: 0.5412, Test: 0.5423\n",
            "Epoch: 099, Loss: 1.7857, Train: 0.9929, Val: 0.5636, Test: 0.5659\n",
            "Epoch: 100, Loss: 1.7871, Train: 0.9469, Val: 0.5472, Test: 0.5486\n",
            "Epoch: 101, Loss: 1.7832, Train: 0.9371, Val: 0.5439, Test: 0.5451\n",
            "Epoch: 102, Loss: 1.7839, Train: 0.9872, Val: 0.5622, Test: 0.5644\n",
            "Epoch: 103, Loss: 1.7849, Train: 0.9481, Val: 0.5481, Test: 0.5496\n",
            "Epoch: 104, Loss: 1.7821, Train: 0.9407, Val: 0.5456, Test: 0.5469\n",
            "Epoch: 105, Loss: 1.7825, Train: 0.9824, Val: 0.5609, Test: 0.5631\n",
            "Epoch: 106, Loss: 1.7832, Train: 0.9492, Val: 0.5489, Test: 0.5505\n",
            "Epoch: 107, Loss: 1.7811, Train: 0.9434, Val: 0.5470, Test: 0.5484\n",
            "Epoch: 108, Loss: 1.7811, Train: 0.9787, Val: 0.5601, Test: 0.5622\n",
            "Epoch: 109, Loss: 1.7816, Train: 0.9486, Val: 0.5491, Test: 0.5506\n",
            "Epoch: 110, Loss: 1.7800, Train: 0.9468, Val: 0.5485, Test: 0.5500\n",
            "Epoch: 111, Loss: 1.7797, Train: 0.9758, Val: 0.5591, Test: 0.5612\n",
            "Epoch: 112, Loss: 1.7801, Train: 0.9465, Val: 0.5483, Test: 0.5499\n",
            "Epoch: 113, Loss: 1.7789, Train: 0.9514, Val: 0.5501, Test: 0.5517\n",
            "Epoch: 114, Loss: 1.7782, Train: 0.9728, Val: 0.5578, Test: 0.5599\n",
            "Epoch: 115, Loss: 1.7785, Train: 0.9443, Val: 0.5473, Test: 0.5488\n",
            "Epoch: 116, Loss: 1.7778, Train: 0.9568, Val: 0.5518, Test: 0.5535\n",
            "Epoch: 117, Loss: 1.7768, Train: 0.9685, Val: 0.5560, Test: 0.5580\n",
            "Epoch: 118, Loss: 1.7768, Train: 0.9427, Val: 0.5465, Test: 0.5480\n",
            "Epoch: 119, Loss: 1.7766, Train: 0.9631, Val: 0.5539, Test: 0.5558\n",
            "Epoch: 120, Loss: 1.7756, Train: 0.9608, Val: 0.5530, Test: 0.5548\n",
            "Epoch: 121, Loss: 1.7750, Train: 0.9445, Val: 0.5469, Test: 0.5485\n",
            "Epoch: 122, Loss: 1.7749, Train: 0.9680, Val: 0.5554, Test: 0.5574\n",
            "Epoch: 123, Loss: 1.7744, Train: 0.9499, Val: 0.5486, Test: 0.5503\n",
            "Epoch: 124, Loss: 1.7735, Train: 0.9540, Val: 0.5500, Test: 0.5517\n",
            "Epoch: 125, Loss: 1.7729, Train: 0.9644, Val: 0.5536, Test: 0.5555\n",
            "Epoch: 126, Loss: 1.7725, Train: 0.9442, Val: 0.5461, Test: 0.5476\n",
            "Epoch: 127, Loss: 1.7722, Train: 0.9664, Val: 0.5540, Test: 0.5559\n",
            "Epoch: 128, Loss: 1.7716, Train: 0.9482, Val: 0.5472, Test: 0.5488\n",
            "Epoch: 129, Loss: 1.7708, Train: 0.9582, Val: 0.5507, Test: 0.5524\n",
            "Epoch: 130, Loss: 1.7700, Train: 0.9565, Val: 0.5499, Test: 0.5516\n",
            "Epoch: 131, Loss: 1.7694, Train: 0.9497, Val: 0.5471, Test: 0.5488\n",
            "Epoch: 132, Loss: 1.7689, Train: 0.9639, Val: 0.5521, Test: 0.5540\n",
            "Epoch: 133, Loss: 1.7685, Train: 0.9416, Val: 0.5437, Test: 0.5452\n",
            "Epoch: 134, Loss: 1.7682, Train: 0.9741, Val: 0.5554, Test: 0.5574\n",
            "Epoch: 135, Loss: 1.7682, Train: 0.9246, Val: 0.5372, Test: 0.5384\n",
            "Epoch: 136, Loss: 1.7693, Train: 1.0030, Val: 0.5657, Test: 0.5683\n",
            "Epoch: 137, Loss: 1.7733, Train: 0.8701, Val: 0.5182, Test: 0.5182\n",
            "Epoch: 138, Loss: 1.7889, Train: 1.0993, Val: 0.6028, Test: 0.6072\n",
            "Epoch: 139, Loss: 1.8317, Train: 0.7246, Val: 0.4736, Test: 0.4709\n",
            "Epoch: 140, Loss: 1.9519, Train: 1.1928, Val: 0.6415, Test: 0.6477\n",
            "Epoch: 141, Loss: 1.9445, Train: 0.8348, Val: 0.5050, Test: 0.5046\n",
            "Epoch: 142, Loss: 1.8171, Train: 0.8679, Val: 0.5148, Test: 0.5151\n",
            "Epoch: 143, Loss: 1.7951, Train: 1.1098, Val: 0.6061, Test: 0.6112\n",
            "Epoch: 144, Loss: 1.8456, Train: 0.9536, Val: 0.5462, Test: 0.5484\n",
            "Epoch: 145, Loss: 1.7702, Train: 0.8320, Val: 0.5042, Test: 0.5041\n",
            "Epoch: 146, Loss: 1.8220, Train: 0.9553, Val: 0.5505, Test: 0.5529\n",
            "Epoch: 147, Loss: 1.7707, Train: 1.0655, Val: 0.5966, Test: 0.6013\n",
            "Epoch: 148, Loss: 1.8097, Train: 0.9590, Val: 0.5566, Test: 0.5593\n",
            "Epoch: 149, Loss: 1.7714, Train: 0.8659, Val: 0.5234, Test: 0.5243\n",
            "Epoch: 150, Loss: 1.7986, Train: 0.9172, Val: 0.5445, Test: 0.5465\n",
            "Epoch: 151, Loss: 1.7767, Train: 1.0190, Val: 0.5865, Test: 0.5905\n",
            "Epoch: 152, Loss: 1.7854, Train: 1.0132, Val: 0.5855, Test: 0.5895\n",
            "Epoch: 153, Loss: 1.7835, Train: 0.9268, Val: 0.5525, Test: 0.5549\n",
            "Epoch: 154, Loss: 1.7755, Train: 0.8899, Val: 0.5391, Test: 0.5407\n",
            "Epoch: 155, Loss: 1.7868, Train: 0.9395, Val: 0.5584, Test: 0.5611\n",
            "Epoch: 156, Loss: 1.7730, Train: 1.0068, Val: 0.5853, Test: 0.5892\n",
            "Epoch: 157, Loss: 1.7801, Train: 0.9955, Val: 0.5808, Test: 0.5845\n",
            "Epoch: 158, Loss: 1.7761, Train: 0.9290, Val: 0.5546, Test: 0.5571\n",
            "Epoch: 159, Loss: 1.7729, Train: 0.9060, Val: 0.5458, Test: 0.5477\n",
            "Epoch: 160, Loss: 1.7784, Train: 0.9511, Val: 0.5632, Test: 0.5661\n",
            "Epoch: 161, Loss: 1.7699, Train: 0.9997, Val: 0.5825, Test: 0.5862\n",
            "Epoch: 162, Loss: 1.7758, Train: 0.9795, Val: 0.5744, Test: 0.5777\n",
            "Epoch: 163, Loss: 1.7710, Train: 0.9272, Val: 0.5538, Test: 0.5561\n",
            "Epoch: 164, Loss: 1.7714, Train: 0.9194, Val: 0.5507, Test: 0.5529\n",
            "Epoch: 165, Loss: 1.7726, Train: 0.9626, Val: 0.5674, Test: 0.5704\n",
            "Epoch: 166, Loss: 1.7682, Train: 0.9917, Val: 0.5788, Test: 0.5824\n",
            "Epoch: 167, Loss: 1.7719, Train: 0.9623, Val: 0.5671, Test: 0.5701\n",
            "Epoch: 168, Loss: 1.7674, Train: 0.9249, Val: 0.5525, Test: 0.5548\n",
            "Epoch: 169, Loss: 1.7698, Train: 0.9355, Val: 0.5565, Test: 0.5589\n",
            "Epoch: 170, Loss: 1.7677, Train: 0.9748, Val: 0.5717, Test: 0.5749\n",
            "Epoch: 171, Loss: 1.7674, Train: 0.9790, Val: 0.5733, Test: 0.5765\n",
            "Epoch: 172, Loss: 1.7676, Train: 0.9434, Val: 0.5593, Test: 0.5618\n",
            "Epoch: 173, Loss: 1.7657, Train: 0.9289, Val: 0.5536, Test: 0.5558\n",
            "Epoch: 174, Loss: 1.7671, Train: 0.9568, Val: 0.5641, Test: 0.5669\n",
            "Epoch: 175, Loss: 1.7646, Train: 0.9783, Val: 0.5722, Test: 0.5753\n",
            "Epoch: 176, Loss: 1.7660, Train: 0.9561, Val: 0.5626, Test: 0.5653\n",
            "Epoch: 177, Loss: 1.7637, Train: 0.9324, Val: 0.5540, Test: 0.5563\n",
            "Epoch: 178, Loss: 1.7649, Train: 0.9483, Val: 0.5632, Test: 0.5658\n",
            "Epoch: 179, Loss: 1.7630, Train: 0.9731, Val: 0.5757, Test: 0.5789\n",
            "Epoch: 180, Loss: 1.7637, Train: 0.9597, Val: 0.5728, Test: 0.5758\n",
            "Epoch: 181, Loss: 1.7622, Train: 0.9360, Val: 0.5655, Test: 0.5681\n",
            "Epoch: 182, Loss: 1.7627, Train: 0.9475, Val: 0.5720, Test: 0.5749\n",
            "Epoch: 183, Loss: 1.7614, Train: 0.9697, Val: 0.5828, Test: 0.5861\n",
            "Epoch: 184, Loss: 1.7617, Train: 0.9569, Val: 0.5791, Test: 0.5822\n",
            "Epoch: 185, Loss: 1.7605, Train: 0.9376, Val: 0.5726, Test: 0.5754\n",
            "Epoch: 186, Loss: 1.7609, Train: 0.9521, Val: 0.5796, Test: 0.5827\n",
            "Epoch: 187, Loss: 1.7597, Train: 0.9673, Val: 0.5867, Test: 0.5902\n",
            "Epoch: 188, Loss: 1.7600, Train: 0.9494, Val: 0.5800, Test: 0.5831\n",
            "Epoch: 189, Loss: 1.7590, Train: 0.9405, Val: 0.5768, Test: 0.5798\n",
            "Epoch: 190, Loss: 1.7591, Train: 0.9602, Val: 0.5852, Test: 0.5885\n",
            "Epoch: 191, Loss: 1.7584, Train: 0.9603, Val: 0.5854, Test: 0.5888\n",
            "Epoch: 192, Loss: 1.7580, Train: 0.9414, Val: 0.5778, Test: 0.5808\n",
            "Epoch: 193, Loss: 1.7579, Train: 0.9509, Val: 0.5817, Test: 0.5848\n",
            "Epoch: 194, Loss: 1.7572, Train: 0.9632, Val: 0.5867, Test: 0.5901\n",
            "Epoch: 195, Loss: 1.7572, Train: 0.9460, Val: 0.5797, Test: 0.5827\n",
            "Epoch: 196, Loss: 1.7567, Train: 0.9464, Val: 0.5798, Test: 0.5828\n",
            "Epoch: 197, Loss: 1.7563, Train: 0.9620, Val: 0.5861, Test: 0.5894\n",
            "Epoch: 198, Loss: 1.7563, Train: 0.9485, Val: 0.5805, Test: 0.5835\n",
            "Epoch: 199, Loss: 1.7557, Train: 0.9457, Val: 0.5793, Test: 0.5822\n",
            "Epoch: 200, Loss: 1.7555, Train: 0.9609, Val: 0.5854, Test: 0.5886\n",
            "Epoch: 201, Loss: 1.7554, Train: 0.9478, Val: 0.5800, Test: 0.5829\n",
            "Epoch: 202, Loss: 1.7549, Train: 0.9476, Val: 0.5798, Test: 0.5827\n",
            "Epoch: 203, Loss: 1.7547, Train: 0.9599, Val: 0.5847, Test: 0.5878\n",
            "Epoch: 204, Loss: 1.7547, Train: 0.9451, Val: 0.5786, Test: 0.5814\n",
            "Epoch: 205, Loss: 1.7544, Train: 0.9522, Val: 0.5813, Test: 0.5843\n",
            "Epoch: 206, Loss: 1.7541, Train: 0.9565, Val: 0.5829, Test: 0.5859\n",
            "Epoch: 207, Loss: 1.7540, Train: 0.9437, Val: 0.5777, Test: 0.5804\n",
            "Epoch: 208, Loss: 1.7539, Train: 0.9582, Val: 0.5835, Test: 0.5865\n",
            "Epoch: 209, Loss: 1.7537, Train: 0.9479, Val: 0.5796, Test: 0.5824\n",
            "Epoch: 210, Loss: 1.7534, Train: 0.9506, Val: 0.5809, Test: 0.5837\n",
            "Epoch: 211, Loss: 1.7532, Train: 0.9557, Val: 0.5833, Test: 0.5862\n",
            "Epoch: 212, Loss: 1.7532, Train: 0.9444, Val: 0.5790, Test: 0.5817\n",
            "Epoch: 213, Loss: 1.7531, Train: 0.9594, Val: 0.5854, Test: 0.5883\n",
            "Epoch: 214, Loss: 1.7531, Train: 0.9423, Val: 0.5787, Test: 0.5813\n",
            "Epoch: 215, Loss: 1.7530, Train: 0.9603, Val: 0.5862, Test: 0.5892\n",
            "Epoch: 216, Loss: 1.7529, Train: 0.9414, Val: 0.5788, Test: 0.5814\n",
            "Epoch: 217, Loss: 1.7529, Train: 0.9621, Val: 0.5874, Test: 0.5904\n",
            "Epoch: 218, Loss: 1.7529, Train: 0.9376, Val: 0.5777, Test: 0.5802\n",
            "Epoch: 219, Loss: 1.7530, Train: 0.9692, Val: 0.5908, Test: 0.5938\n",
            "Epoch: 220, Loss: 1.7534, Train: 0.9251, Val: 0.5731, Test: 0.5754\n",
            "Epoch: 221, Loss: 1.7545, Train: 0.9906, Val: 0.6000, Test: 0.6035\n",
            "Epoch: 222, Loss: 1.7573, Train: 0.8892, Val: 0.5593, Test: 0.5609\n",
            "Epoch: 223, Loss: 1.7649, Train: 1.0490, Val: 0.6250, Test: 0.6295\n",
            "Epoch: 224, Loss: 1.7831, Train: 0.8056, Val: 0.5279, Test: 0.5279\n",
            "Epoch: 225, Loss: 1.8249, Train: 1.1362, Val: 0.6634, Test: 0.6694\n",
            "Epoch: 226, Loss: 1.8615, Train: 0.7871, Val: 0.5223, Test: 0.5220\n",
            "Epoch: 227, Loss: 1.8454, Train: 0.9897, Val: 0.6040, Test: 0.6076\n",
            "Epoch: 228, Loss: 1.7571, Train: 1.0554, Val: 0.6342, Test: 0.6390\n",
            "Epoch: 229, Loss: 1.7879, Train: 0.8488, Val: 0.5491, Test: 0.5502\n",
            "Epoch: 230, Loss: 1.7893, Train: 0.9052, Val: 0.5736, Test: 0.5759\n",
            "Epoch: 231, Loss: 1.7618, Train: 1.0512, Val: 0.6368, Test: 0.6419\n",
            "Epoch: 232, Loss: 1.7871, Train: 0.9683, Val: 0.6069, Test: 0.6107\n",
            "Epoch: 233, Loss: 1.7567, Train: 0.8713, Val: 0.5697, Test: 0.5717\n",
            "Epoch: 234, Loss: 1.7787, Train: 0.9218, Val: 0.5934, Test: 0.5965\n",
            "Epoch: 235, Loss: 1.7602, Train: 1.0177, Val: 0.6370, Test: 0.6419\n",
            "Epoch: 236, Loss: 1.7708, Train: 0.9974, Val: 0.6281, Test: 0.6327\n",
            "Epoch: 237, Loss: 1.7641, Train: 0.9135, Val: 0.5905, Test: 0.5935\n",
            "Epoch: 238, Loss: 1.7632, Train: 0.8970, Val: 0.5833, Test: 0.5860\n",
            "Epoch: 239, Loss: 1.7687, Train: 0.9597, Val: 0.6115, Test: 0.6154\n",
            "Epoch: 240, Loss: 1.7585, Train: 1.0081, Val: 0.6338, Test: 0.6385\n",
            "Epoch: 241, Loss: 1.7682, Train: 0.9706, Val: 0.6167, Test: 0.6208\n",
            "Epoch: 242, Loss: 1.7594, Train: 0.9137, Val: 0.5912, Test: 0.5942\n",
            "Epoch: 243, Loss: 1.7636, Train: 0.9167, Val: 0.5926, Test: 0.5957\n",
            "Epoch: 244, Loss: 1.7627, Train: 0.9701, Val: 0.6165, Test: 0.6206\n",
            "Epoch: 245, Loss: 1.7589, Train: 0.9965, Val: 0.6280, Test: 0.6325\n",
            "Epoch: 246, Loss: 1.7637, Train: 0.9550, Val: 0.6093, Test: 0.6131\n",
            "Epoch: 247, Loss: 1.7575, Train: 0.9164, Val: 0.5919, Test: 0.5950\n",
            "Epoch: 248, Loss: 1.7616, Train: 0.9371, Val: 0.5996, Test: 0.6031\n",
            "Epoch: 249, Loss: 1.7577, Train: 0.9830, Val: 0.6174, Test: 0.6217\n",
            "Epoch: 250, Loss: 1.7597, Train: 0.9737, Val: 0.6126, Test: 0.6167\n",
            "Epoch: 251, Loss: 1.7580, Train: 0.9299, Val: 0.5939, Test: 0.5972\n",
            "Epoch: 252, Loss: 1.7580, Train: 0.9276, Val: 0.5923, Test: 0.5955\n",
            "Epoch: 253, Loss: 1.7582, Train: 0.9670, Val: 0.6076, Test: 0.6116\n",
            "Epoch: 254, Loss: 1.7566, Train: 0.9780, Val: 0.6115, Test: 0.6156\n",
            "Epoch: 255, Loss: 1.7578, Train: 0.9430, Val: 0.5968, Test: 0.6003\n",
            "Epoch: 256, Loss: 1.7557, Train: 0.9276, Val: 0.5901, Test: 0.5933\n",
            "Epoch: 257, Loss: 1.7572, Train: 0.9566, Val: 0.6013, Test: 0.6050\n",
            "Epoch: 258, Loss: 1.7550, Train: 0.9753, Val: 0.6085, Test: 0.6124\n",
            "Epoch: 259, Loss: 1.7565, Train: 0.9494, Val: 0.5976, Test: 0.6011\n",
            "Epoch: 260, Loss: 1.7545, Train: 0.9307, Val: 0.5897, Test: 0.5928\n",
            "Epoch: 261, Loss: 1.7557, Train: 0.9530, Val: 0.5983, Test: 0.6018\n",
            "Epoch: 262, Loss: 1.7540, Train: 0.9713, Val: 0.6052, Test: 0.6090\n",
            "Epoch: 263, Loss: 1.7550, Train: 0.9496, Val: 0.5960, Test: 0.5994\n",
            "Epoch: 264, Loss: 1.7536, Train: 0.9340, Val: 0.5894, Test: 0.5925\n",
            "Epoch: 265, Loss: 1.7544, Train: 0.9549, Val: 0.5972, Test: 0.6007\n",
            "Epoch: 266, Loss: 1.7531, Train: 0.9673, Val: 0.6016, Test: 0.6053\n",
            "Epoch: 267, Loss: 1.7537, Train: 0.9456, Val: 0.5923, Test: 0.5955\n",
            "Epoch: 268, Loss: 1.7528, Train: 0.9381, Val: 0.5886, Test: 0.5917\n",
            "Epoch: 269, Loss: 1.7531, Train: 0.9596, Val: 0.5964, Test: 0.5998\n",
            "Epoch: 270, Loss: 1.7525, Train: 0.9610, Val: 0.5961, Test: 0.5995\n",
            "Epoch: 271, Loss: 1.7524, Train: 0.9404, Val: 0.5870, Test: 0.5900\n",
            "Epoch: 272, Loss: 1.7523, Train: 0.9458, Val: 0.5881, Test: 0.5912\n",
            "Epoch: 273, Loss: 1.7518, Train: 0.9627, Val: 0.5937, Test: 0.5970\n",
            "Epoch: 274, Loss: 1.7520, Train: 0.9501, Val: 0.5872, Test: 0.5903\n",
            "Epoch: 275, Loss: 1.7514, Train: 0.9401, Val: 0.5821, Test: 0.5850\n",
            "Epoch: 276, Loss: 1.7516, Train: 0.9573, Val: 0.5883, Test: 0.5914\n",
            "Epoch: 277, Loss: 1.7512, Train: 0.9560, Val: 0.5868, Test: 0.5900\n",
            "Epoch: 278, Loss: 1.7511, Train: 0.9404, Val: 0.5797, Test: 0.5825\n",
            "Epoch: 279, Loss: 1.7512, Train: 0.9541, Val: 0.5846, Test: 0.5877\n",
            "Epoch: 280, Loss: 1.7508, Train: 0.9575, Val: 0.5854, Test: 0.5885\n",
            "Epoch: 281, Loss: 1.7509, Train: 0.9419, Val: 0.5785, Test: 0.5813\n",
            "Epoch: 282, Loss: 1.7510, Train: 0.9530, Val: 0.5826, Test: 0.5855\n",
            "Epoch: 283, Loss: 1.7507, Train: 0.9569, Val: 0.5837, Test: 0.5867\n",
            "Epoch: 284, Loss: 1.7508, Train: 0.9428, Val: 0.5777, Test: 0.5804\n",
            "Epoch: 285, Loss: 1.7508, Train: 0.9532, Val: 0.5816, Test: 0.5845\n",
            "Epoch: 286, Loss: 1.7506, Train: 0.9554, Val: 0.5821, Test: 0.5851\n",
            "Epoch: 287, Loss: 1.7506, Train: 0.9436, Val: 0.5771, Test: 0.5798\n",
            "Epoch: 288, Loss: 1.7507, Train: 0.9542, Val: 0.5812, Test: 0.5841\n",
            "Epoch: 289, Loss: 1.7505, Train: 0.9534, Val: 0.5806, Test: 0.5835\n",
            "Epoch: 290, Loss: 1.7504, Train: 0.9446, Val: 0.5769, Test: 0.5796\n",
            "Epoch: 291, Loss: 1.7505, Train: 0.9553, Val: 0.5811, Test: 0.5840\n",
            "Epoch: 292, Loss: 1.7504, Train: 0.9510, Val: 0.5792, Test: 0.5820\n",
            "Epoch: 293, Loss: 1.7503, Train: 0.9463, Val: 0.5772, Test: 0.5799\n",
            "Epoch: 294, Loss: 1.7503, Train: 0.9557, Val: 0.5809, Test: 0.5837\n",
            "Epoch: 295, Loss: 1.7503, Train: 0.9487, Val: 0.5780, Test: 0.5807\n",
            "Epoch: 296, Loss: 1.7502, Train: 0.9485, Val: 0.5779, Test: 0.5806\n",
            "Epoch: 297, Loss: 1.7501, Train: 0.9551, Val: 0.5804, Test: 0.5832\n",
            "Epoch: 298, Loss: 1.7501, Train: 0.9472, Val: 0.5773, Test: 0.5799\n",
            "Epoch: 299, Loss: 1.7501, Train: 0.9509, Val: 0.5787, Test: 0.5814\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0, 300):\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    test_rmse = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joyCx1zCnzl2",
        "outputId": "0c9e3fd0-6b49-451c-bb72-661c5d556b76"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SxYona145IU",
        "outputId": "de2fa76d-ad96-4a5a-f13b-a385f1942914"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208170,\n",
              "    x=[208170, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127728, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.encoder(data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbPqjTSINEG",
        "outputId": "1e79c7fe-7e41-4e4d-afc2-67fb145a4cbe"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[-9.7412e-01,  2.4478e+00,  2.3534e-01,  ..., -4.6157e-01,\n",
              "          -6.2345e-01,  4.3177e-01],\n",
              "         [-9.3550e-01,  2.2810e+00, -9.0241e-02,  ..., -6.0263e-01,\n",
              "          -6.2245e-01,  4.3918e-01],\n",
              "         [-9.8137e-01,  2.4772e+00,  2.7850e-02,  ..., -6.1465e-01,\n",
              "          -6.0377e-01,  4.9269e-01],\n",
              "         ...,\n",
              "         [-9.4631e-01,  2.3232e+00, -2.6920e-03,  ..., -6.7439e-01,\n",
              "          -6.0488e-01,  4.4904e-01],\n",
              "         [-1.0267e+00,  2.3541e+00,  5.4554e-02,  ..., -5.5205e-01,\n",
              "          -5.4983e-01,  5.0213e-01],\n",
              "         [-1.3512e+00,  2.7143e+00,  2.5843e-01,  ..., -5.5363e-01,\n",
              "          -7.9118e-01,  5.5559e-01]], grad_fn=<AddBackward0>),\n",
              " 'aid': tensor([[-1.1588, -0.2248,  0.1874,  ...,  2.2923, -0.3588,  1.6453],\n",
              "         [-1.0812, -0.1628,  0.0266,  ...,  2.3042, -0.3995,  1.6671],\n",
              "         [-1.0300, -0.0753,  0.0894,  ...,  2.2286, -0.4006,  1.6088],\n",
              "         ...,\n",
              "         [-1.0446, -0.2571, -0.0177,  ...,  2.5165, -0.5805,  1.7302],\n",
              "         [-1.1200, -0.2939,  0.1455,  ...,  2.2645, -0.4501,  1.6233],\n",
              "         [-0.9348, -0.0701,  0.1697,  ...,  2.2275, -0.4806,  1.5302]],\n",
              "        grad_fn=<AddBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test dataset"
      ],
      "metadata": {
        "id": "WLHyzIiNECx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_parquet('/content/kaggle/test.parquet')"
      ],
      "metadata": {
        "id": "WDkdfZnxEB02"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.sample(frac=0.01, replace=False)"
      ],
      "metadata": {
        "id": "AkgwhJjiIyAm"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "Q4LGeBz9EPjh",
        "outputId": "4d9ad5ba-c1c9-4831-f29f-84075fea3b60"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          session      aid          ts  type\n",
              "5465461  14190516   976033  1662203664     0\n",
              "1438664  13217943   265219  1661860240     0\n",
              "4078581  13850857  1374621  1662058660     0\n",
              "3272684  13655975  1777026  1661970824     0\n",
              "357851   12972164   644558  1661768631     1\n",
              "...           ...      ...         ...   ...\n",
              "5580349  14218711  1477811  1662210929     0\n",
              "366675   12974024  1748111  1661768243     0\n",
              "962819   13108220   386901  1661797473     0\n",
              "1797244  13302176   439795  1661865215     0\n",
              "4858905  14043271  1842689  1662131599     0\n",
              "\n",
              "[69281 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-292674b2-ed40-4ca8-8759-e99299f0b090\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5465461</th>\n",
              "      <td>14190516</td>\n",
              "      <td>976033</td>\n",
              "      <td>1662203664</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1438664</th>\n",
              "      <td>13217943</td>\n",
              "      <td>265219</td>\n",
              "      <td>1661860240</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4078581</th>\n",
              "      <td>13850857</td>\n",
              "      <td>1374621</td>\n",
              "      <td>1662058660</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3272684</th>\n",
              "      <td>13655975</td>\n",
              "      <td>1777026</td>\n",
              "      <td>1661970824</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357851</th>\n",
              "      <td>12972164</td>\n",
              "      <td>644558</td>\n",
              "      <td>1661768631</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5580349</th>\n",
              "      <td>14218711</td>\n",
              "      <td>1477811</td>\n",
              "      <td>1662210929</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366675</th>\n",
              "      <td>12974024</td>\n",
              "      <td>1748111</td>\n",
              "      <td>1661768243</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962819</th>\n",
              "      <td>13108220</td>\n",
              "      <td>386901</td>\n",
              "      <td>1661797473</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1797244</th>\n",
              "      <td>13302176</td>\n",
              "      <td>439795</td>\n",
              "      <td>1661865215</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4858905</th>\n",
              "      <td>14043271</td>\n",
              "      <td>1842689</td>\n",
              "      <td>1662131599</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>69281 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-292674b2-ed40-4ca8-8759-e99299f0b090')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-292674b2-ed40-4ca8-8759-e99299f0b090 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-292674b2-ed40-4ca8-8759-e99299f0b090');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct heterogenous graph for test"
      ],
      "metadata": {
        "id": "iY12RhftEWwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}"
      ],
      "metadata": {
        "id": "VQwWWWsnEfli"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BITDjJKVEwpq",
        "outputId": "113dd147-3284-4d77-a6f9-0281cf1babc1"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-61-fdbbf2e7eb54>:2: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "<ipython-input-61-fdbbf2e7eb54>:3: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values)).type(torch.int64)"
      ],
      "metadata": {
        "id": "WZjCOHTlE0Xf"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ],
      "metadata": {
        "id": "7RH8e4VtE39m"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label,\n",
        "        'edge_label_index': edge_index\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ],
      "metadata": {
        "id": "uwJLoByFFATA"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rtest_data = HeteroData({**node_types, **edge_types})"
      ],
      "metadata": {
        "id": "UY3tqA4HFG3u"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OnPMRj27FwbQ",
        "outputId": "d02b166b-f2ca-4c9f-aed9-c382ede48c3b"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208170,\n",
              "    x=[208170, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127728, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rtest_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vC_MYbqNFK_s",
        "outputId": "ecae3b84-f97c-499a-8ffb-8704ff418665"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ num_nodes=63734 },\n",
              "  \u001b[1maid\u001b[0m={ x=[49176, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 69281],\n",
              "    edge_label=[69281],\n",
              "    edge_label_index=[2, 69281]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# add sesion features for message passing:\n",
        "Rtest_data['session'].x = torch.rand(Rtest_data['session'].num_nodes, 300)\n",
        "\n",
        "Rtest_data = T.ToUndirected()(Rtest_data)\n",
        "del Rtest_data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ],
      "metadata": {
        "id": "0ktGWQnnIPbL"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Rtest_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb6N2GaqNj_e",
        "outputId": "40cfcb5f-2b63-495a-cdee-5638394d0c9f"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=63734,\n",
              "    x=[63734, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[49176, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 69281],\n",
              "    edge_label=[69281],\n",
              "    edge_label_index=[2, 69281]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 69281] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "1serMeUuEf8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    gg = model(Rtest_data.x_dict, Rtest_data.edge_index_dict, Rtest_data['session', 'aid'].edge_label_index)"
      ],
      "metadata": {
        "id": "FsVoiBSqLsrR"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eUS0_0PjKKY",
        "outputId": "d9f388ec-1c6a-4a6d-d039-19d282713dc4"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Rtest_data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RilROrFHN-xZ",
        "outputId": "dece2a65-ae9d-46a3-b269-57da00b0b187"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW4XhiQHhf7f",
        "outputId": "d40d072f-2eed-4aa2-94dc-6d5900a42ae2"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7743, 1.0169, 0.9359,  ..., 1.2656, 1.1711, 0.8962])"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRQNaMN8fSz8",
        "outputId": "282832ef-4769-43fb-8316-349250ad13a8"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208170,\n",
              "    x=[208170, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127728, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHNbZyHebUPV"
      },
      "source": [
        "# [TEMPORARY DROP]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "2NTRQjhLACfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "d5f5702d-7aae-4133-821b-05e73ae52f91"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass GNNEncoder(torch.nn.Module):\\n    def __init__(self, hidden_channels, out_channels, conv):\\n        super().__init__()\\n        # conv(#in_channels, #out_channels)\\n        \\n        in_channels (int or tuple): \\n            Size of each input sample, or :obj:`-1` to\\n            derive the size from the first input(s) to the forward method.\\n            A tuple corresponds to the sizes of source and target\\n            dimensionalities.\\n        \\n        self.conv1 = conv((-1, -1), hidden_channels)\\n        self.conv2 = conv((-1, -1), out_channels)\\n        self.linear1 = Linear(-1, out_channels)\\n        self.linear2 = Linear(-1, out_channels)\\n\\n    def forward(self, x, edge_index):\\n        x0 = self.linear1(x)\\n        x2 = self.conv1(x0, edge_index).relu()\\n        x3 = self.conv2(x2, edge_index)\\n        x4 = self.linear2(x2 + x3)\\n        # Add combined layer to reduce over-smoothing\\n        return x4\\n\\nclass EdgeDecoder(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\\n        self.lin2 = Linear(hidden_channels, 1)\\n\\n    def forward(self, z_dict, edge_label_index):\\n        row, col = edge_label_index\\n        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\\n        z = self.lin1(z).relu()\\n        z = self.lin2(z)\\n        return z.view(-1)\\n\\nclass Model(torch.nn.Module):\\n    def __init__(self, hidden_channels,  conv=SAGEConv):\\n        super().__init__()\\n        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\\n        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\\n\\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\\n        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\\n        return self.decoder(z_dict, edge_label_index)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 75
        }
      ],
      "source": [
        "# Temporary comment\n",
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, conv):\n",
        "        super().__init__()\n",
        "        # conv(#in_channels, #out_channels)\n",
        "        ''''''\n",
        "        in_channels (int or tuple): \n",
        "            Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        ''''''\n",
        "        self.conv1 = conv((-1, -1), hidden_channels)\n",
        "        self.conv2 = conv((-1, -1), out_channels)\n",
        "        self.linear1 = Linear(-1, out_channels)\n",
        "        self.linear2 = Linear(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x0 = self.linear1(x)\n",
        "        x2 = self.conv1(x0, edge_index).relu()\n",
        "        x3 = self.conv2(x2, edge_index)\n",
        "        x4 = self.linear2(x2 + x3)\n",
        "        # Add combined layer to reduce over-smoothing\n",
        "        return x4\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,  conv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "JsSAc0seAHmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8ed310ad-7656-4f01-d76f-188a340284bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train(train_data, model, optimizer, loss=weighted_mse_loss):\\n    model.train()\\n    optimizer.zero_grad()\\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\\n                 train_data['session', 'aid'].edge_label_index)\\n    target = train_data['session', 'aid'].edge_label\\n    loss = weighted_mse_loss(pred, target, weight)\\n    loss.backward()\\n    optimizer.step()\\n    return float(loss.sqrt())\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 76
        }
      ],
      "source": [
        "'''\n",
        "def train(train_data, model, optimizer, loss=weighted_mse_loss):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.sqrt())\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "qxHfcosNAXQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "10abd4b4-d804-4054-fcff-43f3b719a2f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef test(data, model, metric=F.mse_loss):\\n    model.eval()\\n    pred = model(data.x_dict, data.edge_index_dict,\\n                 data['session', 'aid'].edge_label_index)\\n    pred = pred.clamp(min=0, max=2)\\n    target = data['session', 'aid'].edge_label.float()\\n    rmse = F.mse_loss(pred, target).sqrt()\\n    return float(rmse) # Return RMSE loss\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "## set pred.clamp\n",
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data, model, metric=F.mse_loss):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse) # Return RMSE loss\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "PE1pmW4KAXpe"
      },
      "outputs": [],
      "source": [
        "#from tqdm import tqdm\n",
        "#from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "M2Mc3SOUAiui",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "14c29b33-8cc0-4d16-847d-f5718df17d63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\\n    t0 = time.time()\\n\\n    model = model(**model_params) # Define the model\\n\\n    # Due to lazy initialization, we need to run one model step so the number\\n    # of parameters can be inferred:\\n    with torch.no_grad():\\n        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\\n\\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n\\n    k=0\\n    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\\n    train_wrmse, val_wrmse, test_wrmse = [], [], []\\n    for epoch in tqdm(range(n_epochs)):\\n        # Call train fuction here >> return loss\\n        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\\n        \\n        # Call test function here >> return RMSE loss\\n        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\\n        train_rmse += [test(train_data, model, metric=F.mse_loss)]\\n        \\n        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\\n        val_rmse += [test(val_data, model, metric=F.mse_loss)]\\n        \\n        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\\n        test_rmse += [test(test_data, model, metric=F.mse_loss)]\\n\\n        if epoch+1 %10==0:\\n            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\\n                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\\n\\n        results = pd.DataFrame({\\n            'loss': loss,\\n            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\\n            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\\n            'time':(time.time()-t0)/60\\n        })\\n        \\n        ## Debugging\\n        #clear_output()\\n        '''\\n        print('\\nloss: ', loss, \\n              '\\ntrain_rmse: ', train_rmse, \\n              '\\nval_rmse: ', val_rmse, \\n              '\\ntest_rmse: ', test_rmse,\\n              '\\ntrain_wrmse: ', train_wrmse, \\n              '\\nval_wrmse: ', val_wrmse, \\n              '\\ntest_wrmse: ', test_wrmse,\\n              '\\ntime: ', (time.time()-t0)/60)\\n        '''\\n        #visualize_loss(results, metric='wrmse').show()\\n        #print(results.to_string())\\n\\n        # enable early stopping\\n        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\\n            k += 1\\n        if k> e_patience:\\n            print('Early stopping')\\n            break\\n\\n    return results, model\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "\"\"\"\n",
        "def train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\n",
        "    t0 = time.time()\n",
        "\n",
        "    model = model(**model_params) # Define the model\n",
        "\n",
        "    # Due to lazy initialization, we need to run one model step so the number\n",
        "    # of parameters can be inferred:\n",
        "    with torch.no_grad():\n",
        "        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    k=0\n",
        "    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\n",
        "    train_wrmse, val_wrmse, test_wrmse = [], [], []\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        # Call train fuction here >> return loss\n",
        "        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\n",
        "        \n",
        "        # Call test function here >> return RMSE loss\n",
        "        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\n",
        "        train_rmse += [test(train_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\n",
        "        val_rmse += [test(val_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\n",
        "        test_rmse += [test(test_data, model, metric=F.mse_loss)]\n",
        "\n",
        "        if epoch+1 %10==0:\n",
        "            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\n",
        "                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'loss': loss,\n",
        "            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\n",
        "            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\n",
        "            'time':(time.time()-t0)/60\n",
        "        })\n",
        "        \n",
        "        ## Debugging\n",
        "        #clear_output()\n",
        "        '''\n",
        "        print('\\nloss: ', loss, \n",
        "              '\\ntrain_rmse: ', train_rmse, \n",
        "              '\\nval_rmse: ', val_rmse, \n",
        "              '\\ntest_rmse: ', test_rmse,\n",
        "              '\\ntrain_wrmse: ', train_wrmse, \n",
        "              '\\nval_wrmse: ', val_wrmse, \n",
        "              '\\ntest_wrmse: ', test_wrmse,\n",
        "              '\\ntime: ', (time.time()-t0)/60)\n",
        "        '''\n",
        "        #visualize_loss(results, metric='wrmse').show()\n",
        "        #print(results.to_string())\n",
        "\n",
        "        # enable early stopping\n",
        "        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\n",
        "            k += 1\n",
        "        if k> e_patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "\n",
        "    return results, model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "8edkAihHAmP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c17e996c-d905-4612-9430-a2c1d89aa6de"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef visualize_loss(results, metric=\\'rmse\\'):\\n    fig = go.Figure()\\n\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'train_\\'+metric], name = \\'train_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'val_\\'+metric], name = \\'val_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'test_\\'+metric], name = \\'test_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'loss\\'], name = \\'loss\\'))\\n\\n    fig.update_yaxes(title_text=metric.upper())\\n    fig.update_xaxes(title_text=\"Epoch\")\\n\\n    return fig\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "'''\n",
        "def visualize_loss(results, metric='rmse'):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['train_'+metric], name = 'train_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['val_'+metric], name = 'val_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['test_'+metric], name = 'test_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['loss'], name = 'loss'))\n",
        "\n",
        "    fig.update_yaxes(title_text=metric.upper())\n",
        "    fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "    return fig\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bQElhxOkAn_q",
        "outputId": "1e97b54d-b9dc-47dd-8dee-e7253b3f3f19"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nN_EPOCHS = 300\\nE_PATIENCE = 50\\nLEARNING_RATE = 0.01\\n\\nmodel_params = {\"hidden_channels\":32, \\'conv\\':SAGEConv}\\n\\nresults, trained_model = train_test(\\n    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "'''\n",
        "N_EPOCHS = 300\n",
        "E_PATIENCE = 50\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "model_params = {\"hidden_channels\":32, 'conv':SAGEConv}\n",
        "\n",
        "results, trained_model = train_test(\n",
        "    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "j58QMqIdUcfc"
      },
      "outputs": [],
      "source": [
        "#visualize_loss(results, metric='wrmse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "EUHSNzLmBEYx"
      },
      "outputs": [],
      "source": [
        "#trained_model.encoder(test_data.x_dict, test_data.edge_index_dict)['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "PtRs2Bw7kfOP"
      },
      "outputs": [],
      "source": [
        "#trained_model.state_dict()['encoder.linear2.session.weight']"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HKBFpzXHtgJ"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation"
      ],
      "metadata": {
        "id": "aED_TAobTF6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def recommendation(user_id, model, x_dict, edge_index_dict):\n",
        "  # Get model decoder\n",
        "  #model = Model(**model_params)\n",
        "  with torch.no_grad():\n",
        "    encoder = model.encoder(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "  # Get node representations for users and movies\n",
        "  user_representations = encoder['session']\n",
        "  movie_representations = encoder['aid']\n",
        "\n",
        "  # Compute the dot product between user and movie representations to get edge weights\n",
        "  edge_weights = user_representations.mm(movie_representations.T)\n",
        "\n",
        "  # Make predictions for each user by taking the top k largest edge weights\n",
        "  k = 20  # number of recommendations to make\n",
        "  _, top_k_indices = edge_weights.topk(k, dim=1)\n",
        "  recommendations = top_k_indices.numpy()\n",
        "\n",
        "  # Print recommendations for the first user\n",
        "  print(f'Recommendations for user {user_id}: {recommendations[user_id]}')"
      ],
      "metadata": {
        "id": "9IbcT22JTIFr"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 1\n",
        "#recommendation(session, model, Rtest_data.x_dict, Rtest_data.edge_index_dict)"
      ],
      "metadata": {
        "id": "WP1SufyhTURW"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 2\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "VFmAIGENUV9F"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 999\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "4H4tCDOyUcVI"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "uZw_TNkMQRaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission File\n",
        "For each `session` id and `type` combination in the test set, you must predict the `aid` values in the `label` column, which is space delimited. You can predict up to 20 `aid` values per row. The file should contain a header and have the following format:\n",
        "\n",
        "```\n",
        "session_type,labels\n",
        "12906577_clicks,135193 129431 119318 ...\n",
        "12906577_carts,135193 129431 119318 ...\n",
        "12906577_orders,135193 129431 119318 ...\n",
        "12906578_clicks, 135193 129431 119318 ...\n",
        "etc.\n",
        "```"
      ],
      "metadata": {
        "id": "DFOSPOfhOjYr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWyo1qVmOi8E"
      },
      "execution_count": 88,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FriR71pK-hxH",
        "pqgOrM6ak915",
        "fUkcZdZr8seK",
        "VKqQxQA0-X44",
        "XHNbZyHebUPV"
      ],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOVHKcyn4VugZ82ypG5sG8c",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
