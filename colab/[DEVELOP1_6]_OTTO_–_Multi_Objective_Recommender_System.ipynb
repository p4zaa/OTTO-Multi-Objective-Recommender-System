{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p4zaa/OTTO-Multi-Objective-Recommender-System/blob/main/%5BDEVELOP1_6%5D_OTTO_%E2%80%93_Multi_Objective_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf2nIQqrAy8y"
      },
      "source": [
        "# Version Logs\n",
        "* [View in my Github](https://github.com/p4zaa/OTTO-Multi-Objective-Recommender-System)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTgGyHWwP0wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e22cf374-3738-499e-981e-98d152d4ba99"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.4 MB 2.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.5 MB 2.7 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3.2 MB 2.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 873 kB 2.6 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 564 kB 5.5 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 280 kB 44.1 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YGBdYwXz-B9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a545b3e4-cf8a-4926-c8ad-b122edb75e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 85 kB 2.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5.8 MB 9.8 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.3 MB 45.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 182 kB 64.9 MB/s \n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 7.6 MB 52.8 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "import tqdm\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.loader import HGTLoader, NeighborLoader, LinkNeighborLoader\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97P3ABJvXkB_",
        "outputId": "a0b96902-c27c-438d-ea2c-6730dad5cb3a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting polars\n",
            "  Downloading polars-0.15.11-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.6 MB)\n",
            "\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 14.6 MB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from polars) (4.4.0)\n",
            "Installing collected packages: polars\n",
            "Successfully installed polars-0.15.11\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -q torch torchvision torchaudio\n",
        "!pip install -U polars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "17ePRXhpuuFE"
      },
      "outputs": [],
      "source": [
        "import polars as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0nqQodKXs7R",
        "outputId": "ecb2aa7a-0ee0-40f1-c47c-cacc0402be9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch CUDA Version is  11.6\n"
          ]
        }
      ],
      "source": [
        "print('Pytorch CUDA Version is ', torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mwEe6Wxor7uB"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlaViVcbYSGa",
        "outputId": "8a342dda-2945-493d-c629-5045ac09feb6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eLnmtjpYCtk",
        "outputId": "64157c0e-c186-46f1-b82c-7b6297f7cea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pa5S-Yu9b4OL"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "j7Gsb6xQ98eL",
        "outputId": "8ab14957-4550-47f5-dc78-9a2b2840e8f5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-fbc28b13-37d8-4cb4-8e70-0e1cd4c965ea\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-fbc28b13-37d8-4cb4-8e70-0e1cd4c965ea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "ref                                                           title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                     COVID-19 Dataset                                     5MB  2022-11-13 15:47:17          14954        424  1.0              \n",
            "devrimtuner/list-of-moststreamed-songs-on-spotify             Top 100 Spotify Songsüëëüé§üéßüéº                            3KB  2022-12-30 05:42:54            332         26  1.0              \n",
            "thedevastator/analyzing-credit-card-spending-habits-in-india  Credit Card Spending Habits in India               319KB  2022-12-14 07:30:37           1522         52  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset            Fifa World Cup 2022: Complete Dataset                7KB  2022-12-18 22:51:11           3146        112  1.0              \n",
            "michals22/coffee-dataset                                      Coffee dataset                                      24KB  2022-12-15 20:02:12           3640         83  1.0              \n",
            "heemalichaudhari/netflix-movies-and-series                    Netflix Movies and Series                            2MB  2022-12-22 13:34:22           1029         30  0.8235294        \n",
            "sejungjenn/spotify-best-songs-of-2022                         Spotify: Winner Tracks Audio Featuresüéπ              38KB  2022-12-28 08:06:49            264         21  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data       E-Commerce Sales Dataset                             6MB  2022-12-03 09:27:17           2893         72  1.0              \n",
            "aklimarimi/qs-world-ranked-universities-20182022              QS World ranked Universities (2018-2022)            51KB  2022-12-28 03:53:39            480         28  1.0              \n",
            "rajeshrampure/black-friday-sale                               Black Friday Sale                                    5MB  2022-12-24 09:37:49            845         28  1.0              \n",
            "devrimtuner/highestpaid-athletes                              HIGHEST-PAID ATHLETES‚öΩÔ∏èüèÄüèà‚öæÔ∏èü•éüéæ                        1KB  2022-12-29 01:29:51            269         25  1.0              \n",
            "heemalichaudhari/shopping                                     Shopping                                            12KB  2022-12-26 14:25:07            367         22  0.9411765        \n",
            "milanvaddoriya/old-car-price-prediction                       Old car price prediction                           105KB  2022-12-24 15:38:56            375         29  1.0              \n",
            "thedevastator/how-does-daily-yoga-impact-screen-time-habits   How Does Daily Yoga Impact Screen Time Habits       742B  2022-12-14 04:10:56            592         21  1.0              \n",
            "thedevastator/uncovering-factors-that-affect-used-car-prices  Used Cars                                           18MB  2022-12-06 13:36:08           1027         31  1.0              \n",
            "devrimtuner/list-of-mostfollowed-instagram-accounts           (TOP 50)List of most-followed Instagram accountsüëë    2KB  2022-12-30 07:52:00            313         25  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                     Salary Prediction                                    3MB  2022-11-16 13:52:31           8349        178  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                         Melbourne Housing Snapshot                         451KB  2018-06-05 12:52:24         103265       1188  0.7058824        \n",
            "mattop/best-selling-game-boy-video-games                      Best Selling Game Boy Video Games                    2KB  2022-12-17 18:41:38            369         27  0.9705882        \n",
            "rajeshrampure/zomato-dataset                                  Zomato Dataset                                      89MB  2022-12-23 07:38:07            513         28  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "421Djk4r4qJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d85d3168-0d4a-47ce-e907-78adc41f3711"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading otto-full-optimized-memory-footprint.zip to /content/kaggle\n",
            " 99% 1.07G/1.09G [00:05<00:00, 195MB/s]\n",
            "100% 1.09G/1.09G [00:05<00:00, 197MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "# Pandas\n",
        "#df = pd.read_parquet('/content/kaggle/train.parquet')\n",
        "\n",
        "# Polars\n",
        "df = pl.read_parquet('/content/kaggle/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "#df = df.sample(frac=0.01, replace=False)\n",
        "\n",
        "# Polars\n",
        "df = df.sample(frac=0.005)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-Q_j2wx7Omc"
      },
      "outputs": [],
      "source": [
        "df = df.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "cdB8Tum90sZX",
        "outputId": "08cd311c-3e53-4e14-fb76-d29f54d35fe3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         session      aid          ts  type\n",
              "0        1501601   635864  1659443915     0\n",
              "1         644159   396198  1660569107     0\n",
              "2        7936838  1116026  1660412341     0\n",
              "3        7560153  1672263  1660337516     0\n",
              "4        3424360  1076444  1660928522     0\n",
              "...          ...      ...         ...   ...\n",
              "1083575   553176  1259905  1660404960     0\n",
              "1083576   387336  1449938  1661648656     0\n",
              "1083577  9147729   491706  1660624426     0\n",
              "1083578  1569592  1017009  1660042861     0\n",
              "1083579  6017748  1216403  1660056795     1\n",
              "\n",
              "[1083580 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75442237-f9c5-4cb8-8cbe-5c972536d99e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1501601</td>\n",
              "      <td>635864</td>\n",
              "      <td>1659443915</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>644159</td>\n",
              "      <td>396198</td>\n",
              "      <td>1660569107</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7936838</td>\n",
              "      <td>1116026</td>\n",
              "      <td>1660412341</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7560153</td>\n",
              "      <td>1672263</td>\n",
              "      <td>1660337516</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3424360</td>\n",
              "      <td>1076444</td>\n",
              "      <td>1660928522</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083575</th>\n",
              "      <td>553176</td>\n",
              "      <td>1259905</td>\n",
              "      <td>1660404960</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083576</th>\n",
              "      <td>387336</td>\n",
              "      <td>1449938</td>\n",
              "      <td>1661648656</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083577</th>\n",
              "      <td>9147729</td>\n",
              "      <td>491706</td>\n",
              "      <td>1660624426</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083578</th>\n",
              "      <td>1569592</td>\n",
              "      <td>1017009</td>\n",
              "      <td>1660042861</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1083579</th>\n",
              "      <td>6017748</td>\n",
              "      <td>1216403</td>\n",
              "      <td>1660056795</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1083580 rows √ó 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75442237-f9c5-4cb8-8cbe-5c972536d99e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75442237-f9c5-4cb8-8cbe-5c972536d99e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75442237-f9c5-4cb8-8cbe-5c972536d99e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6SK6ahjEpy9"
      },
      "outputs": [],
      "source": [
        "#df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h8hFppsb5cAW",
        "outputId": "b5d7a5d6-487f-42cf-9be8-aa6eb565eb78"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OFhgeI-OgFEz"
      },
      "outputs": [],
      "source": [
        "#df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERcykcKRz4Ri"
      },
      "outputs": [],
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QvTKqD08lNFz",
        "outputId": "ae0f9bad-2d4a-4675-80eb-86bdd17243db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-fdbbf2e7eb54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['session'] = connected['session'].map(source_idx)\n",
            "<ipython-input-21-fdbbf2e7eb54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['aid'] = connected['aid'].map(target_idx)\n"
          ]
        }
      ],
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4L_GWK4hlTWM",
        "outputId": "c5b877ca-7895-4450-f1f1-2f8fc11f061a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-23961f25841f>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  edge_index = torch.tensor((source.values, target.values))\n"
          ]
        }
      ],
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl_tLvXkFVmG",
        "outputId": "9cf3278f-eccf-468c-a679-dd92e6f37616"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0          1501601\n",
              "1           644159\n",
              "2          7936838\n",
              "3          7560153\n",
              "4          3424360\n",
              "            ...   \n",
              "1083575     553176\n",
              "1083576     387336\n",
              "1083577    9147729\n",
              "1083578    1569592\n",
              "1083579    6017748\n",
              "Name: session, Length: 1083580, dtype: int32"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 32)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del df"
      ],
      "metadata": {
        "id": "9kR2R3WCvpG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        #'num_nodes': session_num_nodes,\n",
        "        'node_id': torch.tensor(list(source_idx.values()), dtype=torch.int64)\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features,\n",
        "        'node_id': torch.tensor(list(target_idx.values()), dtype=torch.int64)\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGH8Sd8O97x7",
        "outputId": "da069d69-f1b9-4c79-a731-c4d5a597378d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ node_id=[912038] },\n",
              "  \u001b[1maid\u001b[0m={\n",
              "    x=[380386, 32],\n",
              "    node_id=[380386]\n",
              "  },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 1083580],\n",
              "    edge_label=[1083580]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9F9gevNn-Ms3",
        "outputId": "f2a5b24b-4efc-4250-d90d-b6d50a3d9373"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TArUgtyn-OZV",
        "outputId": "0b9492ca-5d6c-4b8d-b063-fcbf45b6cd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQNhuNgM-Tar"
      },
      "outputs": [],
      "source": [
        "#print('Isolated nodes?', data.has_isolated_nodes())\n",
        "#print('Self loops?', data.has_self_loops())\n",
        "#print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d50QCHYyKBNh",
        "outputId": "9cf26241-874e-47e0-e34b-3542b1113d4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    node_id=[912038],\n",
              "    x=[912038, 32]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={\n",
              "    x=[380386, 32],\n",
              "    node_id=[380386]\n",
              "  },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 1083580],\n",
              "    edge_label=[1083580]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 1083580] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKqQxQA0-X44"
      },
      "source": [
        "### Calculate Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5QvT19CNOtUI",
        "outputId": "a0c0f390-4a4c-4c71-b5ce-a05246e5e2df"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1083580])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data['session', 'aid'].edge_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jlz46YER-Uns"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "\n",
        "counts = torch.bincount(data['session', 'aid'].edge_label)\n",
        "\n",
        "# Set weights normalized by (max count/each count)\n",
        "weight = counts.max() / counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZEH42kKOl58",
        "outputId": "86e3946d-10e3-449f-ea73-44055ca8746e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([973843,  84241,  25496])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rw__CF6WOife",
        "outputId": "dd54935d-41fc-4693-a089-4e29286c91ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5602, 38.1959])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLOdlJzR-hDm",
        "outputId": "62e0b446-ae41-4a2c-b2b1-733e5212ae85"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"a4d31fed-75bb-4c71-81e1-6a4992daa438\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"a4d31fed-75bb-4c71-81e1-6a4992daa438\")) {                    Plotly.newPlot(                        \"a4d31fed-75bb-4c71-81e1-6a4992daa438\",                        [{\"line\":{\"color\":\"coral\"},\"name\":\"nb rows\",\"x\":[0,1,2,3,4,5],\"y\":[973843,84241,25496],\"type\":\"scatter\"},{\"line\":{\"color\":\"royalblue\"},\"name\":\"weights\",\"x\":[0,1,2,3,4,5],\"y\":[1.0,11.560202598571777,38.1959114074707],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"# rows\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"weights\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('a4d31fed-75bb-4c71-81e1-6a4992daa438');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dict = {'type': (counts, '# rows','coral'), 'weights': (weight, 'weights','royalblue')}\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=counts.detach().cpu().numpy(),\n",
        "               name = 'nb rows', line_color= 'coral'))\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=weight.detach().cpu().numpy(),\n",
        "               name = 'weights', line_color= 'royalblue'),  secondary_y=True)\n",
        "\n",
        "\n",
        "fig.update_yaxes(title_text=\"# rows\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"weights\", secondary_y=True)\n",
        "fig.update_xaxes(title_text=\"Type\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV6330E6VmlW"
      },
      "source": [
        "### Mini Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bExrskfWXv8A",
        "outputId": "9cd83da0-6d80-4e2d-c05a-a3fe5b9f38de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    node_id=[320],\n",
            "    x=[320, 32]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={\n",
            "    x=[139, 32],\n",
            "    node_id=[139]\n",
            "  },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 321],\n",
            "    edge_label=[64],\n",
            "    edge_label_index=[2, 64],\n",
            "    input_id=[64]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 307] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define seed edges:\n",
        "edge_label_index = train_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = train_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,  # TODO\n",
        "    num_neighbors=[5, 10],  # TODO\n",
        "    neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=64,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Inspect a sample:\n",
        "sampled_data = next(iter(train_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label_index.size(1) == 128\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.min() == 0\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.max() == 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N6oASmHaoa5",
        "outputId": "318e8382-b1b3-4136-d9a0-cf9cbed60adb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5589, 38.0843])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # encoder and decoder\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "        # embedding matrices for sessions and aids\n",
        "        self.aid_lin = Linear(-1, hidden_channels)\n",
        "        self.session_emb = torch.nn.Embedding(data['session'].num_nodes, hidden_channels)\n",
        "        self.aid_emb = torch.nn.Embedding(data['aid'].num_nodes, hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        x_dict = {\n",
        "            'session': self.session_emb(data['session'].node_id.to(device)),\n",
        "            'aid': self.aid_lin(data['aid'].x.to(device).float()) + self.aid_emb(data['aid'].node_id.to(device))\n",
        "        }\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfKuKIU-aYuS",
        "outputId": "7baa5af2-833d-4c0f-cc3b-8a570a63e3e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    node_id=[912038],\n",
              "    x=[912038, 32]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={\n",
              "    x=[380386, 32],\n",
              "    node_id=[380386]\n",
              "  },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 1083580],\n",
              "    edge_label=[1083580]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 1083580] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZENXvG8wealJ",
        "outputId": "6f6b459f-04bf-4687-d258-21400815d21c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nsampled = next(iter(train_loader))\\n\\nwith torch.no_grad():\\n    model.encoder(sampled_data.to(device).x_dict, sampled_data.to(device).edge_index_dict)\\n\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "'''\n",
        "sampled = next(iter(train_loader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.encoder(sampled_data.to(device).x_dict, sampled_data.to(device).edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "ayGHaB6JegtI",
        "outputId": "5bd2978c-484e-40b2-96ff-f946cb861677"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train():\\n    model.train()\\n    optimizer.zero_grad()\\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\\n                 train_data['session', 'aid'].edge_label_index)\\n    target = train_data['session', 'aid'].edge_label\\n    loss = weighted_mse_loss(pred, target, weight)\\n    loss.backward()\\n    optimizer.step()\\n    return float(loss)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "'''\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "RIjLW5AteiWZ",
        "outputId": "a431f568-9ee4-4490-ed10-573d4127755a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef test(data):\\n    model.eval()\\n    pred = model(data.x_dict, data.edge_index_dict,\\n                 data['session', 'aid'].edge_label_index)\\n    pred = pred.clamp(min=-1, max=2)\\n    target = data['session', 'aid'].edge_label.float()\\n    rmse = F.mse_loss(pred, target).sqrt()\\n    return float(rmse)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=-1, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iG6cTQvOi70X"
      },
      "outputs": [],
      "source": [
        "def train(train_data=sampled_data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight.to(device))\n",
        "    #loss = F.binary_cross_entropy_with_logits(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss), pred, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "31EopkIapWVk"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data=data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse), pred, target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kos-BVhlm6dR"
      },
      "source": [
        "### [non-batch] Training Heterogenous Link-level GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "7Mt5-wzRekay",
        "outputId": "f137d40b-6064-4662-b8ea-22fe391493af"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor epoch in range(0, 30):\\n    loss = train()\\n    train_rmse = test(train_data)\\n    val_rmse = test(val_data)\\n    test_rmse = test(test_data)\\n    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\\n          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "'''\n",
        "for epoch in range(0, 30):\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    test_rmse = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZXrZJEknJAo"
      },
      "source": [
        "### [mini-batch] Training Heterogenous Link-level GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "id": "hbuDkO-Nh8kA",
        "outputId": "c4c01d1f-a8e7-4f4b-8501-70d7d199f2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cpu'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|‚ñà‚ñà‚ñå       | 3476/13545 [2:47:06<8:04:03,  2.88s/it]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-d9574b528ad5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msampled_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0;31m# TODO: Move `sampled_data` to the respective `device`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m# TODO: Run `forward` pass of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-54-34fdfcaee0a2>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     pred = model(train_data.x_dict, train_data.edge_index_dict,\n\u001b[0m\u001b[1;32m      5\u001b[0m                  train_data['session', 'aid'].edge_label_index)\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-48-168a201230b3>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, edge_index_dict, edge_label_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;34m'aid'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maid_lin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maid_emb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         }\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0mz_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_label_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<eval_with_key>.1\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0medge_index__session__event__aid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'event'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0medge_index__aid__rev_event__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rev_event'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'session'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0medge_index_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mconv1__aid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession__event__aid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__aid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__session__event__aid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mconv1__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maid__rev_event__session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__aid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__aid__rev_event__session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mx__aid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrelu__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1__session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mconv1__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot_weight\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx_r\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "#model = Model(hidden_channels=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(0, 10):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss, pred, model = train(train_data=sampled_data.to(device))\n",
        "        # TODO: Move `sampled_data` to the respective `device`\n",
        "        # TODO: Run `forward` pass of the model\n",
        "        # TODO: Apply binary cross entropy via\n",
        "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
        "\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joyCx1zCnzl2"
      },
      "outputs": [],
      "source": [
        "path = '/content/drive/MyDrive/OTTO-Kaggle-Competition/model.pt'\n",
        "# Save the entire model\n",
        "#torch.save(model, path)\n",
        "#model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FV5XwXrhfbYT",
        "outputId": "8784e1cf-5e95-40af-cd2c-c4638394c815"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): Module(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): Module(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              "  (aid_lin): Linear(32, 32, bias=True)\n",
              "  (session_emb): Embedding(208340, 32)\n",
              "  (aid_emb): Embedding(127651, 32)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ],
      "source": [
        "# Load the entire model\n",
        "trained_model = torch.load(path, map_location=torch.device('cpu'))\n",
        "trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ia8AeaevVSQH",
        "outputId": "d181b71f-0e0e-4b98-8ce9-5350f6d29a03"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[0.3496, 0.3576, 0.4350,  ..., 0.6999, 0.4863, 0.4950],\n",
              "         [0.1491, 0.8726, 0.9180,  ..., 0.6280, 0.2909, 0.3206],\n",
              "         [0.0133, 0.7595, 0.0310,  ..., 0.4020, 0.3845, 0.7873],\n",
              "         ...,\n",
              "         [0.4796, 0.9141, 0.4633,  ..., 0.3266, 0.3514, 0.0129],\n",
              "         [0.2017, 0.2295, 0.6426,  ..., 0.0386, 0.0270, 0.8272],\n",
              "         [0.1999, 0.2325, 0.2433,  ..., 0.5451, 0.6901, 0.3934]]),\n",
              " 'aid': tensor([[0.6101, 0.5663, 0.1656,  ..., 0.5417, 0.3627, 0.3910],\n",
              "         [0.5994, 0.7613, 0.2289,  ..., 0.9359, 0.9888, 0.1481],\n",
              "         [0.4539, 0.9263, 0.4720,  ..., 0.4157, 0.2312, 0.0429],\n",
              "         ...,\n",
              "         [0.5931, 0.5741, 0.2546,  ..., 0.9014, 0.7131, 0.1320],\n",
              "         [0.8739, 0.8120, 0.1230,  ..., 0.0576, 0.0523, 0.0178],\n",
              "         [0.5163, 0.5471, 0.3522,  ..., 0.8437, 0.4139, 0.9526]])}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "data.x_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbPqjTSINEG",
        "outputId": "9fc1fc7c-14c3-4add-cb25-dbd402de8dd6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[ 0.5086,  0.1713, -0.1024,  ..., -0.2654,  0.0533,  0.1688],\n",
              "         [ 0.5146, -0.0319, -0.0986,  ..., -0.2964, -0.2364,  0.0285],\n",
              "         [ 0.8892,  0.2763, -0.2755,  ..., -0.3909,  0.0060,  0.1843],\n",
              "         ...,\n",
              "         [ 0.7275,  0.4005, -0.3474,  ..., -0.2208,  0.0366,  0.0864],\n",
              "         [ 0.7869,  0.1656, -0.2175,  ..., -0.3619,  0.1895,  0.2474],\n",
              "         [ 0.4761,  0.2052, -0.1818,  ..., -0.2033,  0.0482, -0.0524]],\n",
              "        grad_fn=<AddBackward0>),\n",
              " 'aid': tensor([[-0.0559, -0.2701,  0.3355,  ...,  0.4512, -0.2145,  0.3344],\n",
              "         [-0.3173, -0.3699,  0.2872,  ...,  0.3806, -0.0325,  0.2324],\n",
              "         [-0.3945, -0.1062,  0.3149,  ...,  0.3986, -0.2398,  0.4475],\n",
              "         ...,\n",
              "         [-0.1265,  0.0740,  0.4994,  ...,  0.3266, -0.2041,  0.7710],\n",
              "         [-0.3580, -0.0395,  0.1333,  ...,  0.3520, -0.3750,  0.6459],\n",
              "         [-0.5111, -0.3922,  0.0240,  ...,  0.4656, -0.0313,  0.6253]],\n",
              "        grad_fn=<AddBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "model.encoder(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t4bbKw80fs7A",
        "outputId": "63d859ac-1466-4a3c-d3d3-ade30582cd6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[-3.4276e-02, -6.7186e-02,  7.0359e-02,  ...,  5.6479e-01,\n",
              "           6.2746e-01, -3.6857e-01],\n",
              "         [ 9.0695e-03, -1.8986e-01, -4.2547e-02,  ...,  5.7287e-01,\n",
              "           6.2704e-01,  1.6782e-01],\n",
              "         [-1.3472e-01, -2.4179e-01,  1.1364e-01,  ...,  4.5827e-01,\n",
              "           3.5611e-01,  2.0237e-01],\n",
              "         ...,\n",
              "         [-6.2032e-02,  1.2672e-01,  1.0672e-01,  ...,  3.6610e-01,\n",
              "           3.7137e-01, -1.8489e-01],\n",
              "         [ 1.9452e-04, -4.1146e-02, -1.7734e-02,  ...,  3.1574e-01,\n",
              "           3.3442e-01, -1.9015e-01],\n",
              "         [ 3.8809e-02, -3.9735e-03,  1.3751e-01,  ...,  4.9234e-01,\n",
              "           3.3738e-01, -2.6441e-01]], grad_fn=<AddBackward0>),\n",
              " 'aid': tensor([[-0.8280,  0.0782,  0.6897,  ...,  0.3859, -0.2916, -0.7016],\n",
              "         [-0.6276,  0.2062,  0.6144,  ...,  0.3266, -0.3236, -0.5227],\n",
              "         [-0.6649, -0.0069,  0.4999,  ...,  0.1297, -0.1545, -0.2722],\n",
              "         ...,\n",
              "         [-1.1918,  0.0282,  1.0897,  ...,  0.5333, -0.2856, -0.8711],\n",
              "         [-0.2578,  0.0469,  0.4690,  ...,  0.0531, -0.1329, -0.1011],\n",
              "         [-0.8914,  0.3419,  0.6604,  ...,  0.1180, -0.2640, -0.4368]],\n",
              "        grad_fn=<AddBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ],
      "source": [
        "trained_model.encoder(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqiZlbCxnOcp"
      },
      "source": [
        "### Evaluate a Heterogenous Linklevel GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzCtJihVnWKu",
        "outputId": "03fabfa6-8210-4ebb-e944-3ec73323663b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    node_id=[3508],\n",
            "    x=[3508, 32]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={\n",
            "    x=[1209, 32],\n",
            "    node_id=[1209]\n",
            "  },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 3238],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    input_id=[384]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 3463] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = val_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,  # TODO\n",
        "    num_neighbors=[20, 10],  # TODO\n",
        "    #neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.min() >= 0\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.max() <= 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFGjR1IWpKqX",
        "outputId": "81929b8c-e4ea-4fcd-fb9a-e994250c0167"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 283/283 [04:20<00:00,  1.09it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.4976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# You need the labels to binarize\n",
        "labels = [0, 1, 2]\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        _, pred, ground_truth = test(data=sampled_data.to(device))\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(ground_truth)\n",
        "        # TODO: Collect predictions and ground-truths and write them into\n",
        "        # `preds` and `ground_truths`.\n",
        "        #raise NotImplementedError\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "\n",
        "# Binarize `pred` with shape (n_samples, n_classes)\n",
        "pred = label_binarize(pred.astype(int), classes=labels)\n",
        "\n",
        "# Binarize `ground_truth` with shape (n_samples, n_classes)\n",
        "ground_truth = label_binarize(ground_truth, classes=labels)\n",
        "\n",
        "#rmse = _\n",
        "auc = roc_auc_score(ground_truth, pred, multi_class='ovo', average='weighted')\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "#print('RMSE: ', rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WLHyzIiNECx-"
      },
      "source": [
        "# Test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WDkdfZnxEB02"
      },
      "outputs": [],
      "source": [
        "#df = pd.read_parquet('/content/kaggle/test.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkgwhJjiIyAm"
      },
      "outputs": [],
      "source": [
        "#df = df.sample(frac=0.01, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q4LGeBz9EPjh"
      },
      "outputs": [],
      "source": [
        "#df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iY12RhftEWwm"
      },
      "source": [
        "## Construct heterogenous graph for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VQwWWWsnEfli"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BITDjJKVEwpq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)\n",
        "\n",
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values)).type(torch.int64)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WZjCOHTlE0Xf"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwJLoByFFATA"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label,\n",
        "        'edge_label_index': edge_index\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UY3tqA4HFG3u"
      },
      "outputs": [],
      "source": [
        "#Rtest_data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OnPMRj27FwbQ"
      },
      "outputs": [],
      "source": [
        "#data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vC_MYbqNFK_s"
      },
      "outputs": [],
      "source": [
        "#Rtest_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ktGWQnnIPbL"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "# add sesion features for message passing:\n",
        "Rtest_data['session'].x = torch.rand(Rtest_data['session'].num_nodes, 300)\n",
        "\n",
        "Rtest_data = T.ToUndirected()(Rtest_data)\n",
        "del Rtest_data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label.\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Eb6N2GaqNj_e"
      },
      "outputs": [],
      "source": [
        "#Rtest_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1serMeUuEf8-"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FsVoiBSqLsrR"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    gg = model(Rtest_data.x_dict, Rtest_data.edge_index_dict, Rtest_data['session', 'aid'].edge_label_index)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-eUS0_0PjKKY"
      },
      "outputs": [],
      "source": [
        "#data['session', 'aid'].edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RilROrFHN-xZ"
      },
      "outputs": [],
      "source": [
        "#Rtest_data['session', 'aid'].edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eW4XhiQHhf7f"
      },
      "outputs": [],
      "source": [
        "#gg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FRQNaMN8fSz8"
      },
      "outputs": [],
      "source": [
        "#data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHNbZyHebUPV"
      },
      "source": [
        "# [TEMPORARY DROP]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NTRQjhLACfe"
      },
      "outputs": [],
      "source": [
        "# Temporary comment\n",
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, conv):\n",
        "        super().__init__()\n",
        "        # conv(#in_channels, #out_channels)\n",
        "        ''''''\n",
        "        in_channels (int or tuple): \n",
        "            Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        ''''''\n",
        "        self.conv1 = conv((-1, -1), hidden_channels)\n",
        "        self.conv2 = conv((-1, -1), out_channels)\n",
        "        self.linear1 = Linear(-1, out_channels)\n",
        "        self.linear2 = Linear(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x0 = self.linear1(x)\n",
        "        x2 = self.conv1(x0, edge_index).relu()\n",
        "        x3 = self.conv2(x2, edge_index)\n",
        "        x4 = self.linear2(x2 + x3)\n",
        "        # Add combined layer to reduce over-smoothing\n",
        "        return x4\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,  conv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsSAc0seAHmq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def train(train_data, model, optimizer, loss=weighted_mse_loss):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.sqrt())\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxHfcosNAXQT"
      },
      "outputs": [],
      "source": [
        "## set pred.clamp\n",
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data, model, metric=F.mse_loss):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse) # Return RMSE loss\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE1pmW4KAXpe"
      },
      "outputs": [],
      "source": [
        "#from tqdm import tqdm\n",
        "#from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Mc3SOUAiui"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\n",
        "    t0 = time.time()\n",
        "\n",
        "    model = model(**model_params) # Define the model\n",
        "\n",
        "    # Due to lazy initialization, we need to run one model step so the number\n",
        "    # of parameters can be inferred:\n",
        "    with torch.no_grad():\n",
        "        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    k=0\n",
        "    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\n",
        "    train_wrmse, val_wrmse, test_wrmse = [], [], []\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        # Call train fuction here >> return loss\n",
        "        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\n",
        "        \n",
        "        # Call test function here >> return RMSE loss\n",
        "        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\n",
        "        train_rmse += [test(train_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\n",
        "        val_rmse += [test(val_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\n",
        "        test_rmse += [test(test_data, model, metric=F.mse_loss)]\n",
        "\n",
        "        if epoch+1 %10==0:\n",
        "            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\n",
        "                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'loss': loss,\n",
        "            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\n",
        "            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\n",
        "            'time':(time.time()-t0)/60\n",
        "        })\n",
        "        \n",
        "        ## Debugging\n",
        "        #clear_output()\n",
        "        '''\n",
        "        print('\\nloss: ', loss, \n",
        "              '\\ntrain_rmse: ', train_rmse, \n",
        "              '\\nval_rmse: ', val_rmse, \n",
        "              '\\ntest_rmse: ', test_rmse,\n",
        "              '\\ntrain_wrmse: ', train_wrmse, \n",
        "              '\\nval_wrmse: ', val_wrmse, \n",
        "              '\\ntest_wrmse: ', test_wrmse,\n",
        "              '\\ntime: ', (time.time()-t0)/60)\n",
        "        '''\n",
        "        #visualize_loss(results, metric='wrmse').show()\n",
        "        #print(results.to_string())\n",
        "\n",
        "        # enable early stopping\n",
        "        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\n",
        "            k += 1\n",
        "        if k> e_patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "\n",
        "    return results, model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8edkAihHAmP3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def visualize_loss(results, metric='rmse'):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['train_'+metric], name = 'train_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['val_'+metric], name = 'val_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['test_'+metric], name = 'test_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['loss'], name = 'loss'))\n",
        "\n",
        "    fig.update_yaxes(title_text=metric.upper())\n",
        "    fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "    return fig\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQElhxOkAn_q"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "N_EPOCHS = 300\n",
        "E_PATIENCE = 50\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "model_params = {\"hidden_channels\":32, 'conv':SAGEConv}\n",
        "\n",
        "results, trained_model = train_test(\n",
        "    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j58QMqIdUcfc"
      },
      "outputs": [],
      "source": [
        "#visualize_loss(results, metric='wrmse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUHSNzLmBEYx"
      },
      "outputs": [],
      "source": [
        "#trained_model.encoder(test_data.x_dict, test_data.edge_index_dict)['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtRs2Bw7kfOP"
      },
      "outputs": [],
      "source": [
        "#trained_model.state_dict()['encoder.linear2.session.weight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HKBFpzXHtgJ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aED_TAobTF6d"
      },
      "source": [
        "# Recommendation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9IbcT22JTIFr"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def recommendation(user_id, model, x_dict, edge_index_dict):\n",
        "  # Get model decoder\n",
        "  #model = Model(**model_params)\n",
        "  with torch.no_grad():\n",
        "    encoder = model.encoder(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "  # Get node representations for users and movies\n",
        "  user_representations = encoder['session']\n",
        "  movie_representations = encoder['aid']\n",
        "\n",
        "  # Compute the dot product between user and movie representations to get edge weights\n",
        "  edge_weights = user_representations.mm(movie_representations.T)\n",
        "\n",
        "  # Make predictions for each user by taking the top k largest edge weights\n",
        "  k = 20  # number of recommendations to make\n",
        "  _, top_k_indices = edge_weights.topk(k, dim=1)\n",
        "  recommendations = top_k_indices.numpy()\n",
        "\n",
        "  # Print recommendations for the first user\n",
        "  print(f'Recommendations for user {user_id}: {recommendations[user_id]}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WP1SufyhTURW"
      },
      "outputs": [],
      "source": [
        "#session = 1\n",
        "#recommendation(session, model, Rtest_data.x_dict, Rtest_data.edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VFmAIGENUV9F"
      },
      "outputs": [],
      "source": [
        "#session = 2\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4H4tCDOyUcVI"
      },
      "outputs": [],
      "source": [
        "#session = 999\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZw_TNkMQRaq"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFOSPOfhOjYr"
      },
      "source": [
        "Submission File\n",
        "For each `session` id and `type` combination in the test set, you must predict the `aid` values in the `label` column, which is space delimited. You can predict up to 20 `aid` values per row. The file should contain a header and have the following format:\n",
        "\n",
        "```\n",
        "session_type,labels\n",
        "12906577_clicks,135193 129431 119318 ...\n",
        "12906577_carts,135193 129431 119318 ...\n",
        "12906577_orders,135193 129431 119318 ...\n",
        "12906578_clicks, 135193 129431 119318 ...\n",
        "etc.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWyo1qVmOi8E"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "VKqQxQA0-X44",
        "XHNbZyHebUPV"
      ],
      "provenance": [],
      "mount_file_id": "1LMM4KUubrtgFevA8BQiTAU_4AgC4FOlM",
      "authorship_tag": "ABX9TyPw3jYmsDUkzhiWLMNUusCl",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
