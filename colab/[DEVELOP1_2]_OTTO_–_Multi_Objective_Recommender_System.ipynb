{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTgGyHWwP0wa",
        "outputId": "cc655039-e69c-4ca8-8840-07d2f3f91cf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▍                               | 10 kB 24.4 MB/s eta 0:00:01\r\u001b[K     |▊                               | 20 kB 28.4 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30 kB 35.6 MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███                             | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 112 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 143 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████                          | 163 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 174 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 194 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 204 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 225 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 235 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 256 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 266 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 276 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 286 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 296 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 307 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 317 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 327 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 337 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 348 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 358 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 368 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 378 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 389 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 399 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 409 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 419 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 430 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 440 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 450 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████▉               | 460 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 471 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 481 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 491 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 501 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 512 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 522 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 532 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 542 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 552 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 563 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 573 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 583 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 593 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 604 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 614 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 624 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 634 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 645 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 655 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 665 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 675 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 686 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 696 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 706 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 716 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 727 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 737 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 747 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 757 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 768 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 778 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 788 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 798 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 808 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 819 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 829 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 839 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 849 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 860 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 870 kB 7.0 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 873 kB 7.0 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YGBdYwXz-B9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "834b0094-ed9d-4300-e6ce-47c7acc07b8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 2.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 16.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 48.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 52.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 33.9 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j7Gsb6xQ98eL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "8356b080-4201-4681-9319-4b3a83ac8536"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c2eec298-dccb-436c-be7c-5936905f2c2b\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c2eec298-dccb-436c-be7c-5936905f2c2b\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "ref                                                             title                                           size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                       COVID-19 Dataset                                 5MB  2022-11-13 15:47:17          12942        371  1.0              \n",
            "thedevastator/analyzing-credit-card-spending-habits-in-india    Credit Card Spending Habits in India           319KB  2022-12-14 07:30:37            661         29  1.0              \n",
            "michals22/coffee-dataset                                        Coffee dataset                                  24KB  2022-12-15 20:02:12           2726         70  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data         E-Commerce Sales Dataset                         6MB  2022-12-03 09:27:17           2028         53  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                       Salary Prediction                                3MB  2022-11-16 13:52:31           7606        167  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset              Fifa World Cup 2022: Complete Dataset            7KB  2022-12-18 22:51:11           2254         94  1.0              \n",
            "mattop/highest-grossing-mobile-games                            Highest Grossing Mobile Games                    3KB  2022-12-19 15:20:22            386         23  1.0              \n",
            "thedevastator/uncover-global-trends-in-mental-health-disorder   Global Trends in Mental Health Disorder          1MB  2022-12-14 05:30:38            649         23  1.0              \n",
            "rajkumarpandey02/fifa-world-cup-attendance-19302022             FIFA World Cup Attendance 1930-2022              5KB  2022-12-19 10:04:26            718         21  1.0              \n",
            "thedevastator/revealing-insights-from-youtube-video-and-channe  YouTube Videos and Channels Metadata            82MB  2022-12-14 02:48:24            410         22  0.9411765        \n",
            "thedevastator/uncovering-insights-to-college-majors-and-their   College Majors and their Graduates              39KB  2022-12-06 16:06:52           1060         31  1.0              \n",
            "mvieira101/global-cost-of-living                                Global Cost of Living                            1MB  2022-12-03 16:37:53           3497         73  0.9705882        \n",
            "anashamoutni/students-employability-dataset                     Students' Employability Dataset - Philippines   97KB  2022-12-18 15:51:39            542         24  0.88235295       \n",
            "swaptr/fifa-world-cup-2022-statistics                           FIFA World Cup 2022 Team Data                   15KB  2022-12-19 00:29:15           2669         61  0.9705882        \n",
            "thedevastator/the-ultimate-netflix-tv-shows-and-movies-dataset  Netflix TV Shows and Movies (2022 Updated)       2MB  2022-11-27 20:41:41           2480         46  1.0              \n",
            "whenamancodes/predict-diabities                                 Predict Diabetes                                 9KB  2022-11-09 12:18:49           7923        122  1.0              \n",
            "kulturehire/understanding-career-aspirations-of-genz            Understanding Career Aspirations of GenZ         8KB  2022-12-21 13:44:32            231         23  0.9117647        \n",
            "thedevastator/uncovering-wage-disparities-in-pennsylvania-s-hi  Higher Education Wages                         223KB  2022-12-04 15:42:36           1265         40  1.0              \n",
            "laibaanwer/superstore-sales-dataset                             SuperStore Sales Dataset                         2MB  2022-12-07 08:53:32           1471         37  1.0              \n",
            "catherinerasgaitis/mxmh-survey-results                          Music & Mental Health Survey Results            22KB  2022-11-21 10:03:12           3138         75  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "421Djk4r4qJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a61bb946-6926-4aa7-a96d-8d9394d57e1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading otto-full-optimized-memory-footprint.zip to /content/kaggle\n",
            "100% 1.09G/1.09G [00:11<00:00, 119MB/s]\n",
            "100% 1.09G/1.09G [00:11<00:00, 100MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('/content/kaggle/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "df = df.sample(frac=0.001, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N-Q_j2wx7Omc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "249e2d45-54cf-4b71-e417-2a2e03567bc2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            session      aid          ts  type\n",
              "54247959    1459308  1799821  1660065370     0\n",
              "199325592  10884500   408289  1661714957     0\n",
              "123348340   4757521   329725  1661098601     0\n",
              "81697696    2566605   473536  1659542228     0\n",
              "195862982  10541270   462093  1661497516     0\n",
              "...             ...      ...         ...   ...\n",
              "40747481    1026501   828967  1661716204     1\n",
              "57566249    1580341  1060453  1659864059     0\n",
              "100403930   3490741   674028  1659861345     0\n",
              "172279091   8307299   313155  1660480140     0\n",
              "214839598  12658635   197350  1661684740     0\n",
              "\n",
              "[216716 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5f9b54d7-57d9-40f8-a5a8-502ef8e7a37d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>54247959</th>\n",
              "      <td>1459308</td>\n",
              "      <td>1799821</td>\n",
              "      <td>1660065370</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199325592</th>\n",
              "      <td>10884500</td>\n",
              "      <td>408289</td>\n",
              "      <td>1661714957</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123348340</th>\n",
              "      <td>4757521</td>\n",
              "      <td>329725</td>\n",
              "      <td>1661098601</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81697696</th>\n",
              "      <td>2566605</td>\n",
              "      <td>473536</td>\n",
              "      <td>1659542228</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195862982</th>\n",
              "      <td>10541270</td>\n",
              "      <td>462093</td>\n",
              "      <td>1661497516</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40747481</th>\n",
              "      <td>1026501</td>\n",
              "      <td>828967</td>\n",
              "      <td>1661716204</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57566249</th>\n",
              "      <td>1580341</td>\n",
              "      <td>1060453</td>\n",
              "      <td>1659864059</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100403930</th>\n",
              "      <td>3490741</td>\n",
              "      <td>674028</td>\n",
              "      <td>1659861345</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172279091</th>\n",
              "      <td>8307299</td>\n",
              "      <td>313155</td>\n",
              "      <td>1660480140</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214839598</th>\n",
              "      <td>12658635</td>\n",
              "      <td>197350</td>\n",
              "      <td>1661684740</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216716 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5f9b54d7-57d9-40f8-a5a8-502ef8e7a37d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5f9b54d7-57d9-40f8-a5a8-502ef8e7a37d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5f9b54d7-57d9-40f8-a5a8-502ef8e7a37d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I6SK6ahjEpy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f478248-46b5-40bb-afd7-c0625e19a237"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session    0\n",
              "aid        0\n",
              "ts         0\n",
              "type       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h8hFppsb5cAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c910f8a-d968-4883-ee8c-411fc9f40825"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OFhgeI-OgFEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56ca0106-e756-4c23-d66b-5f08ecd7feb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 216716 entries, 54247959 to 214839598\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count   Dtype\n",
            "---  ------   --------------   -----\n",
            " 0   session  216716 non-null  int32\n",
            " 1   aid      216716 non-null  int32\n",
            " 2   ts       216716 non-null  int32\n",
            " 3   type     216716 non-null  uint8\n",
            "dtypes: int32(3), uint8(1)\n",
            "memory usage: 4.3 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FriR71pK-hxH"
      },
      "source": [
        "### [Use new code instead] Construct `edge_index`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Jw0zU0aTMZ-G"
      },
      "outputs": [],
      "source": [
        "#def to_tuple(row):\n",
        "#    return tuple(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D1eMUs7A8qbA"
      },
      "outputs": [],
      "source": [
        "# also drop the ts and type column\n",
        "#connectivity = df.drop(columns=['ts', 'type']).apply(to_tuple, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h8KsppDI7dvJ"
      },
      "outputs": [],
      "source": [
        "#connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p2Yv20LW0Bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "eba2fd0d-5d26-462b-d6c1-b916e791d905"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# session index dict\\n#session = sorted(df['session'].unique())\\nsession = df['session'].unique()\\nsession_nodes_idx = {id:idx for idx, id in enumerate(session)}\\n\\n# aid(article id) index dict\\n#aid = sorted(df['aid'].unique())\\naid = df['aid'].unique()\\naid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Old code\n",
        "'''\n",
        "# session index dict\n",
        "#session = sorted(df['session'].unique())\n",
        "session = df['session'].unique()\n",
        "session_nodes_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "#aid = sorted(df['aid'].unique())\n",
        "aid = df['aid'].unique()\n",
        "aid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xTiXlCrOQYYm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b9783e9c-be1a-4788-9afd-cd3ec979642d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef get_node_indices(data, key):\\n  for id in data[key].unique():\\n    yield id, next(i for i, v in enumerate(data[key]) if v == id)\\n\\nsession_nodes_idx = dict(get_node_indices(df, 'session'))\\naid_nodes_idx = dict(get_node_indices(df, 'aid'))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# use this code if the above cause memory crash\n",
        "# very slow but memory good\n",
        "'''\n",
        "def get_node_indices(data, key):\n",
        "  for id in data[key].unique():\n",
        "    yield id, next(i for i, v in enumerate(data[key]) if v == id)\n",
        "\n",
        "session_nodes_idx = dict(get_node_indices(df, 'session'))\n",
        "aid_nodes_idx = dict(get_node_indices(df, 'aid'))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tpiPnhRYN7X4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "af0dfdae-cf0d-4a92-fc65-7f014333ceef"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni_session = []\\ni_aid = []\\nfor session, aid in connectivity_list:\\n  i_session.append(user_nodes_idx[user])\\n  i_aid.append(item_nodes_idx[item])\\n\\nindice = [i_session, i_aid]\\nedge_index = torch.Tensor(indice).type(torch.long)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# /!\\ this cause memory crashed in a very large data\n",
        "'''\n",
        "i_session = []\n",
        "i_aid = []\n",
        "for session, aid in connectivity_list:\n",
        "  i_session.append(user_nodes_idx[user])\n",
        "  i_aid.append(item_nodes_idx[item])\n",
        "\n",
        "indice = [i_session, i_aid]\n",
        "edge_index = torch.Tensor(indice).type(torch.long)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "My-fApG4OR-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c6d548c7-92a8-48f1-c03d-2f7c60c66eb2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\\n  for user, item in connectivity_list:\\n    yield user_nodes_idx[user], item_nodes_idx[item]\\n\\nedge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Work but still got memory crash in very large data\n",
        "'''\n",
        "def get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\n",
        "  for user, item in connectivity_list:\n",
        "    yield user_nodes_idx[user], item_nodes_idx[item]\n",
        "\n",
        "edge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ERcykcKRz4Ri"
      },
      "outputs": [],
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QvTKqD08lNFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7930b0a-62a8-4780-cf93-405cb2522bdb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-fdbbf2e7eb54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['session'] = connected['session'].map(source_idx)\n",
            "<ipython-input-20-fdbbf2e7eb54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['aid'] = connected['aid'].map(target_idx)\n"
          ]
        }
      ],
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4L_GWK4hlTWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d994a8-699f-4a4a-9917-53866a3d3531"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-23961f25841f>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  edge_index = torch.tensor((source.values, target.values))\n"
          ]
        }
      ],
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Dn3bodEPSWNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "016a697f-c188-4b43-a731-f89458b14433"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xXl7YIluHxDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b43ddd9-730b-4442-c722-4e9021c719ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 216716])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "edge_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zEQRr1JTIMYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72632842-b4d8-4f79-9c41-738a9912ad63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([127942, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "aid_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TLVPfcmsIThg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c4d018a-da11-45fb-d662-f1e877a0f188"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "edge_label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gGH8Sd8O97x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eac2c4d-ecdd-4409-e042-7c60b9d69ab1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ num_nodes=208348 },\n",
              "  \u001b[1maid\u001b[0m={ x=[127942, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9F9gevNn-Ms3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f7aa25ea-e803-46be-ad98-c19cf4d54480"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TArUgtyn-OZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b112cd43-b192-443c-9548-23438571b6a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wQNhuNgM-Tar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ba92dc81-4799-4d51-d313-26a409fe1ce6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolated nodes? False\n",
            "Self loops? False\n",
            "Undirected graph?  False\n"
          ]
        }
      ],
      "source": [
        "print('Isolated nodes?', data.has_isolated_nodes())\n",
        "print('Self loops?', data.has_self_loops())\n",
        "print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "d50QCHYyKBNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd9227b3-240e-440e-92ef-52f5f4af1c82"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208348,\n",
              "    x=[208348, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127942, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKqQxQA0-X44"
      },
      "source": [
        "### Calculate Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5QvT19CNOtUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9295ba2-4e3d-46c7-d5f7-85e094ffbc85"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "data['session', 'aid'].edge_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Jlz46YER-Uns"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "\n",
        "counts = torch.bincount(data['session', 'aid'].edge_label)\n",
        "\n",
        "# Set weights normalized by (max count/each count)\n",
        "weight = counts.max() / counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cZEH42kKOl58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ee394101-f799-4342-96b8-0435ca576c67"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([194651,  17095,   4970])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Rw__CF6WOife",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a40f8f85-dbea-46be-f112-37bfedd192a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.3864, 39.1652])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nLOdlJzR-hDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "outputId": "e2612250-8f91-4e6f-e07e-02bed1c87c9d"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"adadb701-465b-4514-874d-1966610ddee5\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"adadb701-465b-4514-874d-1966610ddee5\")) {                    Plotly.newPlot(                        \"adadb701-465b-4514-874d-1966610ddee5\",                        [{\"line\":{\"color\":\"coral\"},\"name\":\"nb rows\",\"x\":[0,1,2,3,4,5],\"y\":[194651,17095,4970],\"type\":\"scatter\"},{\"line\":{\"color\":\"royalblue\"},\"name\":\"weights\",\"x\":[0,1,2,3,4,5],\"y\":[1.0,11.386428833007812,39.165191650390625],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"# rows\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"weights\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('adadb701-465b-4514-874d-1966610ddee5');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dict = {'type': (counts, '# rows','coral'), 'weights': (weight, 'weights','royalblue')}\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=counts.detach().cpu().numpy(),\n",
        "               name = 'nb rows', line_color= 'coral'))\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=weight.detach().cpu().numpy(),\n",
        "               name = 'weights', line_color= 'royalblue'),  secondary_y=True)\n",
        "\n",
        "\n",
        "fig.update_yaxes(title_text=\"# rows\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"weights\", secondary_y=True)\n",
        "fig.update_xaxes(title_text=\"Type\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5kq9vMp3Rxeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4dab958-deaf-4317-baa8-9dec696d09ea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[ 73617, 162871, 152302,  ..., 189690,  37939, 200145],\n",
              "        [ 55316, 105536,  21241,  ..., 118948,  31241, 123985]]), 'edge_label': tensor([0, 0, 0,  ..., 0, 0, 0]), 'edge_label_index': tensor([[ 73617, 162871, 152302,  ..., 189690,  37939, 200145],\n",
              "        [ 55316, 105536,  21241,  ..., 118948,  31241, 123985]])}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "train_data['session','aid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "VzTgyXxUSGfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5b31ae2-04a4-45c9-b594-43cc6e6f382c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "train_data['session','aid'].edge_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4N6oASmHaoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "401ef779-80a8-4094-e712-3ab83fb72739"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.3974, 39.2899])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZENXvG8wealJ"
      },
      "outputs": [],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "with torch.no_grad():\n",
        "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ayGHaB6JegtI"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RIjLW5AteiWZ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mt5-wzRekay",
        "outputId": "7ebf35bb-b839-4975-cf4f-c54261465c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 001, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 002, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 003, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 004, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 005, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 006, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 007, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 008, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 009, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 010, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 011, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 012, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 013, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 014, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 015, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 016, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 017, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 018, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 019, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 020, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 021, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 022, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 023, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 024, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 025, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 026, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 027, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 028, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 029, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 030, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 031, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 032, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 033, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 034, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 035, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 036, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 037, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 038, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 039, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 040, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 041, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 042, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 043, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 044, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 045, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 046, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 047, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 048, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n",
            "Epoch: 049, Loss: 5.0565, Train: 0.4126, Val: 0.4167, Test: 0.4127\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0, 50):\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    test_rmse = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joyCx1zCnzl2",
        "outputId": "159eadd0-5385-4de1-c5b6-4dcf8a73f53c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SxYona145IU",
        "outputId": "5af68c5d-47c6-4f4c-c05b-b39b55021b94"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208348,\n",
              "    x=[208348, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127942, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "60a-6qAqpPXT"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "encoder = model.encoder(data.x_dict, data.edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.encoder(data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbPqjTSINEG",
        "outputId": "2b178169-e213-4843-ecb4-6886b7a03263"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[-0.0771, -0.0724, -0.3130,  ..., -0.1629, -0.0106, -0.2367],\n",
              "         [-0.4352, -0.1870, -0.5053,  ..., -0.3003,  0.0773, -0.0627],\n",
              "         [-0.3129, -0.1915, -0.6144,  ..., -0.3951,  0.0734,  0.0172],\n",
              "         ...,\n",
              "         [-0.3079,  0.1375, -0.7560,  ..., -0.2474, -0.0074,  0.2241],\n",
              "         [-0.4293, -0.1128, -0.9489,  ..., -0.3731,  0.1654, -0.0090],\n",
              "         [-0.2008,  0.1316, -0.7115,  ..., -0.4850, -0.0167, -0.0465]],\n",
              "        grad_fn=<AddBackward0>),\n",
              " 'aid': tensor([[ 0.0611,  0.5430, -0.0236,  ..., -0.1099,  0.2670, -0.0076],\n",
              "         [-0.1354,  0.2800, -0.3637,  ...,  0.1717, -0.1400, -0.0859],\n",
              "         [-0.0322,  0.1844, -0.2027,  ...,  0.3200, -0.1634, -0.2238],\n",
              "         ...,\n",
              "         [-0.2321,  0.1500, -0.2298,  ...,  0.2146, -0.1831,  0.0258],\n",
              "         [-0.2058,  0.3597, -0.5925,  ..., -0.1896,  0.0751,  0.0998],\n",
              "         [-0.2224,  0.2792, -0.2579,  ...,  0.2430, -0.0296, -0.1056]],\n",
              "        grad_fn=<AddBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gg = model(data.x_dict, data.edge_index_dict, data['session', 'aid'].edge_index)"
      ],
      "metadata": {
        "id": "FsVoiBSqLsrR"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eUS0_0PjKKY",
        "outputId": "f8099b20-2f91-46b8-90d5-873946938d82"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW4XhiQHhf7f",
        "outputId": "13ca41b8-6b7d-450a-d638-86c944096269"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.1028, -0.1119, -0.0971,  ..., -0.1488, -0.1248, -0.1152],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRQNaMN8fSz8",
        "outputId": "c347b24c-be77-44d3-9466-a475d0bdda9f"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208348,\n",
              "    x=[208348, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127942, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOKEZTyifQOW",
        "outputId": "f844756c-a7b3-4e6d-bcc3-3d6855743490"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208348,\n",
              "    x=[208348, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127942, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 173374],\n",
              "    edge_label=[173374],\n",
              "    edge_label_index=[2, 173374]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 173374] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['session','aid']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q30qpTGg7qt",
        "outputId": "c47d3e8c-4f16-4657-c9bb-54eb15a0fc12"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[ 73617, 162871, 152302,  ..., 189690,  37939, 200145],\n",
              "        [ 55316, 105536,  21241,  ..., 118948,  31241, 123985]]), 'edge_label': tensor([0, 0, 0,  ..., 0, 0, 0]), 'edge_label_index': tensor([[ 73617, 162871, 152302,  ..., 189690,  37939, 200145],\n",
              "        [ 55316, 105536,  21241,  ..., 118948,  31241, 123985]])}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ez = model(train_data.x_dict, train_data.edge_index_dict, train_data['session', 'aid'].edge_label_index)"
      ],
      "metadata": {
        "id": "pLU1Xv2fe6_4"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ez"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUItCDLYfBjX",
        "outputId": "4cf1a704-5370-4f4c-e6c8-fe4d49a92267"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0841, 0.9967, 1.0437,  ..., 1.0449, 1.0171, 1.0640],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHNbZyHebUPV"
      },
      "source": [
        "##### [2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NTRQjhLACfe"
      },
      "outputs": [],
      "source": [
        "# Temporary comment\n",
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, conv):\n",
        "        super().__init__()\n",
        "        # conv(#in_channels, #out_channels)\n",
        "        ''''''\n",
        "        in_channels (int or tuple): \n",
        "            Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        ''''''\n",
        "        self.conv1 = conv((-1, -1), hidden_channels)\n",
        "        self.conv2 = conv((-1, -1), out_channels)\n",
        "        self.linear1 = Linear(-1, out_channels)\n",
        "        self.linear2 = Linear(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x0 = self.linear1(x)\n",
        "        x2 = self.conv1(x0, edge_index).relu()\n",
        "        x3 = self.conv2(x2, edge_index)\n",
        "        x4 = self.linear2(x2 + x3)\n",
        "        # Add combined layer to reduce over-smoothing\n",
        "        return x4\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,  conv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsSAc0seAHmq"
      },
      "outputs": [],
      "source": [
        "def train(train_data, model, optimizer, loss=weighted_mse_loss):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.sqrt())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxHfcosNAXQT"
      },
      "outputs": [],
      "source": [
        "## set pred.clamp\n",
        "@torch.no_grad()\n",
        "def test(data, model, metric=F.mse_loss):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse) # Return RMSE loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE1pmW4KAXpe"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Mc3SOUAiui"
      },
      "outputs": [],
      "source": [
        "def train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\n",
        "    t0 = time.time()\n",
        "\n",
        "    model = model(**model_params) # Define the model\n",
        "\n",
        "    # Due to lazy initialization, we need to run one model step so the number\n",
        "    # of parameters can be inferred:\n",
        "    with torch.no_grad():\n",
        "        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    k=0\n",
        "    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\n",
        "    train_wrmse, val_wrmse, test_wrmse = [], [], []\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        # Call train fuction here >> return loss\n",
        "        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\n",
        "        \n",
        "        # Call test function here >> return RMSE loss\n",
        "        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\n",
        "        train_rmse += [test(train_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\n",
        "        val_rmse += [test(val_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\n",
        "        test_rmse += [test(test_data, model, metric=F.mse_loss)]\n",
        "\n",
        "        if epoch+1 %10==0:\n",
        "            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\n",
        "                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'loss': loss,\n",
        "            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\n",
        "            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\n",
        "            'time':(time.time()-t0)/60\n",
        "        })\n",
        "        \n",
        "        ## Debugging\n",
        "        #clear_output()\n",
        "        '''\n",
        "        print('\\nloss: ', loss, \n",
        "              '\\ntrain_rmse: ', train_rmse, \n",
        "              '\\nval_rmse: ', val_rmse, \n",
        "              '\\ntest_rmse: ', test_rmse,\n",
        "              '\\ntrain_wrmse: ', train_wrmse, \n",
        "              '\\nval_wrmse: ', val_wrmse, \n",
        "              '\\ntest_wrmse: ', test_wrmse,\n",
        "              '\\ntime: ', (time.time()-t0)/60)\n",
        "        '''\n",
        "        #visualize_loss(results, metric='wrmse').show()\n",
        "        #print(results.to_string())\n",
        "\n",
        "        # enable early stopping\n",
        "        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\n",
        "            k += 1\n",
        "        if k> e_patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "\n",
        "    return results, model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "8edkAihHAmP3"
      },
      "outputs": [],
      "source": [
        "def visualize_loss(results, metric='rmse'):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['train_'+metric], name = 'train_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['val_'+metric], name = 'val_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['test_'+metric], name = 'test_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['loss'], name = 'loss'))\n",
        "\n",
        "    fig.update_yaxes(title_text=metric.upper())\n",
        "    fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "    return fig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQElhxOkAn_q",
        "outputId": "e0c089d1-ac75-4a5f-9f89-44aded4f1e76"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 21%|██        | 62/300 [05:12<19:59,  5.04s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Early stopping\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "N_EPOCHS = 300\n",
        "E_PATIENCE = 50\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "model_params = {\"hidden_channels\":32, 'conv':SAGEConv}\n",
        "\n",
        "results, trained_model = train_test(\n",
        "    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "j58QMqIdUcfc",
        "outputId": "46a147da-4bc8-4180-8f51-3893e15844d4"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-136-1997eb055977>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvisualize_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wrmse'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'results' is not defined"
          ]
        }
      ],
      "source": [
        "visualize_loss(results, metric='wrmse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUHSNzLmBEYx",
        "outputId": "ad7e8a09-f011-45ea-c6ea-1a01c12178e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0202,  0.1865, -1.5817,  ...,  0.3076, -0.5708, -0.3113],\n",
              "        [ 0.5542,  1.7736, -3.6844,  ...,  1.0820, -3.4425, -0.9355],\n",
              "        [ 0.5612,  1.8848, -3.6680,  ...,  1.0439, -3.4606, -0.8596],\n",
              "        ...,\n",
              "        [ 0.6097,  1.9271, -3.8425,  ...,  1.1255, -3.6148, -0.9310],\n",
              "        [-0.0196,  0.1864, -1.5662,  ...,  0.3088, -0.5734, -0.3177],\n",
              "        [ 0.6241,  1.8300, -3.6237,  ...,  1.0752, -3.3341, -0.8680]],\n",
              "       grad_fn=<AddmmBackward0>)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_model.encoder(test_data.x_dict, test_data.edge_index_dict)['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PtRs2Bw7kfOP",
        "outputId": "319bd1f0-a8b5-40a7-e89a-7cd832906d3b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-0.0422,  0.1216,  0.0835,  ...,  0.1315,  0.1706, -0.0522],\n",
              "        [ 0.1098,  0.0852,  0.1251,  ...,  0.0553,  0.0312, -0.0077],\n",
              "        [-0.0142,  0.0712, -0.0888,  ..., -0.1421, -0.0150, -0.0069],\n",
              "        ...,\n",
              "        [ 0.0493,  0.1519,  0.0811,  ...,  0.1542, -0.1844,  0.0976],\n",
              "        [-0.0150,  0.1030, -0.1174,  ..., -0.1944, -0.0111,  0.0048],\n",
              "        [ 0.1059,  0.0325, -0.0114,  ..., -0.0815,  0.1416, -0.0457]])"
            ]
          },
          "execution_count": 87,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "trained_model.state_dict()['encoder.linear2.session.weight']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wSsspvv4lFv-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPFILyhjWzbh2uA6mg10mxU"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
