{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p4zaa/OTTO-Multi-Objective-Recommender-System/blob/main/%5BDEVELOP1_8%5D_OTTO_%E2%80%93_Multi_Objective_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yf2nIQqrAy8y"
      },
      "source": [
        "# Version Logs\n",
        "* [View in my Github](https://github.com/p4zaa/OTTO-Multi-Objective-Recommender-System)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import gc\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZTgGyHWwP0wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e56cb1e5-d5de-42b9-f55d-21e481a54dc3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m51.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m873.9/873.9 KB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m565.0/565.0 KB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YGBdYwXz-B9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "608e203d-6a29-4ead-b0a3-8f428dd541e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.0 KB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.0/86.0 KB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m92.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m77.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m53.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "import tqdm\n",
        "from collections import defaultdict\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "#import plotly.io as pio\n",
        "#import plotly.express as px\n",
        "#import plotly.graph_objects as go\n",
        "#from plotly.subplots import make_subplots\n",
        "#pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.loader import HGTLoader, NeighborLoader, LinkNeighborLoader\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "97P3ABJvXkB_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3efba9da-6073-4034-ad1a-4fa0072b38a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting polars\n",
            "  Downloading polars-0.15.14-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m38.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0.0 in /usr/local/lib/python3.8/dist-packages (from polars) (4.4.0)\n",
            "Installing collected packages: polars\n",
            "Successfully installed polars-0.15.14\n"
          ]
        }
      ],
      "source": [
        "!pip3 install -q torch torchvision torchaudio\n",
        "!pip install -U polars"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "17ePRXhpuuFE"
      },
      "outputs": [],
      "source": [
        "import polars as pl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "B0nqQodKXs7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96fd3925-ff62-4eb7-e912-8dfe90a443f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch CUDA Version is  11.6\n"
          ]
        }
      ],
      "source": [
        "print('Pytorch CUDA Version is ', torch.version.cuda)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "mwEe6Wxor7uB"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76_LytnFg0vB",
        "outputId": "608c8f3c-82b3-4410-cb33-6511b3a45e5c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Jan  9 13:44:23 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    10W /  70W |      3MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "  print('Not using a high-RAM runtime')\n",
        "else:\n",
        "  print('You are using a high-RAM runtime!')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KY_7dPR8g30J",
        "outputId": "47ae4c58-b6f4-4ec3-eff5-451ac6797c49"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Your runtime has 13.6 gigabytes of available RAM\n",
            "\n",
            "Not using a high-RAM runtime\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "xlaViVcbYSGa"
      },
      "outputs": [],
      "source": [
        "#!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "5eLnmtjpYCtk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b49e1d6-bf8e-4434-acde-a26c7058f006"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "torch.cuda.is_available()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Pa5S-Yu9b4OL"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "j7Gsb6xQ98eL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "42583afb-b7d5-4482-df72-794730cb9e2f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nfrom google.colab import files\\nfiles.upload() # expire any previous token(s) and upload recreated token\\n!rm -r ~/.kaggle\\n!mkdir ~/.kaggle\\n!mv ./kaggle.json ~/.kaggle/\\n!chmod 600 ~/.kaggle/kaggle.json\\n\\n!kaggle datasets list\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "'''\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "421Djk4r4qJy"
      },
      "outputs": [],
      "source": [
        "#!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!kaggle datasets download 'radek1/otto-train-and-test-data-for-local-validation' -p /content/drive/MyDrive/OTTO-Kaggle-Competition/for-local-validation/ --unzip"
      ],
      "metadata": {
        "id": "HGZUTRH07O5c"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "# Pandas\n",
        "#df = pd.read_parquet('/content/kaggle/train.parquet')\n",
        "\n",
        "# Polars\n",
        "#df = pl.read_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/dataset/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "#df = df.sample(frac=0.01, replace=False)\n",
        "\n",
        "# Polars\n",
        "#df = df.sample(frac=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save 1% dataset\n",
        "#df.write_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/train_frac0.01.parquet')\n",
        "\n",
        "# Load\n",
        "#df = pl.read_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/train_frac0.01.parquet')"
      ],
      "metadata": {
        "id": "MUnGtCTd-QoS"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "N-Q_j2wx7Omc"
      },
      "outputs": [],
      "source": [
        "#df = df.to_pandas()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df[df['aid'] == 1517085]"
      ],
      "metadata": {
        "id": "yLpk5Wg-lj1R"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "cdB8Tum90sZX"
      },
      "outputs": [],
      "source": [
        "#df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "I6SK6ahjEpy9"
      },
      "outputs": [],
      "source": [
        "#df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "h8hFppsb5cAW"
      },
      "outputs": [],
      "source": [
        "#df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OFhgeI-OgFEz"
      },
      "outputs": [],
      "source": [
        "#df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "ERcykcKRz4Ri",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7b362e60-7135-4c83-c302-cecb5cceaca6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# session index dict\\nsession = df['session'].unique()\\nsource_idx = {id:idx for idx, id in enumerate(session)}\\n\\n# aid(article id) index dict\\naid = df['aid'].unique()\\ntarget_idx = {id:idx for idx, id in enumerate(aid)}\\n\\n# Load data (deserialize)\\n#with open('/content/drive/MyDrive/OTTO-Kaggle-Competition/source_idx.pkl', 'rb') as file:\\n#    source_idx = pickle.load(file)\\n\\n#with open('/content/drive/MyDrive/OTTO-Kaggle-Competition/target_idx.pkl', 'rb') as file:\\n#    target_idx = pickle.load(file)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "'''\n",
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "\n",
        "# Load data (deserialize)\n",
        "#with open('/content/drive/MyDrive/OTTO-Kaggle-Competition/source_idx.pkl', 'rb') as file:\n",
        "#    source_idx = pickle.load(file)\n",
        "\n",
        "#with open('/content/drive/MyDrive/OTTO-Kaggle-Competition/target_idx.pkl', 'rb') as file:\n",
        "#    target_idx = pickle.load(file)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QvTKqD08lNFz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9bd19f6f-4ec8-401c-c39e-241d4ea17e0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nconnected = df[['session', 'aid']]\\nconnected['session'] = connected['session'].map(source_idx)\\nconnected['aid'] = connected['aid'].map(target_idx)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "'''\n",
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "4L_GWK4hlTWM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "55b49c71-ef39-4715-ec66-e3cc5d19239c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nsource = connected['session']\\ntarget = connected['aid']\\nedge_index = torch.tensor((source.values, target.values))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "'''\n",
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del connected\n",
        "#gc.collect()"
      ],
      "metadata": {
        "id": "usXDAgHejMUN"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index = torch.load('/content/drive/MyDrive/OTTO-Kaggle-Competition/session-aid_edges_train_and_test.pt')"
      ],
      "metadata": {
        "id": "wKJY4ZbU0Zcl"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "edge_label = torch.load('/content/drive/MyDrive/OTTO-Kaggle-Competition/edge_label_session-aid_edges_train_and_test.pt')"
      ],
      "metadata": {
        "id": "btlINongAnq9"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "Nl_tLvXkFVmG"
      },
      "outputs": [],
      "source": [
        "#df['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = len(edge_index[0].unique()) #df['session'].nunique()\n",
        "aid_num_nodes = len(edge_index[1].unique()) #df['aid'].nunique()\n",
        "#session_id = torch.tensor(list(source_idx.values()), dtype=torch.int64)\n",
        "\n",
        "aid_features = torch.rand((aid_num_nodes, 32)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "#aid_id = torch.tensor(list(target_idx.values()), dtype=torch.int64)\n",
        "#aid_features = torch.nn.Embedding(aid_num_nodes, 32)\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = edge_label #torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del df\n",
        "#gc.collect()"
      ],
      "metadata": {
        "id": "9kR2R3WCvpG_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes,\n",
        "        #'node_id': session_id\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features,\n",
        "        #'node_id': aid_id\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "gGH8Sd8O97x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3678b1f3-78e2-4460-c3f7-b6099fb05f4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ num_nodes=14571582 },\n",
              "  \u001b[1maid\u001b[0m={ x=[1855603, 32] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 223644219],\n",
              "    edge_label=[223644219]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "9F9gevNn-Ms3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1991ba48-21bc-4c63-ef4e-414c4d26b3ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del source, target, edge_index, edge_label\n",
        "#gc.collect()"
      ],
      "metadata": {
        "id": "EiKJB1ai_H-z"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "TArUgtyn-OZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45dc5dac-4c5d-49d1-e8bc-da68b8979bd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "wQNhuNgM-Tar"
      },
      "outputs": [],
      "source": [
        "#print('Isolated nodes?', data.has_isolated_nodes())\n",
        "#print('Self loops?', data.has_self_loops())\n",
        "#print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 32)\n",
        "#data['session'].x = torch.nn.Embedding(data['session'].num_nodes, 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "d50QCHYyKBNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44772bbb-1647-4c08-c330-38f24009e2fd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=14571582,\n",
              "    x=[14571582, 32]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[1855603, 32] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 223644219],\n",
              "    edge_label=[223644219]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 223644219] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SV6330E6VmlW"
      },
      "source": [
        "### Mini Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "bExrskfWXv8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3523403-9190-4677-e35a-8e91db25200e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    num_nodes=811,\n",
            "    x=[811, 32]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={ x=[762, 32] },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 697],\n",
            "    edge_label=[128],\n",
            "    edge_label_index=[2, 128],\n",
            "    input_id=[128]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 750] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define seed edges:\n",
        "edge_label_index = train_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = train_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,  # TODO\n",
        "    num_neighbors=[3, 1],  # TODO\n",
        "    neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Inspect a sample:\n",
        "sampled_data = next(iter(train_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label_index.size(1) == 128\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.min() == 0\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.max() == 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "4N6oASmHaoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e27902c6-5549-419a-f990-253e9b3ace63"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5114, 38.9320])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.ModuleList([\n",
        "            SAGEConv((-1, -1), hidden_channels),\n",
        "            SAGEConv((-1, -1), out_channels)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for layer in self.layers:\n",
        "            x = layer(x, edge_index)\n",
        "        return x.relu()\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.layers = torch.nn.Sequential(\n",
        "            torch.nn.Linear(2 * hidden_channels, hidden_channels),\n",
        "            torch.nn.BatchNorm1d(hidden_channels),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_channels, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        return self.layers(z).view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # encoder and decoder\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "        # embedding matrices for sessions and aids\n",
        "        self.aid_lin = torch.nn.Linear(hidden_channels, hidden_channels)\n",
        "        self.session_emb = torch.nn.Embedding(data['session'].num_nodes, hidden_channels)\n",
        "        self.aid_emb = torch.nn.Embedding(data['aid'].num_nodes, hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        #x_dict = {\n",
        "        #    'session': self.session_emb(data['session'].node_id),\n",
        "        #    'aid': self.aid_lin(data['aid'].x.float()) + self.aid_emb(data['aid'].node_id)\n",
        "        #}\n",
        "        #x_dict = x_dict.copy()\n",
        "        #x_dict['session'] = self.session_emb.weight\n",
        "        #x_dict['aid'] = self.aid_emb.weight\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "id": "HShMqjU1wdBC",
        "outputId": "10225214-9ace-4e6e-f264-5b0f2f532b5c"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass GNNEncoder(torch.nn.Module):\\n    def __init__(self, hidden_channels, out_channels):\\n        super().__init__()\\n        self.layers = torch.nn.ModuleList([\\n            SAGEConv((-1, -1), hidden_channels),\\n            SAGEConv((-1, -1), out_channels)\\n        ])\\n\\n    def forward(self, x, edge_index):\\n        for layer in self.layers:\\n            x = layer(x, edge_index)\\n        return x.relu()\\n\\nclass EdgeDecoder(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        self.layers = torch.nn.Sequential(\\n            torch.nn.Linear(2 * hidden_channels, hidden_channels),\\n            torch.nn.BatchNorm1d(hidden_channels),\\n            torch.nn.ReLU(),\\n            torch.nn.Linear(hidden_channels, 1)\\n        )\\n\\n    def forward(self, z_dict, edge_label_index):\\n        row, col = edge_label_index\\n        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\\n        return self.layers(z).view(-1)\\n\\nclass Model(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        # encoder and decoder\\n        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\\n        self.decoder = EdgeDecoder(hidden_channels)\\n\\n        # embedding matrices for sessions and aids\\n        self.aid_lin = torch.nn.Linear(hidden_channels, hidden_channels)\\n        self.session_emb = torch.nn.Embedding(data['session'].num_nodes, hidden_channels)\\n        self.aid_emb = torch.nn.Embedding(data['aid'].num_nodes, hidden_channels)\\n\\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\\n        #x_dict = {\\n        #    'session': self.session_emb(data['session'].node_id),\\n        #    'aid': self.aid_lin(data['aid'].x.float()) + self.aid_emb(data['aid'].node_id)\\n        #}\\n        #x_dict = x_dict.copy()\\n        #x_dict['session'] = self.session_emb.weight\\n        #x_dict['aid'] = self.aid_emb.weight\\n        z_dict = self.encoder(x_dict, edge_index_dict)\\n        return self.decoder(z_dict, edge_label_index)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        # encoder and decoder\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "        # embedding matrices for sessions and aids\n",
        "        #self.aid_lin = Linear(hidden_channels, hidden_channels)\n",
        "        #self.session_emb = torch.nn.Embedding(data['session'].num_nodes, hidden_channels)\n",
        "        #self.aid_emb = torch.nn.Embedding(data['aid'].num_nodes, hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        #x_dict = {\n",
        "        #    'session': self.session_emb(data['session'].node_id.to(device)),\n",
        "        #    'aid': self.aid_lin(data['aid'].x.to(device).float()) + self.aid_emb(data['aid'].node_id.to(device))\n",
        "        #}\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "\n",
        "    def get_embedding(self, x_dict, edge_index_dict):\n",
        "        return self.encoder(x_dict, edge_index_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "ZENXvG8wealJ"
      },
      "outputs": [],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "\n",
        "sampled = next(iter(train_loader))\n",
        "\n",
        "with torch.no_grad():\n",
        "    model.encoder(sampled_data.to(device).x_dict, sampled_data.to(device).edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "del sampled, optimizer\n",
        "gc.collect()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsWQWHOHAFGS",
        "outputId": "8d90f589-a533-4665-aef8-b358f4cc146f"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "280"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "ayGHaB6JegtI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "892ecdf8-0fac-412c-fcfd-2fac75b74fa5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train():\\n    model.train()\\n    optimizer.zero_grad()\\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\\n                 train_data['session', 'aid'].edge_label_index)\\n    target = train_data['session', 'aid'].edge_label\\n    loss = weighted_mse_loss(pred, target, weight)\\n    loss.backward()\\n    optimizer.step()\\n    return float(loss)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "'''\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "RIjLW5AteiWZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "470ba75f-d34a-41ac-caa3-53baba983f11"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef test(data):\\n    model.eval()\\n    pred = model(data.x_dict, data.edge_index_dict,\\n                 data['session', 'aid'].edge_label_index)\\n    pred = pred.clamp(min=-1, max=2)\\n    target = data['session', 'aid'].edge_label.float()\\n    rmse = F.mse_loss(pred, target).sqrt()\\n    return float(rmse)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=-1, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "iG6cTQvOi70X"
      },
      "outputs": [],
      "source": [
        "\n",
        "def train(train_data=sampled_data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data[('session', 'event', 'aid')].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight.to(device))\n",
        "    #loss = F.binary_cross_entropy_with_logits(pred, target)\n",
        "\n",
        "    # Embedding\n",
        "    emb_dict = model.get_embedding(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss), pred, model, emb_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def train(model, train_data):\n",
        "    edge_index_dict, edge_label_index, edge_label = train_data.edge_index_dict, train_data.edge_label_index, train_data.edge_label\n",
        "\n",
        "    pred = model(edge_index_dict, edge_label_index)\n",
        "    loss = F.binary_cross_entropy_with_logits(pred, edge_label.to(device).float())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return loss.item(), pred, model\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "xJFuT04qzDBT",
        "outputId": "3efb8f24-cd85-45e3-e141-f0199adaf927"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef train(model, train_data):\\n    edge_index_dict, edge_label_index, edge_label = train_data.edge_index_dict, train_data.edge_label_index, train_data.edge_label\\n\\n    pred = model(edge_index_dict, edge_label_index)\\n    loss = F.binary_cross_entropy_with_logits(pred, edge_label.to(device).float())\\n    loss.backward()\\n    optimizer.step()\\n\\n    return loss.item(), pred, model\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "31EopkIapWVk"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data=data):\n",
        "    model.eval()\n",
        "    #pred = model(data.x_dict, data.edge_index_dict,\n",
        "    #             data['session', 'aid'].edge_label_index)\n",
        "    pred = model(data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse), pred, target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(model=model, data=data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse), pred, target"
      ],
      "metadata": {
        "id": "9zB0PMV-fWVU"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZXrZJEknJAo"
      },
      "source": [
        "### [mini-batch] Training Heterogenous Link-level GNN"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data = data.to(device)"
      ],
      "metadata": {
        "id": "JS_YMaNyxNAM"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "hbuDkO-Nh8kA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 450
        },
        "outputId": "41decf23-f5b1-4e93-d145-da8a591e7af4"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: 'cuda'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 221179/1397777 [43:24<3:50:56, 84.91it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-59-36d8b75a7c0c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_data)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     pred = model(train_data.x_dict, train_data.edge_index_dict,\n\u001b[0m\u001b[1;32m      5\u001b[0m                  train_data[('session', 'event', 'aid')].edge_label_index)\n\u001b[1;32m      6\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-3b7243201da1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x_dict, edge_index_dict, edge_label_index)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;31m#}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mz_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_label_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-53-3b7243201da1>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, z_dict, edge_label_index)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mz_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mz_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'aid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "\n",
        "%%time\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "#model = Model(hidden_channels=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(0, 1):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        sampled_data = sampled_data.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        loss, pred, model, emb_dict = train(train_data=sampled_data)\n",
        "        #loss, pred, model = train(model=model, train_data=sampled_data)\n",
        "        # TODO: Move `sampled_data` to the respective `device`\n",
        "        # TODO: Run `forward` pass of the model\n",
        "        # TODO: Apply binary cross entropy via\n",
        "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
        "\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Save and load trained model"
      ],
      "metadata": {
        "id": "LoQpRVra1wVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/drive/MyDrive/OTTO-Kaggle-Competition/model_full_dataset.pt'"
      ],
      "metadata": {
        "id": "Rh1zgbIocu6X"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "joyCx1zCnzl2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f43786f-3654-4fe7-84d8-251a5050490c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ],
      "source": [
        "# Save the entire model\n",
        "torch.save(model, path)\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FV5XwXrhfbYT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "edddf008-f7b8-4743-c2d4-46a258b73993"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): Module(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): Module(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# Load the entire model\n",
        "model = torch.load(path, map_location=torch.device('cpu'))\n",
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.session_emb"
      ],
      "metadata": {
        "id": "v43RFc65Db3H"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2 = torch.load('/content/drive/MyDrive/OTTO-Kaggle-Competition/model_node2vec.pt')"
      ],
      "metadata": {
        "id": "Ke9G66EkKXT-"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model3 = torch.load('/content/drive/MyDrive/OTTO-Kaggle-Competition/model_frac0.1.pt')"
      ],
      "metadata": {
        "id": "n5RWkoYbLujf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "ia8AeaevVSQH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "464dd1ea-d30d-4285-d486-47aacb5452fb"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-66604a021f05>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "#data.x_dict"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model.get_embedding(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ],
      "metadata": {
        "id": "bBNzMoCZ9BZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2fbPqjTSINEG"
      },
      "outputs": [],
      "source": [
        "#model.encoder(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4bbKw80fs7A"
      },
      "outputs": [],
      "source": [
        "#trained_model.encoder(data.to(device).x_dict, data.to(device).edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model(val_data.to(device).x_dict,\n",
        "#      val_data.to(device).edge_index_dict,\n",
        "#      val_data['session', 'aid'].edge_label_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WTbyGz6d5Jf8",
        "outputId": "d972e733-2460-4890-cecb-7419574e962c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0536, 1.1028, 1.0545,  ..., 1.0439, 1.0466, 1.0864], device='cuda:0',\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trained_model(val_data.x_dict,\n",
        "#      val_data.edge_index_dict,\n",
        "#      val_data['session', 'aid'].edge_label_index)"
      ],
      "metadata": {
        "id": "OCh1KqnT5msU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QqiZlbCxnOcp"
      },
      "source": [
        "### Evaluate a Heterogenous Linklevel GNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "GzCtJihVnWKu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1695d29f-5fc1-4336-c57f-d5c9e68caf76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    num_nodes=48000,\n",
            "    x=[48000, 32]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={ x=[40592, 32] },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 50972],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    input_id=[384]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 68313] }\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = val_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,  # TODO\n",
        "    num_neighbors=[20, 10],  # TODO\n",
        "    #neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.min() >= 0\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.max() <= 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "bFGjR1IWpKqX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "outputId": "bf765e36-3333-408e-d37b-53a38a4a39ac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 113/58241 [00:21<3:07:05,  5.18it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-72-60c32773e726>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mground_truths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0msampled_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mground_truth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msampled_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1194\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1195\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1196\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1197\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/base.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/loader/link_loader.py\u001b[0m in \u001b[0;36mcollate_fn\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0minput_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEdgeSamplerInput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         out = self.link_sampler.sample_from_edges(\n\u001b[0m\u001b[1;32m    172\u001b[0m             input_data, neg_sampling=self.neg_sampling)\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36msample_from_edges\u001b[0;34m(self, index, **kwargs)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     ) -> Union[SamplerOutput, HeteroSamplerOutput]:\n\u001b[0;32m--> 345\u001b[0;31m         return edge_sample(index, self._sample, self.num_src_nodes,\n\u001b[0m\u001b[1;32m    346\u001b[0m                            \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_dst_nodes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisjoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m                            node_time=self.node_time, **kwargs)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36medge_sample\u001b[0;34m(index, sample_fn, num_src_nodes, num_dst_nodes, disjoint, input_type, node_time, neg_sampling)\u001b[0m\n\u001b[1;32m    492\u001b[0m                 }\n\u001b[1;32m    493\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 494\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msample_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed_time_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed_time_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;31m# Enhance `out` by label information ##################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/sampler/neighbor_sampler.py\u001b[0m in \u001b[0;36m_sample\u001b[0;34m(self, seed, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m                                      \u001b[0;34m\"Please install 'pyg-lib' for improved \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m                                      \"and optimized sampling routines.\")\n\u001b[0;32m--> 258\u001b[0;31m                 out = torch.ops.torch_sparse.hetero_neighbor_sample(\n\u001b[0m\u001b[1;32m    259\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnode_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    440\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# You need the labels to binarize\n",
        "labels = [0, 1, 2]\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        _, pred, ground_truth = test(model=model, data=sampled_data)\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(ground_truth)\n",
        "        # TODO: Collect predictions and ground-truths and write them into\n",
        "        # `preds` and `ground_truths`.\n",
        "        #raise NotImplementedError\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "\n",
        "# Binarize `pred` with shape (n_samples, n_classes)\n",
        "pred = label_binarize(pred.astype(int), classes=labels)\n",
        "\n",
        "# Binarize `ground_truth` with shape (n_samples, n_classes)\n",
        "ground_truth = label_binarize(ground_truth, classes=labels)\n",
        "\n",
        "#rmse = _\n",
        "auc = roc_auc_score(ground_truth, pred, multi_class='ovo', average='weighted')\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "#print('RMSE: ', rmse)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "wvliA4O-iRzu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#model = train"
      ],
      "metadata": {
        "id": "WDuQfHztjFw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#del data\n",
        "#gc.collect()"
      ],
      "metadata": {
        "id": "sdT6MuWSiXjH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXF9UUz-K8Ap",
        "outputId": "5737606f-3b95-4e11-aa5c-6b2ecc9146bf"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('embedding.weight',\n",
              "              tensor([[ 0.2494,  0.0784,  0.2418,  ...,  0.1685,  0.0085, -0.1500],\n",
              "                      [-0.0101,  0.1191,  0.1512,  ..., -0.2910,  0.0166,  0.1297],\n",
              "                      [-0.3570, -0.1713,  0.1843,  ...,  0.4919, -0.0062, -0.0136],\n",
              "                      ...,\n",
              "                      [-0.0022, -0.2023,  0.3768,  ..., -0.2536, -0.0839,  0.3394],\n",
              "                      [-0.5325, -0.3410,  0.0990,  ..., -0.5023,  0.2621, -0.5723],\n",
              "                      [-0.2530,  0.0381, -0.0338,  ..., -0.0348,  0.1333, -0.3346]],\n",
              "                     device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model2.state_dict()['embedding.weight'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rnuayjv9K_EX",
        "outputId": "bd33b157-dd72-421a-8fe7-fb981035a84c"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1855603, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDEZjTSwL874",
        "outputId": "170fd6ad-d074-4a81-ec8d-2f8289facab0"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('encoder.conv1.session__event__aid.lin_l.weight',\n",
              "              tensor([[ 0.2087,  0.1432,  0.1538,  ..., -0.1009, -0.1565, -0.0229],\n",
              "                      [ 0.0291,  0.0585,  0.0842,  ..., -0.0779,  0.2441,  0.2059],\n",
              "                      [-0.0990, -0.2112,  0.1550,  ...,  0.1726,  0.0990, -0.0743],\n",
              "                      ...,\n",
              "                      [-0.6443, -0.1546,  0.7859,  ...,  0.2159, -0.2733,  0.4864],\n",
              "                      [ 0.0192, -0.1633, -0.1616,  ..., -0.0184, -0.0451,  0.0491],\n",
              "                      [ 0.0087, -0.0999, -0.0022,  ...,  0.0833, -0.0433,  0.1291]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.session__event__aid.lin_l.bias',\n",
              "              tensor([-0.1622,  0.0261, -0.1761, -0.3527, -0.2081,  0.1091, -0.1533, -0.1407,\n",
              "                      -0.0246, -0.2430, -0.3877, -0.3214, -0.2803, -0.0109, -0.0713, -0.0145,\n",
              "                      -0.2210, -0.3043, -0.2705, -0.0762, -0.3324, -0.0199, -0.1911, -0.2275,\n",
              "                      -0.1850, -0.1097, -0.1846, -0.0931, -0.1312, -0.3004, -0.1640, -0.3208],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.session__event__aid.lin_r.weight',\n",
              "              tensor([[-0.1889, -0.1331, -0.0527,  ...,  0.0505, -0.0329,  0.0551],\n",
              "                      [-0.0039, -0.1661, -0.1123,  ...,  0.1088,  0.2104,  0.0665],\n",
              "                      [ 0.0228,  0.1042,  0.1505,  ...,  0.0042,  0.0529,  0.0755],\n",
              "                      ...,\n",
              "                      [-0.1325, -0.4230, -0.1225,  ...,  0.0448, -0.1711, -0.5527],\n",
              "                      [-0.2220, -0.2124,  0.0447,  ...,  0.0539,  0.2134, -0.1455],\n",
              "                      [-0.3432, -0.1086,  0.0907,  ...,  0.0368,  0.1335,  0.0363]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.aid__rev_event__session.lin_l.weight',\n",
              "              tensor([[-1.8731e-02, -2.4130e-02,  8.1425e-02,  ...,  5.2887e-02,\n",
              "                        2.4834e-01, -1.5963e-01],\n",
              "                      [-2.4414e-02,  8.8923e-02,  2.0488e-01,  ..., -1.8208e-02,\n",
              "                       -4.4356e-02,  1.2340e-02],\n",
              "                      [-1.3755e-01,  3.1791e-02,  3.3177e-02,  ...,  1.2495e-01,\n",
              "                        2.4103e-04, -1.9169e-01],\n",
              "                      ...,\n",
              "                      [-3.8076e-01, -4.1368e-02,  1.0674e-01,  ...,  6.2064e-02,\n",
              "                       -4.2804e-02, -8.7615e-02],\n",
              "                      [-2.7224e-02,  9.3784e-03, -2.6622e-02,  ..., -6.4237e-02,\n",
              "                        3.0850e-02, -2.8356e-02],\n",
              "                      [-2.0250e-01, -2.6808e-01, -6.3273e-03,  ...,  1.9693e-01,\n",
              "                        1.8673e-01, -5.8316e-02]], device='cuda:0')),\n",
              "             ('encoder.conv1.aid__rev_event__session.lin_l.bias',\n",
              "              tensor([-0.3194,  0.0120, -0.0929, -0.2073, -0.1362,  0.1075, -0.1714, -0.0903,\n",
              "                      -0.1869, -0.2924,  0.0922, -0.1759, -0.0697, -0.1317, -0.0741, -0.0219,\n",
              "                      -0.1163,  0.0410, -0.0763, -0.0414, -0.2131, -0.2432, -0.2489, -0.0090,\n",
              "                      -0.2397, -0.1329, -0.2254, -0.0559, -0.0943, -0.0783, -0.0958, -0.1759],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.aid__rev_event__session.lin_r.weight',\n",
              "              tensor([[ 0.2261,  0.0845,  0.1155,  ...,  0.0958, -0.0787, -0.1104],\n",
              "                      [ 0.0462, -0.0381,  0.1019,  ..., -0.0403, -0.2203,  0.0890],\n",
              "                      [ 0.0515, -0.1113,  0.0149,  ...,  0.1415,  0.0488,  0.1797],\n",
              "                      ...,\n",
              "                      [ 0.0116, -0.0128,  0.0432,  ...,  0.0492, -0.2136, -0.1448],\n",
              "                      [-0.2553,  0.0044, -0.0196,  ..., -0.0424,  0.0815,  0.0728],\n",
              "                      [-0.0970, -0.0816, -0.0596,  ...,  0.1154, -0.0552, -0.0515]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.session__event__aid.lin_l.weight',\n",
              "              tensor([[ 0.0438,  0.1545,  0.2779,  ..., -0.1441,  0.2994, -0.0402],\n",
              "                      [ 0.1279, -0.0198,  0.1526,  ...,  0.2520, -0.0634,  0.2289],\n",
              "                      [ 0.0372, -0.0070,  0.1381,  ..., -0.0444,  0.0522,  0.0112],\n",
              "                      ...,\n",
              "                      [-0.0770,  0.0212, -0.0129,  ..., -0.1326, -0.3930,  0.0608],\n",
              "                      [ 0.2049,  0.0681,  0.0444,  ...,  0.1103,  0.0670,  0.2075],\n",
              "                      [-0.1619, -0.1273, -0.0830,  ..., -0.0313, -0.0578, -0.1016]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.session__event__aid.lin_l.bias',\n",
              "              tensor([-0.2621, -0.0058, -0.1005,  0.1960,  0.1583, -0.1574, -0.1347,  0.3332,\n",
              "                       0.1338,  0.4754, -0.0019, -0.2343,  0.0148, -0.0212, -0.2320, -0.1311,\n",
              "                       0.1238, -0.1922, -0.0267, -0.2860, -0.3363,  0.3032,  0.0613,  0.5464,\n",
              "                       0.0817,  0.3757,  0.3434,  0.0423, -0.0455,  0.1756,  0.3133,  0.0272],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.session__event__aid.lin_r.weight',\n",
              "              tensor([[ 0.0123, -0.0808, -0.0088,  ...,  0.1559,  0.0236,  0.0299],\n",
              "                      [ 0.0706, -0.1374,  0.0902,  ..., -0.1353,  0.0512,  0.0763],\n",
              "                      [ 0.1111, -0.1083,  0.1263,  ..., -0.3225, -0.0246,  0.0847],\n",
              "                      ...,\n",
              "                      [ 0.0716, -0.1471, -0.0222,  ..., -0.2300,  0.1285,  0.0096],\n",
              "                      [ 0.0555,  0.0540, -0.0983,  ..., -0.1237,  0.0433,  0.1740],\n",
              "                      [-0.0370, -0.0653, -0.1371,  ...,  0.1456, -0.0180, -0.0457]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.aid__rev_event__session.lin_l.weight',\n",
              "              tensor([[ 0.1636, -0.1791,  0.0309,  ..., -0.0939,  0.0565, -0.0998],\n",
              "                      [ 0.0189, -0.0530,  0.0669,  ..., -0.0639,  0.0350, -0.0240],\n",
              "                      [ 0.0062,  0.0534, -0.1026,  ..., -0.0545,  0.0220,  0.1161],\n",
              "                      ...,\n",
              "                      [-0.0049, -0.2262, -0.0976,  ..., -0.1714, -0.1631,  0.0527],\n",
              "                      [-0.0734,  0.0845,  0.0989,  ..., -0.0625, -0.1293,  0.0638],\n",
              "                      [ 0.0562,  0.1421, -0.1173,  ...,  0.0461, -0.2206, -0.0174]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.aid__rev_event__session.lin_l.bias',\n",
              "              tensor([ 0.0572,  0.3444,  0.3531, -0.0963,  0.3585,  0.2867,  0.1895, -0.2957,\n",
              "                      -0.2602, -0.0087,  0.2069,  0.3474,  0.0683, -0.0048,  0.3124,  0.1416,\n",
              "                      -0.2863,  0.4303, -0.1355,  0.0048,  0.0952, -0.0340, -0.0237, -0.0917,\n",
              "                      -0.3444,  0.1881, -0.0393, -0.1875,  0.0220,  0.2562, -0.0005, -0.0102],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.aid__rev_event__session.lin_r.weight',\n",
              "              tensor([[-0.1334, -0.2050,  0.1020,  ..., -0.0419,  0.0167,  0.0555],\n",
              "                      [ 0.0872, -0.1505, -0.0318,  ...,  0.0382,  0.0256,  0.1778],\n",
              "                      [ 0.1988,  0.0870,  0.0766,  ..., -0.1381,  0.0054,  0.0066],\n",
              "                      ...,\n",
              "                      [-0.0741,  0.1877, -0.0777,  ..., -0.0935, -0.2388,  0.0767],\n",
              "                      [ 0.0324, -0.0464, -0.0285,  ...,  0.0140,  0.0642,  0.0257],\n",
              "                      [ 0.0495, -0.0429, -0.0515,  ...,  0.0818, -0.0351, -0.1509]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin1.weight',\n",
              "              tensor([[ 0.0551,  0.0076, -0.0605,  ..., -0.0688,  0.1375,  0.0187],\n",
              "                      [-0.0315, -0.1026,  0.0206,  ..., -0.0004, -0.1066, -0.0702],\n",
              "                      [-0.0285, -0.0128, -0.1208,  ...,  0.0381,  0.0525, -0.0783],\n",
              "                      ...,\n",
              "                      [-0.2215, -0.1723, -0.3368,  ..., -0.1251, -0.2118, -0.0792],\n",
              "                      [ 0.0534,  0.0005, -0.1028,  ..., -0.1263,  0.0650,  0.0019],\n",
              "                      [ 0.2199, -0.0748,  0.0688,  ..., -0.0585, -0.1647, -0.0196]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin1.bias',\n",
              "              tensor([-0.0961, -0.2193, -0.0634,  0.2738, -0.1562,  0.0632,  0.0226, -0.2063,\n",
              "                      -0.2345,  0.0461, -0.1665,  0.4993,  0.1691, -0.2796, -0.1039,  0.0113,\n",
              "                       0.0094,  0.3434,  0.5918, -0.0151, -0.1531, -0.1593, -0.1291, -0.2709,\n",
              "                       0.5020, -0.0508, -0.0485,  0.2788, -0.1962, -0.2502, -0.0171,  0.0417],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin2.weight',\n",
              "              tensor([[ 0.0589,  0.0156,  0.0622,  0.0424,  0.0922, -0.0003,  0.0006,  0.0278,\n",
              "                        0.1764,  0.0474,  0.0932,  0.0959,  0.1001,  0.0484,  0.0139,  0.0056,\n",
              "                        0.0633,  0.0320,  0.1546,  0.1859,  0.0675, -0.0131,  0.0470,  0.1089,\n",
              "                        0.0576,  0.0201,  0.0072,  0.0494,  0.0321,  0.0060,  0.0189,  0.0084]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin2.bias', tensor([0.7250], device='cuda:0')),\n",
              "             ('aid_lin.weight',\n",
              "              tensor([[ 0.0637,  0.2672,  0.1521,  ...,  0.1945,  0.3094, -0.0150],\n",
              "                      [-0.1466,  0.1106,  0.1543,  ...,  0.2119,  0.1533, -0.1809],\n",
              "                      [ 0.1283,  0.0786, -0.1397,  ...,  0.0688,  0.0173,  0.1688],\n",
              "                      ...,\n",
              "                      [ 0.1633, -0.0122,  0.0751,  ..., -0.0046, -0.1419,  0.1015],\n",
              "                      [-0.0874, -0.1080,  0.0793,  ...,  0.0733,  0.0601,  0.0606],\n",
              "                      [ 0.1414,  0.2000,  0.0526,  ...,  0.1524, -0.0287,  0.0725]],\n",
              "                     device='cuda:0')),\n",
              "             ('aid_lin.bias',\n",
              "              tensor([ 0.2987, -0.1176, -0.0013,  0.0061, -0.0928, -0.1530,  0.1691, -0.0089,\n",
              "                       0.0203, -0.0863,  0.0873, -0.0821,  0.1000,  0.0066,  0.2086,  0.2242,\n",
              "                      -0.0353,  0.0867, -0.1581,  0.1469,  0.1367,  0.0421,  0.0970,  0.0466,\n",
              "                       0.0284,  0.0737,  0.2636,  0.0740, -0.0005,  0.0358, -0.0580, -0.0302],\n",
              "                     device='cuda:0')),\n",
              "             ('session_emb.weight',\n",
              "              tensor([[ 0.0088, -0.2136,  2.2863,  ..., -0.8041, -0.8302, -1.2617],\n",
              "                      [-0.6931,  1.3209,  0.6545,  ...,  0.4226, -1.4201,  0.0290],\n",
              "                      [ 0.9325,  0.3119, -0.0734,  ...,  0.4531,  0.3698, -1.0527],\n",
              "                      ...,\n",
              "                      [ 0.2160,  0.2387, -0.9321,  ...,  0.6372, -0.9136, -1.7406],\n",
              "                      [ 0.7148, -1.8551, -0.6224,  ..., -1.0549,  0.2444, -0.1544],\n",
              "                      [ 1.1330,  1.6000,  1.1349,  ...,  0.1240,  0.5495, -0.5218]],\n",
              "                     device='cuda:0')),\n",
              "             ('aid_emb.weight',\n",
              "              tensor([[-0.6209, -0.0749,  0.7380,  ..., -1.4550,  0.6630, -1.5567],\n",
              "                      [-1.1837, -0.7782, -0.7135,  ...,  0.9014, -0.7135,  0.1882],\n",
              "                      [ 0.7989,  0.1377, -1.1044,  ..., -0.9770,  1.1871, -0.1426],\n",
              "                      ...,\n",
              "                      [ 0.2102,  0.0435,  0.1938,  ...,  0.3167,  1.3778, -1.9226],\n",
              "                      [ 0.0549, -2.5622, -0.6507,  ..., -0.9573, -1.8388, -2.5520],\n",
              "                      [ 1.3863, -1.8831,  0.5630,  ..., -0.2744,  0.9979,  0.8065]],\n",
              "                     device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model3.state_dict()['encoder.conv2.session__event__aid.lin_l.weight'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvJxv0k8MF_-",
        "outputId": "6ac14a75-07df-4812-cfb8-40980e76432b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "id": "c7e2S_TJjKcV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a0a47f3-6071-49c6-8568-ef7e73fad556"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('encoder.conv1.session__event__aid.lin_l.weight',\n",
              "              tensor([[-0.1586,  0.0805, -0.1247,  ...,  0.1056,  0.0450,  0.0194],\n",
              "                      [-0.2260,  0.0898, -0.0476,  ..., -0.0876,  0.0161, -0.0265],\n",
              "                      [-0.0876, -0.1565,  0.1321,  ...,  0.0678, -0.0924,  0.0265],\n",
              "                      ...,\n",
              "                      [-0.0777,  0.0588, -0.0452,  ..., -0.1548,  0.0844, -0.1329],\n",
              "                      [ 0.0378, -0.1818,  0.0156,  ...,  0.0212,  0.1374, -0.1866],\n",
              "                      [-0.0321, -0.1472,  0.1248,  ..., -0.0274,  0.0790, -0.1516]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.session__event__aid.lin_l.bias',\n",
              "              tensor([-0.1938, -0.1329, -0.1203, -0.1646,  0.0737, -0.1332,  0.0782,  0.1005,\n",
              "                      -0.1241, -0.0613, -0.3342, -0.0192, -0.0933, -0.1976,  0.0037, -0.0312,\n",
              "                      -0.1802, -0.0310, -0.0718,  0.0525,  0.0502,  0.1002, -0.1570, -0.0791,\n",
              "                      -0.2205, -0.1283, -0.0700, -0.0726,  0.0054,  0.0011, -0.0856,  0.0381],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.session__event__aid.lin_r.weight',\n",
              "              tensor([[-0.1089, -0.2198,  0.1260,  ..., -0.0013, -0.2363, -0.1089],\n",
              "                      [ 0.0239, -0.1219,  0.0167,  ...,  0.0124, -0.0414, -0.2182],\n",
              "                      [ 0.1174,  0.0274, -0.0748,  ..., -0.1371,  0.0596, -0.1717],\n",
              "                      ...,\n",
              "                      [-0.0438,  0.0119,  0.0367,  ...,  0.0535,  0.0906, -0.2095],\n",
              "                      [ 0.1137, -0.1103, -0.0022,  ...,  0.1062,  0.0451, -0.0453],\n",
              "                      [-0.0479, -0.0682,  0.0009,  ..., -0.1862, -0.2001, -0.0423]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.aid__rev_event__session.lin_l.weight',\n",
              "              tensor([[-0.1936, -0.1113, -0.0630,  ..., -0.2000, -0.0791,  0.1141],\n",
              "                      [ 0.0038,  0.1113, -0.2201,  ...,  0.0916,  0.0585, -0.1881],\n",
              "                      [-0.2176, -0.2972, -0.0250,  ..., -0.1992,  0.0512, -0.0786],\n",
              "                      ...,\n",
              "                      [ 0.1324,  0.1061, -0.0464,  ..., -0.0324, -0.1957,  0.1293],\n",
              "                      [ 0.1209, -0.0287,  0.1317,  ...,  0.0848,  0.0619, -0.0541],\n",
              "                      [-0.1584, -0.1237,  0.0852,  ..., -0.1460, -0.1522, -0.2241]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.aid__rev_event__session.lin_l.bias',\n",
              "              tensor([ 0.0484, -0.1189, -0.1229,  0.0969, -0.0206, -0.0606, -0.0486, -0.0763,\n",
              "                      -0.0366,  0.0428, -0.2203, -0.2231,  0.0789,  0.0035, -0.1774,  0.0280,\n",
              "                      -0.0719,  0.1350, -0.1171,  0.0816, -0.1362, -0.1565,  0.0368, -0.2227,\n",
              "                       0.0347, -0.0926, -0.1446,  0.1074, -0.2254, -0.0414,  0.0256, -0.1174],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv1.aid__rev_event__session.lin_r.weight',\n",
              "              tensor([[-0.1315, -0.0591, -0.0055,  ...,  0.0510,  0.0534, -0.2230],\n",
              "                      [ 0.1322, -0.0775, -0.1287,  ...,  0.1269, -0.2070, -0.0259],\n",
              "                      [-0.0686, -0.0886, -0.0597,  ..., -0.2946, -0.0401, -0.2031],\n",
              "                      ...,\n",
              "                      [ 0.0371, -0.0955, -0.0398,  ..., -0.0006, -0.2436, -0.0484],\n",
              "                      [ 0.0906,  0.0628, -0.1768,  ..., -0.1211, -0.1549,  0.0738],\n",
              "                      [ 0.0171, -0.1795, -0.1934,  ..., -0.1303, -0.1316,  0.0268]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.session__event__aid.lin_l.weight',\n",
              "              tensor([[-0.2266,  0.0685, -0.0226,  ..., -0.0228, -0.0562, -0.0050],\n",
              "                      [-0.2022, -0.2063, -0.1497,  ...,  0.0551,  0.0366, -0.0392],\n",
              "                      [ 0.2239, -0.0436,  0.0281,  ..., -0.0462, -0.0675,  0.0062],\n",
              "                      ...,\n",
              "                      [ 0.0891, -0.0356,  0.0306,  ..., -0.0778, -0.0241, -0.0424],\n",
              "                      [ 0.2287, -0.0055,  0.0743,  ..., -0.0876,  0.0158,  0.0376],\n",
              "                      [-0.0522, -0.1404,  0.2202,  ...,  0.0515,  0.1189,  0.1429]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.session__event__aid.lin_l.bias',\n",
              "              tensor([-0.0596, -0.0925, -0.1619, -0.1205,  0.1100, -0.1616, -0.0450, -0.0828,\n",
              "                       0.0721,  0.0037,  0.0301,  0.0412, -0.0243, -0.1637, -0.1184,  0.0758,\n",
              "                      -0.0871,  0.0923,  0.0813, -0.0987, -0.0852,  0.0652,  0.0485,  0.0635,\n",
              "                      -0.1792, -0.0264, -0.1012,  0.0457, -0.0465,  0.0155,  0.0305, -0.0513],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.session__event__aid.lin_r.weight',\n",
              "              tensor([[-0.1351,  0.0537,  0.0085,  ...,  0.0942, -0.1150,  0.2580],\n",
              "                      [ 0.1704, -0.2163, -0.1122,  ..., -0.0057, -0.0633, -0.0118],\n",
              "                      [ 0.0973,  0.2017,  0.1081,  ..., -0.1890,  0.0448, -0.2530],\n",
              "                      ...,\n",
              "                      [-0.0403, -0.1370,  0.1031,  ..., -0.1457,  0.1029, -0.1794],\n",
              "                      [-0.0555,  0.2434,  0.0750,  ..., -0.0999, -0.0540, -0.0073],\n",
              "                      [ 0.0133,  0.0811, -0.0840,  ..., -0.0703,  0.0079,  0.0804]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.aid__rev_event__session.lin_l.weight',\n",
              "              tensor([[-0.1807, -0.1101, -0.0500,  ..., -0.0133,  0.0256, -0.0294],\n",
              "                      [ 0.1008, -0.0445, -0.0640,  ...,  0.0638,  0.1449, -0.1396],\n",
              "                      [ 0.0227,  0.1067,  0.1116,  ...,  0.0318,  0.1001,  0.0719],\n",
              "                      ...,\n",
              "                      [-0.1855,  0.1833, -0.0356,  ...,  0.1008, -0.0283, -0.1567],\n",
              "                      [ 0.0041, -0.2045, -0.0173,  ..., -0.0940,  0.0612, -0.0130],\n",
              "                      [ 0.0952,  0.1352,  0.1242,  ..., -0.1484,  0.0683,  0.0856]],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.aid__rev_event__session.lin_l.bias',\n",
              "              tensor([ 0.1490, -0.0277,  0.0207, -0.1314,  0.1363, -0.0298, -0.0371, -0.0228,\n",
              "                       0.0097,  0.1102, -0.1166,  0.1341,  0.0571,  0.0707, -0.0556,  0.0604,\n",
              "                      -0.1286, -0.0101,  0.1827, -0.0543, -0.0803,  0.0521, -0.1129,  0.0002,\n",
              "                       0.0468, -0.0810, -0.0078,  0.0451, -0.0312,  0.1211, -0.0170,  0.0555],\n",
              "                     device='cuda:0')),\n",
              "             ('encoder.conv2.aid__rev_event__session.lin_r.weight',\n",
              "              tensor([[-0.2258, -0.0043, -0.0747,  ...,  0.1000,  0.1063, -0.0080],\n",
              "                      [ 0.0147,  0.1108,  0.0515,  ...,  0.0901, -0.0049, -0.0774],\n",
              "                      [-0.1714, -0.2135,  0.1708,  ...,  0.0558, -0.0283, -0.1356],\n",
              "                      ...,\n",
              "                      [ 0.0175,  0.0855,  0.0600,  ...,  0.1694, -0.0672, -0.1253],\n",
              "                      [-0.1878,  0.0058,  0.0673,  ..., -0.0276, -0.0230,  0.1242],\n",
              "                      [-0.0201,  0.1135,  0.1008,  ..., -0.0767, -0.1515,  0.1113]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin1.weight',\n",
              "              tensor([[-0.4409, -0.3203, -0.4113,  ..., -0.3741,  0.2554, -0.2260],\n",
              "                      [ 0.0117, -0.0988, -0.1333,  ...,  0.0547, -0.0551,  0.0186],\n",
              "                      [ 0.0330,  0.0555,  0.0259,  ..., -0.0255,  0.1904, -0.0832],\n",
              "                      ...,\n",
              "                      [-0.0802,  0.0042,  0.0178,  ..., -0.0222, -0.0493, -0.0152],\n",
              "                      [-0.1559,  0.0667,  0.0684,  ...,  0.0121, -0.0323, -0.0430],\n",
              "                      [-0.0953,  0.0843,  0.0532,  ...,  0.0585,  0.0199,  0.1117]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin1.bias',\n",
              "              tensor([-0.2829, -0.0451, -0.0805, -0.2942, -0.0848, -0.3282, -0.1737,  0.1343,\n",
              "                      -0.1622, -0.1680, -0.0914,  0.0227, -0.1540, -0.0815, -0.2002, -0.0851,\n",
              "                      -0.1427, -0.0333, -0.1451, -0.2385, -0.3907, -0.3005, -0.0797, -0.1438,\n",
              "                      -0.2408, -0.0737, -0.1630, -0.2539, -0.0264, -0.0770, -0.1627,  0.2073],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin2.weight',\n",
              "              tensor([[ 0.2549,  0.0509,  0.0881, -0.2345, -0.0600, -0.0010,  0.0385, -0.0173,\n",
              "                       -0.0294,  0.0144,  0.0174, -0.0694, -0.1297, -0.0074,  0.2421, -0.0749,\n",
              "                        0.0740,  0.0203,  0.0444, -0.2411, -0.2515, -0.0457, -0.1492, -0.1004,\n",
              "                       -0.0952,  0.0064,  0.1067,  0.1427,  0.0147,  0.1195,  0.0020, -0.0112]],\n",
              "                     device='cuda:0')),\n",
              "             ('decoder.lin2.bias', tensor([1.0044], device='cuda:0'))])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()['encoder.conv1.aid__rev_event__session.lin_l.weight'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FNIcr4gJQeB",
        "outputId": "885ed8af-d1ce-4cff-fadf-1f95261c3942"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 32])"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_edge_index(df):\n",
        "    return torch.tensor(np.transpose(df[['session', 'aid']].to_numpy()), dtype=torch.long)"
      ],
      "metadata": {
        "id": "xuBzeFc_NXRQ"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install annoy"
      ],
      "metadata": {
        "id": "-G6SUSA8nPxe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a586c37e-5dbf-458d-f2e5-9a835172b95b"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting annoy\n",
            "  Downloading annoy-1.17.1.tar.gz (647 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m648.0/648.0 KB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: annoy\n",
            "  Building wheel for annoy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for annoy: filename=annoy-1.17.1-cp38-cp38-linux_x86_64.whl size=394073 sha256=1b233cacfd31d0e2f004b40e7596ef65b8fcd35445a1a6505de99f8cca8a95af\n",
            "  Stored in directory: /root/.cache/pip/wheels/f9/93/19/30511c4a9ae6b4937455a134c34a39e13943e2c6f46fcd2ed2\n",
            "Successfully built annoy\n",
            "Installing collected packages: annoy\n",
            "Successfully installed annoy-1.17.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "from annoy import AnnoyIndex\n",
        "\n",
        "index = AnnoyIndex(32, metric='angular')\n",
        "\n",
        "for idx, idx_embedding in enumerate(model.state_dict()['encoder.conv2.session__event__aid.lin_r.weight'].cpu()):\n",
        "  index.add_item(idx, idx_embedding)\n",
        "\n",
        "index.build(10)"
      ],
      "metadata": {
        "id": "THcdpyqPilKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12a9590a-b15f-498f-9581-4737ba2be6f7"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 5.89 ms, sys: 0 ns, total: 5.89 ms\n",
            "Wall time: 5.22 ms\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#del model, loader, optimizer\n",
        "#gc.collect()\n",
        "#torch.cuda.empty_cache()"
      ],
      "metadata": {
        "id": "7C2rm1o7nePf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation/Inference"
      ],
      "metadata": {
        "id": "TEVRPeQOnkjm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# source_idx -> dict{id:idx}\n",
        "# target_idx -> dict{id:idx}"
      ],
      "metadata": {
        "id": "x3UFmE8srtJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(path,mode=\"validation\",n_neighbors=20):\n",
        "\n",
        "\n",
        "    test = pl.read_parquet(path)\n",
        "\n",
        "    session_types = ['clicks', 'carts', 'orders']\n",
        "\n",
        "    test_session_AIDs = test.to_pandas().reset_index(drop=True).groupby('session')['aid'].apply(list)\n",
        "    '''\n",
        "    session\n",
        "    12899779                                              [59625]\n",
        "    12899780           [1142000, 582732, 973453, 736515, 1142000]\n",
        "    12899781    [141736, 199008, 57315, 194067, 199008, 199008...\n",
        "    12899782    [1669402, 1494780, 1494780, 1494780, 1494780, ...\n",
        "    12899783    [255297, 1114789, 255297, 300127, 198385, 3001...\n",
        "                                      ...                        \n",
        "    14571577                                            [1141710]\n",
        "    14571578                                             [519105]\n",
        "    14571579                                             [739876]\n",
        "    14571580                                             [202353]\n",
        "    14571581                                            [1100210]\n",
        "    Name: aid, Length: 1671803, dtype: object\n",
        "    '''\n",
        "\n",
        "    test_session_types = test.to_pandas().reset_index(drop=True).groupby('session')['type'].apply(list)\n",
        "    '''\n",
        "    session\n",
        "    12899779                                                  [0]\n",
        "    12899780                                      [0, 0, 0, 0, 0]\n",
        "    12899781                    [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "    12899782    [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, ...\n",
        "    12899783                    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "                                      ...                        \n",
        "    14571577                                                  [0]\n",
        "    14571578                                                  [0]\n",
        "    14571579                                                  [0]\n",
        "    14571580                                                  [0]\n",
        "    14571581                                                  [0]\n",
        "    Name: type, Length: 1671803, dtype: object\n",
        "    '''\n",
        "\n",
        "    del test\n",
        "    gc.collect()\n",
        "\n",
        "    labels = []\n",
        "\n",
        "    type_weight_multipliers = {0: 1, 1: 6, 2: 3}\n",
        "\n",
        "    for AIDs, types in zip(test_session_AIDs, test_session_types):\n",
        "        # AIDs: list of connected aids in each session\n",
        "        # types: list of connected types in each session\n",
        "        if len(AIDs) >= 20: # this session have at least 20 aids connected\n",
        "            # if we have enough aids (over equals 20) we don't need to look for candidates! we just use the old logic\n",
        "            weights = np.logspace(0.1,1,len(AIDs), base=2, endpoint=True) - 1\n",
        "            aids_temp = defaultdict(lambda: 0)\n",
        "            for aid, w, t in zip(AIDs, weights, types): \n",
        "                # {aid : weight}\n",
        "                aids_temp[aid] += w * type_weight_multipliers[t]\n",
        "\n",
        "            # list of sorted dictionary key by value\n",
        "            sorted_aids = [k for k, v in sorted(aids_temp.items(), key=lambda item: -item[1])]\n",
        "            labels.append(sorted_aids[:20]) # only top 20\n",
        "        else:\n",
        "            # here we don't have 20 aids to output -- we will use word2vec embeddings to generate candidates!\n",
        "            AIDs = list(dict.fromkeys(AIDs[::-1]))\n",
        "\n",
        "            # let's grab the most recent aid\n",
        "            most_recent_aid = AIDs[0]\n",
        "\n",
        "            # and look for some neighbors!\n",
        "            nns = [i for i in index.get_nns_by_item(most_recent_aid, n_neighbors+1)[1:]]\n",
        "\n",
        "\n",
        "            labels.append((AIDs+nns)[:n_neighbors])\n",
        "\n",
        "    labels_as_strings = [' '.join([str(l) for l in lls]) for lls in labels]\n",
        "\n",
        "    predictions = pd.DataFrame(data={'session_type': test_session_AIDs.index, 'labels': labels_as_strings})\n",
        "\n",
        "    prediction_dfs = []\n",
        "\n",
        "    for st in session_types:\n",
        "        modified_predictions = predictions.copy()\n",
        "        modified_predictions.session_type = modified_predictions.session_type.astype('str') + f'_{st}'\n",
        "        prediction_dfs.append(modified_predictions)\n",
        "\n",
        "    sub = pd.concat(prediction_dfs).reset_index(drop=True)\n",
        "    \n",
        "    del prediction_dfs, predictions,labels_as_strings, labels, test_session_types,test_session_AIDs\n",
        "    gc.collect()\n",
        "    if mode==\"test\":\n",
        "        sub.to_csv(\"submission.csv\",index=False)\n",
        "        return sub\n",
        "    else:\n",
        "\n",
        "        sub['labels_2'] = sub['labels'].apply(lambda x : [int(s) for s in x.split(' ')])\n",
        "        submission = pd.DataFrame()\n",
        "        submission['session'] = sub.session_type.apply(lambda x: int(x.split('_')[0]))\n",
        "        submission['type'] = sub.session_type.apply(lambda x: x.split('_')[1])\n",
        "        submission['labels'] = sub.labels_2.apply(lambda x : [item for item in x[:] ]) #.apply(lambda x: [int(i) for i in x.split(',')[:20]])\n",
        "        test_labels = pd.read_parquet('/content/drive/MyDrive/OTTO-Kaggle-Competition/for-local-validation/test_labels.parquet')\n",
        "        test_labels = test_labels.merge(submission, how='left', on=['session', 'type'])\n",
        "        del sub,submission\n",
        "        gc.collect()\n",
        "        gc.collect()\n",
        "        test_labels['hits'] = test_labels.apply(lambda df: len(set(df.ground_truth).intersection(set(df.labels))), axis=1)\n",
        "        test_labels['gt_count'] = test_labels.ground_truth.str.len().clip(0,20)\n",
        "        recall_per_type = test_labels.groupby(['type'])['hits'].sum() / test_labels.groupby(['type'])['gt_count'].sum() \n",
        "        score = (recall_per_type * pd.Series({'clicks': 0.1, 'carts': 0.30, 'orders': 0.60})).sum()\n",
        "\n",
        "        return score"
      ],
      "metadata": {
        "id": "4P_XMrqdnoQZ"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Validation"
      ],
      "metadata": {
        "id": "fkgS_6Sqntvw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"/content/drive/MyDrive/OTTO-Kaggle-Competition/for-local-validation/test.parquet\"\n",
        "validation_score = evaluate(path,mode=\"validation\",n_neighbors=20)"
      ],
      "metadata": {
        "id": "RaKu5eqLntJy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "outputId": "36af7858-172c-40bf-b8e2-a469d51be901"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4b69cdf5e838>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"/content/drive/MyDrive/OTTO-Kaggle-Competition/for-local-validation/test.parquet\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mvalidation_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"validation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-24-95bee18874b9>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(path, mode, n_neighbors)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;31m# and look for some neighbors!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nns_by_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_recent_aid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: Item index larger than the largest item index"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%debug"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY7gyqqlF3eS",
        "outputId": "4bf65d01-46dc-4a8a-fd7c-2f8d6cb2c8dd"
      },
      "execution_count": 26,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> \u001b[0;32m<ipython-input-24-95bee18874b9>\u001b[0m(71)\u001b[0;36mevaluate\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m     69 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     70 \u001b[0;31m            \u001b[0;31m# and look for some neighbors!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m---> 71 \u001b[0;31m            \u001b[0mnns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_nns_by_item\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmost_recent_aid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     72 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\u001b[0;32m     73 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0m\n",
            "ipdb> nns\n",
            "*** NameError: name 'nns' is not defined\n",
            "ipdb> index\n",
            "<annoy.Annoy object at 0x7fc347f1cd70>\n",
            "ipdb> most_recent_aid\n",
            "11830\n",
            "ipdb> index.get_nns_by_item(11830, 21)\n",
            "*** IndexError: Item index larger than the largest item index\n",
            "ipdb> index.size\n",
            "*** AttributeError: 'annoy.Annoy' object has no attribute 'size'\n",
            "ipdb> index.shape\n",
            "*** AttributeError: 'annoy.Annoy' object has no attribute 'shape'\n",
            "ipdb> df\n",
            "*** NameError: name 'df' is not defined\n",
            "ipdb> quit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "PYDEV DEBUGGER WARNING:\n",
            "sys.settrace() should not be used when the debugger is being used.\n",
            "This may cause the debugger to stop working correctly.\n",
            "If this is needed, please check: \n",
            "http://pydev.blogspot.com/2007/06/why-cant-pydev-debugger-work-with.html\n",
            "to see how to restore the debug tracing back correctly.\n",
            "Call Location:\n",
            "  File \"/usr/lib/python3.8/bdb.py\", line 359, in set_quit\n",
            "    sys.settrace(None)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(validation_score)"
      ],
      "metadata": {
        "id": "2L_kDadTn8hU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "ab96114a-b8aa-41d0-bb75-cdf90207bc6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c6a329f7ca58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_score\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'validation_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZw_TNkMQRaq"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFOSPOfhOjYr"
      },
      "source": [
        "Submission File\n",
        "For each `session` id and `type` combination in the test set, you must predict the `aid` values in the `label` column, which is space delimited. You can predict up to 20 `aid` values per row. The file should contain a header and have the following format:\n",
        "\n",
        "```\n",
        "session_type,labels\n",
        "12906577_clicks,135193 129431 119318 ...\n",
        "12906577_carts,135193 129431 119318 ...\n",
        "12906577_orders,135193 129431 119318 ...\n",
        "12906578_clicks, 135193 129431 119318 ...\n",
        "etc.\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BWyo1qVmOi8E"
      },
      "outputs": [],
      "source": [
        "path = \"/content/drive/MyDrive/OTTO-Kaggle-Competition/dataset/test.parquet\"\n",
        "test_submission = evaluate(path,mode=\"test\",n_neighbors=20)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_submission"
      ],
      "metadata": {
        "id": "_DYm3DoNEtDi"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "mount_file_id": "1-0RupSIL7Z5gO3VuaJmirDZn2uRPtGnd",
      "authorship_tag": "ABX9TyMai6CfGdRKNrCHKWmY8ymo",
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}