{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Version Logs\n",
        "* DEVELOP1.2: New code for modeling\n",
        "* [DEVELOP1.3](https://colab.research.google.com/drive/11m9ztUNqBqe4f8dAWDmJe_7IAIT3yJyv#scrollTo=aED_TAobTF6d): Add recommendation function and multiple edge types\n",
        "* DEVELOP1.4: Back to 1 edge type predicting the edges event - example [here](https://colab.research.google.com/drive/1ksnVuQBPZA7W0nbOokz6nqB0EdDKWOUk)\n",
        "---\n",
        "* [Example AutoEncoder.ipynb](https://colab.research.google.com/drive/1nyufporgJp-j4BqZ6jYwgdMLyz_bJ_es#scrollTo=WjdGbaa8LdU9)\n",
        "* [Recommender Systems with Graph Neural Networks in PyG](https://colab.research.google.com/drive/1qQEcYrzWJyJpAlwCMcJdFNPlYlyzHPdF#scrollTo=ktxdLosxtgZd)\n",
        "* https://blog.dataiku.com/graph-neural-networks-link-prediction-part-two"
      ],
      "metadata": {
        "id": "yf2nIQqrAy8y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "ZTgGyHWwP0wa"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "YGBdYwXz-B9e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j7Gsb6xQ98eL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "e0a2153f-1ee6-404c-8cc5-929ca68910a8"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-acfcca3a-ec25-4a83-b7ab-98dc9db2ac86\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-acfcca3a-ec25-4a83-b7ab-98dc9db2ac86\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "ref                                                             title                                           size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                       COVID-19 Dataset                                 5MB  2022-11-13 15:47:17          13122        373  1.0              \n",
            "thedevastator/analyzing-credit-card-spending-habits-in-india    Credit Card Spending Habits in India           319KB  2022-12-14 07:30:37            720         31  1.0              \n",
            "michals22/coffee-dataset                                        Coffee dataset                                  24KB  2022-12-15 20:02:12           2804         71  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data         E-Commerce Sales Dataset                         6MB  2022-12-03 09:27:17           2103         55  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                       Salary Prediction                                3MB  2022-11-16 13:52:31           7649        168  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset              Fifa World Cup 2022: Complete Dataset            7KB  2022-12-18 22:51:11           2328         98  1.0              \n",
            "mattop/highest-grossing-mobile-games                            Highest Grossing Mobile Games                    3KB  2022-12-19 15:20:22            405         23  1.0              \n",
            "thedevastator/uncover-global-trends-in-mental-health-disorder   Global Trends in Mental Health Disorder          1MB  2022-12-14 05:30:38            677         23  1.0              \n",
            "rajkumarpandey02/fifa-world-cup-attendance-19302022             FIFA World Cup Attendance 1930-2022              5KB  2022-12-19 10:04:26            729         21  1.0              \n",
            "thedevastator/revealing-insights-from-youtube-video-and-channe  YouTube Videos and Channels Metadata            82MB  2022-12-14 02:48:24            429         23  0.9411765        \n",
            "thedevastator/uncovering-insights-to-college-majors-and-their   College Majors and their Graduates              39KB  2022-12-06 16:06:52           1083         31  1.0              \n",
            "mvieira101/global-cost-of-living                                Global Cost of Living                            1MB  2022-12-03 16:37:53           3523         73  0.9705882        \n",
            "anashamoutni/students-employability-dataset                     Students' Employability Dataset - Philippines   97KB  2022-12-18 15:51:39            625         26  0.88235295       \n",
            "swaptr/fifa-world-cup-2022-statistics                           FIFA World Cup 2022 Team Data                   15KB  2022-12-19 00:29:15           2694         61  0.9705882        \n",
            "thedevastator/the-ultimate-netflix-tv-shows-and-movies-dataset  Netflix TV Shows and Movies (2022 Updated)       2MB  2022-11-27 20:41:41           2511         46  1.0              \n",
            "whenamancodes/predict-diabities                                 Predict Diabetes                                 9KB  2022-11-09 12:18:49           7970        122  1.0              \n",
            "kulturehire/understanding-career-aspirations-of-genz            Understanding Career Aspirations of GenZ         8KB  2022-12-21 13:44:32            241         23  0.9117647        \n",
            "thedevastator/uncovering-wage-disparities-in-pennsylvania-s-hi  Higher Education Wages                         223KB  2022-12-04 15:42:36           1277         40  1.0              \n",
            "laibaanwer/superstore-sales-dataset                             SuperStore Sales Dataset                         2MB  2022-12-07 08:53:32           1492         37  1.0              \n",
            "catherinerasgaitis/mxmh-survey-results                          Music & Mental Health Survey Results            22KB  2022-11-21 10:03:12           3173         75  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "421Djk4r4qJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e64499b5-cf7f-422f-fd96-35839d124a28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading otto-full-optimized-memory-footprint.zip to /content/kaggle\n",
            " 99% 1.08G/1.09G [00:11<00:00, 85.1MB/s]\n",
            "100% 1.09G/1.09G [00:11<00:00, 105MB/s] \n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('/content/kaggle/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "df = df.sample(frac=0.001, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "N-Q_j2wx7Omc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "209e52da-25a5-44c4-d830-77a55dcd2d8d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            session      aid          ts  type\n",
              "112853711   4161634  1677894  1659723108     0\n",
              "151256708   6574507  1746650  1660155471     0\n",
              "163415184   7544790  1446350  1660742742     0\n",
              "157145532   7025544  1383166  1660242950     0\n",
              "41255095    1042711    68160  1661510649     0\n",
              "...             ...      ...         ...   ...\n",
              "85486607    2741258  1740099  1660644873     0\n",
              "176111941   8662627  1100955  1660527907     0\n",
              "185700990   9549636   117997  1660726993     0\n",
              "70498786    2092358  1108416  1660978246     0\n",
              "208182854  11860335  1672452  1661364355     0\n",
              "\n",
              "[216716 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-43c6088b-17a3-44b0-afac-2da812f5090c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>112853711</th>\n",
              "      <td>4161634</td>\n",
              "      <td>1677894</td>\n",
              "      <td>1659723108</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151256708</th>\n",
              "      <td>6574507</td>\n",
              "      <td>1746650</td>\n",
              "      <td>1660155471</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163415184</th>\n",
              "      <td>7544790</td>\n",
              "      <td>1446350</td>\n",
              "      <td>1660742742</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157145532</th>\n",
              "      <td>7025544</td>\n",
              "      <td>1383166</td>\n",
              "      <td>1660242950</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41255095</th>\n",
              "      <td>1042711</td>\n",
              "      <td>68160</td>\n",
              "      <td>1661510649</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85486607</th>\n",
              "      <td>2741258</td>\n",
              "      <td>1740099</td>\n",
              "      <td>1660644873</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176111941</th>\n",
              "      <td>8662627</td>\n",
              "      <td>1100955</td>\n",
              "      <td>1660527907</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185700990</th>\n",
              "      <td>9549636</td>\n",
              "      <td>117997</td>\n",
              "      <td>1660726993</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70498786</th>\n",
              "      <td>2092358</td>\n",
              "      <td>1108416</td>\n",
              "      <td>1660978246</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208182854</th>\n",
              "      <td>11860335</td>\n",
              "      <td>1672452</td>\n",
              "      <td>1661364355</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216716 rows Ã— 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-43c6088b-17a3-44b0-afac-2da812f5090c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-43c6088b-17a3-44b0-afac-2da812f5090c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-43c6088b-17a3-44b0-afac-2da812f5090c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "I6SK6ahjEpy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1cd214d-a214-472a-d988-280c3330e7c4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session    0\n",
              "aid        0\n",
              "ts         0\n",
              "type       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "h8hFppsb5cAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de5d6b1e-1c06-43b2-dfb4-cf9e595ddeae"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "OFhgeI-OgFEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13c2516c-d0f8-4838-b7f7-e0e4cf861668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 216716 entries, 112853711 to 208182854\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count   Dtype\n",
            "---  ------   --------------   -----\n",
            " 0   session  216716 non-null  int32\n",
            " 1   aid      216716 non-null  int32\n",
            " 2   ts       216716 non-null  int32\n",
            " 3   type     216716 non-null  uint8\n",
            "dtypes: int32(3), uint8(1)\n",
            "memory usage: 4.3 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FriR71pK-hxH"
      },
      "source": [
        "### [Use new code instead] Construct `edge_index`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "Jw0zU0aTMZ-G"
      },
      "outputs": [],
      "source": [
        "#def to_tuple(row):\n",
        "#    return tuple(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "D1eMUs7A8qbA"
      },
      "outputs": [],
      "source": [
        "# also drop the ts and type column\n",
        "#connectivity = df.drop(columns=['ts', 'type']).apply(to_tuple, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "h8KsppDI7dvJ"
      },
      "outputs": [],
      "source": [
        "#connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "p2Yv20LW0Bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "2d869dc0-ab7d-4858-c31b-41d825c7e7b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# session index dict\\n#session = sorted(df['session'].unique())\\nsession = df['session'].unique()\\nsession_nodes_idx = {id:idx for idx, id in enumerate(session)}\\n\\n# aid(article id) index dict\\n#aid = sorted(df['aid'].unique())\\naid = df['aid'].unique()\\naid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "# Old code\n",
        "'''\n",
        "# session index dict\n",
        "#session = sorted(df['session'].unique())\n",
        "session = df['session'].unique()\n",
        "session_nodes_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "#aid = sorted(df['aid'].unique())\n",
        "aid = df['aid'].unique()\n",
        "aid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "xTiXlCrOQYYm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b8a37ec2-f5e2-4495-8e2c-f6ddbc5eea8c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef get_node_indices(data, key):\\n  for id in data[key].unique():\\n    yield id, next(i for i, v in enumerate(data[key]) if v == id)\\n\\nsession_nodes_idx = dict(get_node_indices(df, 'session'))\\naid_nodes_idx = dict(get_node_indices(df, 'aid'))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# use this code if the above cause memory crash\n",
        "# very slow but memory good\n",
        "'''\n",
        "def get_node_indices(data, key):\n",
        "  for id in data[key].unique():\n",
        "    yield id, next(i for i, v in enumerate(data[key]) if v == id)\n",
        "\n",
        "session_nodes_idx = dict(get_node_indices(df, 'session'))\n",
        "aid_nodes_idx = dict(get_node_indices(df, 'aid'))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "tpiPnhRYN7X4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8dfb5d63-3a02-4fa7-85bb-c7a333aade36"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni_session = []\\ni_aid = []\\nfor session, aid in connectivity_list:\\n  i_session.append(user_nodes_idx[user])\\n  i_aid.append(item_nodes_idx[item])\\n\\nindice = [i_session, i_aid]\\nedge_index = torch.Tensor(indice).type(torch.long)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "# /!\\ this cause memory crashed in a very large data\n",
        "'''\n",
        "i_session = []\n",
        "i_aid = []\n",
        "for session, aid in connectivity_list:\n",
        "  i_session.append(user_nodes_idx[user])\n",
        "  i_aid.append(item_nodes_idx[item])\n",
        "\n",
        "indice = [i_session, i_aid]\n",
        "edge_index = torch.Tensor(indice).type(torch.long)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "My-fApG4OR-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "fb443f8a-122c-4371-8dcd-29c38a501217"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\\n  for user, item in connectivity_list:\\n    yield user_nodes_idx[user], item_nodes_idx[item]\\n\\nedge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Work but still got memory crash in very large data\n",
        "'''\n",
        "def get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\n",
        "  for user, item in connectivity_list:\n",
        "    yield user_nodes_idx[user], item_nodes_idx[item]\n",
        "\n",
        "edge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "ERcykcKRz4Ri"
      },
      "outputs": [],
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "QvTKqD08lNFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbd90c55-eb96-4c6d-81c5-bb4267eb876c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-fdbbf2e7eb54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['session'] = connected['session'].map(source_idx)\n",
            "<ipython-input-33-fdbbf2e7eb54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['aid'] = connected['aid'].map(target_idx)\n"
          ]
        }
      ],
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "4L_GWK4hlTWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1634fc1-b99a-4c77-9701-7f2fe75d9c58"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-34-23961f25841f>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  edge_index = torch.tensor((source.values, target.values))\n"
          ]
        }
      ],
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Dn3bodEPSWNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c23535f0-81a1-49e0-d5b3-00e6c05a2961"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xXl7YIluHxDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f3d6794-ffe6-48d3-b517-db7e8fc263e9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 216716])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "edge_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "zEQRr1JTIMYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e32d2f92-721f-439b-992f-0e1d42c87ea6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([127552, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "aid_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "TLVPfcmsIThg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52f18d31-c9e9-408b-ab89-664e2cf51452"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "edge_label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "gGH8Sd8O97x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c035698-24e6-46fc-9168-16c737657b2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ num_nodes=208112 },\n",
              "  \u001b[1maid\u001b[0m={ x=[127552, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9F9gevNn-Ms3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97000ff9-1de9-400c-f055-39a95393e5d1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "TArUgtyn-OZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882abffe-8b7d-4680-ee37-b92a39fcf579"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "wQNhuNgM-Tar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3954499f-ad35-4c29-d832-97df7b83c432"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolated nodes? False\n",
            "Self loops? False\n",
            "Undirected graph?  False\n"
          ]
        }
      ],
      "source": [
        "print('Isolated nodes?', data.has_isolated_nodes())\n",
        "print('Self loops?', data.has_self_loops())\n",
        "print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "d50QCHYyKBNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d17e1507-f291-44af-c8e5-19d78f6b5b28"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208112,\n",
              "    x=[208112, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127552, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKqQxQA0-X44"
      },
      "source": [
        "### Calculate Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "5QvT19CNOtUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "befe28a5-2734-4ccd-8db2-5536b93fbc1a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ],
      "source": [
        "data['session', 'aid'].edge_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "Jlz46YER-Uns"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "\n",
        "counts = torch.bincount(data['session', 'aid'].edge_label)\n",
        "\n",
        "# Set weights normalized by (max count/each count)\n",
        "weight = counts.max() / counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "cZEH42kKOl58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "255f788a-9b0c-468b-85f4-c1a986809b71"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([194356,  17194,   5166])"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "Rw__CF6WOife",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a75ecce-fb36-4226-f730-5260efa45bd7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.3037, 37.6221])"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "nLOdlJzR-hDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "13b853be-fb17-4cf2-b342-790ad0d806e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"8096f2aa-ecdf-4251-9e63-e3de96a149bc\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"8096f2aa-ecdf-4251-9e63-e3de96a149bc\")) {                    Plotly.newPlot(                        \"8096f2aa-ecdf-4251-9e63-e3de96a149bc\",                        [{\"line\":{\"color\":\"coral\"},\"name\":\"nb rows\",\"x\":[0,1,2,3,4,5],\"y\":[194356,17194,5166],\"type\":\"scatter\"},{\"line\":{\"color\":\"royalblue\"},\"name\":\"weights\",\"x\":[0,1,2,3,4,5],\"y\":[1.0,11.3037109375,37.62214660644531],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"# rows\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"weights\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('8096f2aa-ecdf-4251-9e63-e3de96a149bc');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dict = {'type': (counts, '# rows','coral'), 'weights': (weight, 'weights','royalblue')}\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=counts.detach().cpu().numpy(),\n",
        "               name = 'nb rows', line_color= 'coral'))\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=weight.detach().cpu().numpy(),\n",
        "               name = 'weights', line_color= 'royalblue'),  secondary_y=True)\n",
        "\n",
        "\n",
        "fig.update_yaxes(title_text=\"# rows\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"weights\", secondary_y=True)\n",
        "fig.update_xaxes(title_text=\"Type\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "5kq9vMp3Rxeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4728fff2-9c20-41c5-ea65-572aa7896076"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[ 72662,  51217, 189000,  ..., 196173,  74787, 201783],\n",
              "        [ 54499,   1770, 124103,  ...,  96112,  79427,  58495]]), 'edge_label': tensor([0, 0, 0,  ..., 0, 0, 0]), 'edge_label_index': tensor([[ 72662,  51217, 189000,  ..., 196173,  74787, 201783],\n",
              "        [ 54499,   1770, 124103,  ...,  96112,  79427,  58495]])}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ],
      "source": [
        "train_data['session','aid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "VzTgyXxUSGfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7db99e13-39c1-4ef9-e480-8b083cf2f247"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "train_data['session','aid'].edge_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "4N6oASmHaoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdc39de9-6499-483c-8e70-d2de4da11ff3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.2336, 37.4807])"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "ZENXvG8wealJ"
      },
      "outputs": [],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "with torch.no_grad():\n",
        "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "ayGHaB6JegtI"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "RIjLW5AteiWZ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mt5-wzRekay",
        "outputId": "fa0492bc-d25c-4c2b-f5ab-7d43526a42e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 3.7419, Train: 1.0779, Val: 0.5423, Test: 0.5529\n",
            "Epoch: 001, Loss: 1.8398, Train: 0.4189, Val: 0.4079, Test: 0.4207\n",
            "Epoch: 002, Loss: 16.8129, Train: 1.1095, Val: 0.7309, Test: 0.7382\n",
            "Epoch: 003, Loss: 1.8663, Train: 1.9144, Val: 1.1870, Test: 1.1965\n",
            "Epoch: 004, Loss: 5.6208, Train: 1.1234, Val: 0.8065, Test: 0.8127\n",
            "Epoch: 005, Loss: 1.8792, Train: 0.7029, Val: 0.5991, Test: 0.6051\n",
            "Epoch: 006, Loss: 2.0254, Train: 0.5700, Val: 0.5270, Test: 0.5335\n",
            "Epoch: 007, Loss: 2.3761, Train: 0.5930, Val: 0.5291, Test: 0.5358\n",
            "Epoch: 008, Loss: 2.2992, Train: 0.6792, Val: 0.5590, Test: 0.5656\n",
            "Epoch: 009, Loss: 2.0738, Train: 0.8090, Val: 0.6115, Test: 0.6183\n",
            "Epoch: 010, Loss: 1.8703, Train: 0.9710, Val: 0.6805, Test: 0.6876\n",
            "Epoch: 011, Loss: 1.7944, Train: 1.1239, Val: 0.7499, Test: 0.7574\n",
            "Epoch: 012, Loss: 1.8795, Train: 1.2071, Val: 0.7962, Test: 0.8039\n",
            "Epoch: 013, Loss: 1.9856, Train: 1.2109, Val: 0.8026, Test: 0.8102\n",
            "Epoch: 014, Loss: 1.9913, Train: 1.1457, Val: 0.7731, Test: 0.7804\n",
            "Epoch: 015, Loss: 1.9032, Train: 1.0449, Val: 0.7252, Test: 0.7321\n",
            "Epoch: 016, Loss: 1.8173, Train: 0.9429, Val: 0.6767, Test: 0.6833\n",
            "Epoch: 017, Loss: 1.7946, Train: 0.8615, Val: 0.6385, Test: 0.6451\n",
            "Epoch: 018, Loss: 1.8254, Train: 0.8094, Val: 0.6147, Test: 0.6212\n",
            "Epoch: 019, Loss: 1.8695, Train: 0.7872, Val: 0.6054, Test: 0.6119\n",
            "Epoch: 020, Loss: 1.8944, Train: 0.7925, Val: 0.6094, Test: 0.6158\n",
            "Epoch: 021, Loss: 1.8881, Train: 0.8222, Val: 0.6251, Test: 0.6315\n",
            "Epoch: 022, Loss: 1.8569, Train: 0.8718, Val: 0.6507, Test: 0.6570\n",
            "Epoch: 023, Loss: 1.8190, Train: 0.9345, Val: 0.6829, Test: 0.6893\n",
            "Epoch: 024, Loss: 1.7956, Train: 0.9996, Val: 0.7165, Test: 0.7230\n",
            "Epoch: 025, Loss: 1.7989, Train: 1.0529, Val: 0.7443, Test: 0.7509\n",
            "Epoch: 026, Loss: 1.8217, Train: 1.0810, Val: 0.7593, Test: 0.7659\n",
            "Epoch: 027, Loss: 1.8408, Train: 1.0776, Val: 0.7582, Test: 0.7648\n",
            "Epoch: 028, Loss: 1.8382, Train: 1.0468, Val: 0.7429, Test: 0.7494\n",
            "Epoch: 029, Loss: 1.8181, Train: 1.0003, Val: 0.7196, Test: 0.7260\n",
            "Epoch: 030, Loss: 1.7990, Train: 0.9514, Val: 0.6951, Test: 0.7014\n",
            "Epoch: 031, Loss: 1.7937, Train: 0.9105, Val: 0.6747, Test: 0.6809\n",
            "Epoch: 032, Loss: 1.8013, Train: 0.8838, Val: 0.6614, Test: 0.6676\n",
            "Epoch: 033, Loss: 1.8123, Train: 0.8734, Val: 0.6563, Test: 0.6625\n",
            "Epoch: 034, Loss: 1.8179, Train: 0.8791, Val: 0.6592, Test: 0.6655\n",
            "Epoch: 035, Loss: 1.8147, Train: 0.8987, Val: 0.6692, Test: 0.6754\n",
            "Epoch: 036, Loss: 1.8055, Train: 0.9285, Val: 0.6842, Test: 0.6904\n",
            "Epoch: 037, Loss: 1.7965, Train: 0.9626, Val: 0.7014, Test: 0.7078\n",
            "Epoch: 038, Loss: 1.7935, Train: 0.9938, Val: 0.7173, Test: 0.7237\n",
            "Epoch: 039, Loss: 1.7973, Train: 1.0149, Val: 0.7281, Test: 0.7345\n",
            "Epoch: 040, Loss: 1.8034, Train: 1.0212, Val: 0.7313, Test: 0.7377\n",
            "Epoch: 041, Loss: 1.8057, Train: 1.0121, Val: 0.7266, Test: 0.7330\n",
            "Epoch: 042, Loss: 1.8023, Train: 0.9914, Val: 0.7162, Test: 0.7225\n",
            "Epoch: 043, Loss: 1.7967, Train: 0.9657, Val: 0.7031, Test: 0.7094\n",
            "Epoch: 044, Loss: 1.7934, Train: 0.9415, Val: 0.6909, Test: 0.6971\n",
            "Epoch: 045, Loss: 1.7943, Train: 0.9238, Val: 0.6819, Test: 0.6881\n",
            "Epoch: 046, Loss: 1.7973, Train: 0.9154, Val: 0.6777, Test: 0.6839\n",
            "Epoch: 047, Loss: 1.7995, Train: 0.9169, Val: 0.6784, Test: 0.6846\n",
            "Epoch: 048, Loss: 1.7990, Train: 0.9273, Val: 0.6836, Test: 0.6898\n",
            "Epoch: 049, Loss: 1.7965, Train: 0.9438, Val: 0.6920, Test: 0.6982\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0, 50):\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    test_rmse = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joyCx1zCnzl2",
        "outputId": "e2fa2da9-1e28-47e2-bb97-e029d131f2a1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SxYona145IU",
        "outputId": "bb8dbdbf-6e18-41b0-c1ce-7c808f59366e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208112,\n",
              "    x=[208112, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127552, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "60a-6qAqpPXT"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "encoder = model.encoder(data.x_dict, data.edge_index_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.encoder(data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbPqjTSINEG",
        "outputId": "0dddb9ce-22b2-4d1e-8312-b2a23e3e654f"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[ 1.3072,  2.7082, -0.8104,  ..., -0.5934,  3.8347, -1.4570],\n",
              "         [ 1.2758,  2.8191, -0.7274,  ..., -0.5145,  4.0044, -1.5082],\n",
              "         [ 1.2559,  2.7270, -0.8012,  ..., -0.5938,  3.7948, -1.4597],\n",
              "         ...,\n",
              "         [ 1.2993,  2.7431, -0.8576,  ..., -0.6035,  3.8535, -1.4711],\n",
              "         [ 1.2651,  2.7693, -0.8167,  ..., -0.5937,  3.8521, -1.4809],\n",
              "         [ 1.2290,  2.6997, -0.7661,  ..., -0.5685,  3.7609, -1.4434]],\n",
              "        grad_fn=<AddBackward0>),\n",
              " 'aid': tensor([[-0.7087, -0.8479, -3.3189,  ..., -3.2724, -4.3540,  1.2143],\n",
              "         [-0.7630, -0.8778, -3.3434,  ..., -3.3369, -4.3883,  1.2392],\n",
              "         [-0.6884, -0.8321, -3.2644,  ..., -3.1941, -4.2313,  1.2412],\n",
              "         ...,\n",
              "         [-0.7845, -0.8829, -3.3123,  ..., -3.3285, -4.3606,  1.2403],\n",
              "         [-0.6804, -0.8447, -3.3643,  ..., -3.2837, -4.3968,  1.2367],\n",
              "         [-0.7091, -0.8514, -3.2871,  ..., -3.2320, -4.2620,  1.2647]],\n",
              "        grad_fn=<AddBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gg = model(data.x_dict, data.edge_index_dict, data['session', 'aid'].edge_index)"
      ],
      "metadata": {
        "id": "FsVoiBSqLsrR"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eUS0_0PjKKY",
        "outputId": "e54ff8f6-eeb2-4f85-c1b4-9a8858875460"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW4XhiQHhf7f",
        "outputId": "45410876-c378-48b2-a316-a8ccd3b38eb1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9721, 0.9818, 0.9618,  ..., 0.9715, 0.9712, 0.9578],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRQNaMN8fSz8",
        "outputId": "9cb6d4a6-51e7-47f9-ad0d-90388b580d73"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208112,\n",
              "    x=[208112, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127552, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SOKEZTyifQOW",
        "outputId": "ddd9dc06-88a1-4a3d-d5c8-6a60cb7b4858"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208112,\n",
              "    x=[208112, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127552, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 173374],\n",
              "    edge_label=[173374],\n",
              "    edge_label_index=[2, 173374]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 173374] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data['session','aid']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Q30qpTGg7qt",
        "outputId": "5e78447c-7570-46d1-a74d-afa67524d6fa"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[ 72662,  51217, 189000,  ..., 196173,  74787, 201783],\n",
              "        [ 54499,   1770, 124103,  ...,  96112,  79427,  58495]]), 'edge_label': tensor([0, 0, 0,  ..., 0, 0, 0]), 'edge_label_index': tensor([[ 72662,  51217, 189000,  ..., 196173,  74787, 201783],\n",
              "        [ 54499,   1770, 124103,  ...,  96112,  79427,  58495]])}"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ez = model(train_data.x_dict, train_data.edge_index_dict, train_data['session', 'aid'].edge_label_index)"
      ],
      "metadata": {
        "id": "pLU1Xv2fe6_4"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ez"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUItCDLYfBjX",
        "outputId": "4a69cbc5-6bbd-473b-8776-f7e0712e0647"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9758, 0.9776, 0.9662,  ..., 1.0000, 0.9803, 0.9795],\n",
              "       grad_fn=<ViewBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHNbZyHebUPV"
      },
      "source": [
        "# [TEMPORARY DROP]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "2NTRQjhLACfe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "42ae2870-7e72-4726-aaf3-69b1a93861c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass GNNEncoder(torch.nn.Module):\\n    def __init__(self, hidden_channels, out_channels, conv):\\n        super().__init__()\\n        # conv(#in_channels, #out_channels)\\n        \\n        in_channels (int or tuple): \\n            Size of each input sample, or :obj:`-1` to\\n            derive the size from the first input(s) to the forward method.\\n            A tuple corresponds to the sizes of source and target\\n            dimensionalities.\\n        \\n        self.conv1 = conv((-1, -1), hidden_channels)\\n        self.conv2 = conv((-1, -1), out_channels)\\n        self.linear1 = Linear(-1, out_channels)\\n        self.linear2 = Linear(-1, out_channels)\\n\\n    def forward(self, x, edge_index):\\n        x0 = self.linear1(x)\\n        x2 = self.conv1(x0, edge_index).relu()\\n        x3 = self.conv2(x2, edge_index)\\n        x4 = self.linear2(x2 + x3)\\n        # Add combined layer to reduce over-smoothing\\n        return x4\\n\\nclass EdgeDecoder(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\\n        self.lin2 = Linear(hidden_channels, 1)\\n\\n    def forward(self, z_dict, edge_label_index):\\n        row, col = edge_label_index\\n        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\\n        z = self.lin1(z).relu()\\n        z = self.lin2(z)\\n        return z.view(-1)\\n\\nclass Model(torch.nn.Module):\\n    def __init__(self, hidden_channels,  conv=SAGEConv):\\n        super().__init__()\\n        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\\n        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\\n\\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\\n        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\\n        return self.decoder(z_dict, edge_label_index)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "# Temporary comment\n",
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, conv):\n",
        "        super().__init__()\n",
        "        # conv(#in_channels, #out_channels)\n",
        "        ''''''\n",
        "        in_channels (int or tuple): \n",
        "            Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        ''''''\n",
        "        self.conv1 = conv((-1, -1), hidden_channels)\n",
        "        self.conv2 = conv((-1, -1), out_channels)\n",
        "        self.linear1 = Linear(-1, out_channels)\n",
        "        self.linear2 = Linear(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x0 = self.linear1(x)\n",
        "        x2 = self.conv1(x0, edge_index).relu()\n",
        "        x3 = self.conv2(x2, edge_index)\n",
        "        x4 = self.linear2(x2 + x3)\n",
        "        # Add combined layer to reduce over-smoothing\n",
        "        return x4\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,  conv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "JsSAc0seAHmq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3624df25-3d0f-4b5f-cd98-a913dc723f42"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train(train_data, model, optimizer, loss=weighted_mse_loss):\\n    model.train()\\n    optimizer.zero_grad()\\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\\n                 train_data['session', 'aid'].edge_label_index)\\n    target = train_data['session', 'aid'].edge_label\\n    loss = weighted_mse_loss(pred, target, weight)\\n    loss.backward()\\n    optimizer.step()\\n    return float(loss.sqrt())\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "'''\n",
        "def train(train_data, model, optimizer, loss=weighted_mse_loss):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.sqrt())\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "qxHfcosNAXQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e46ccbe5-a2c8-4429-a3cc-04ddedc96eb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef test(data, model, metric=F.mse_loss):\\n    model.eval()\\n    pred = model(data.x_dict, data.edge_index_dict,\\n                 data['session', 'aid'].edge_label_index)\\n    pred = pred.clamp(min=0, max=2)\\n    target = data['session', 'aid'].edge_label.float()\\n    rmse = F.mse_loss(pred, target).sqrt()\\n    return float(rmse) # Return RMSE loss\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "## set pred.clamp\n",
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data, model, metric=F.mse_loss):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse) # Return RMSE loss\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "PE1pmW4KAXpe"
      },
      "outputs": [],
      "source": [
        "#from tqdm import tqdm\n",
        "#from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "id": "M2Mc3SOUAiui",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "eb25c1a4-ff66-4fbd-fe69-84f483145c5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\\n    t0 = time.time()\\n\\n    model = model(**model_params) # Define the model\\n\\n    # Due to lazy initialization, we need to run one model step so the number\\n    # of parameters can be inferred:\\n    with torch.no_grad():\\n        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\\n\\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n\\n    k=0\\n    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\\n    train_wrmse, val_wrmse, test_wrmse = [], [], []\\n    for epoch in tqdm(range(n_epochs)):\\n        # Call train fuction here >> return loss\\n        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\\n        \\n        # Call test function here >> return RMSE loss\\n        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\\n        train_rmse += [test(train_data, model, metric=F.mse_loss)]\\n        \\n        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\\n        val_rmse += [test(val_data, model, metric=F.mse_loss)]\\n        \\n        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\\n        test_rmse += [test(test_data, model, metric=F.mse_loss)]\\n\\n        if epoch+1 %10==0:\\n            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\\n                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\\n\\n        results = pd.DataFrame({\\n            'loss': loss,\\n            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\\n            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\\n            'time':(time.time()-t0)/60\\n        })\\n        \\n        ## Debugging\\n        #clear_output()\\n        '''\\n        print('\\nloss: ', loss, \\n              '\\ntrain_rmse: ', train_rmse, \\n              '\\nval_rmse: ', val_rmse, \\n              '\\ntest_rmse: ', test_rmse,\\n              '\\ntrain_wrmse: ', train_wrmse, \\n              '\\nval_wrmse: ', val_wrmse, \\n              '\\ntest_wrmse: ', test_wrmse,\\n              '\\ntime: ', (time.time()-t0)/60)\\n        '''\\n        #visualize_loss(results, metric='wrmse').show()\\n        #print(results.to_string())\\n\\n        # enable early stopping\\n        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\\n            k += 1\\n        if k> e_patience:\\n            print('Early stopping')\\n            break\\n\\n    return results, model\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 85
        }
      ],
      "source": [
        "\"\"\"\n",
        "def train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\n",
        "    t0 = time.time()\n",
        "\n",
        "    model = model(**model_params) # Define the model\n",
        "\n",
        "    # Due to lazy initialization, we need to run one model step so the number\n",
        "    # of parameters can be inferred:\n",
        "    with torch.no_grad():\n",
        "        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    k=0\n",
        "    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\n",
        "    train_wrmse, val_wrmse, test_wrmse = [], [], []\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        # Call train fuction here >> return loss\n",
        "        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\n",
        "        \n",
        "        # Call test function here >> return RMSE loss\n",
        "        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\n",
        "        train_rmse += [test(train_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\n",
        "        val_rmse += [test(val_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\n",
        "        test_rmse += [test(test_data, model, metric=F.mse_loss)]\n",
        "\n",
        "        if epoch+1 %10==0:\n",
        "            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\n",
        "                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'loss': loss,\n",
        "            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\n",
        "            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\n",
        "            'time':(time.time()-t0)/60\n",
        "        })\n",
        "        \n",
        "        ## Debugging\n",
        "        #clear_output()\n",
        "        '''\n",
        "        print('\\nloss: ', loss, \n",
        "              '\\ntrain_rmse: ', train_rmse, \n",
        "              '\\nval_rmse: ', val_rmse, \n",
        "              '\\ntest_rmse: ', test_rmse,\n",
        "              '\\ntrain_wrmse: ', train_wrmse, \n",
        "              '\\nval_wrmse: ', val_wrmse, \n",
        "              '\\ntest_wrmse: ', test_wrmse,\n",
        "              '\\ntime: ', (time.time()-t0)/60)\n",
        "        '''\n",
        "        #visualize_loss(results, metric='wrmse').show()\n",
        "        #print(results.to_string())\n",
        "\n",
        "        # enable early stopping\n",
        "        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\n",
        "            k += 1\n",
        "        if k> e_patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "\n",
        "    return results, model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "id": "8edkAihHAmP3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c90a14af-d476-45f9-df5e-a9ac061a9cb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef visualize_loss(results, metric=\\'rmse\\'):\\n    fig = go.Figure()\\n\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'train_\\'+metric], name = \\'train_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'val_\\'+metric], name = \\'val_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'test_\\'+metric], name = \\'test_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'loss\\'], name = \\'loss\\'))\\n\\n    fig.update_yaxes(title_text=metric.upper())\\n    fig.update_xaxes(title_text=\"Epoch\")\\n\\n    return fig\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 86
        }
      ],
      "source": [
        "'''\n",
        "def visualize_loss(results, metric='rmse'):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['train_'+metric], name = 'train_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['val_'+metric], name = 'val_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['test_'+metric], name = 'test_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['loss'], name = 'loss'))\n",
        "\n",
        "    fig.update_yaxes(title_text=metric.upper())\n",
        "    fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "    return fig\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bQElhxOkAn_q",
        "outputId": "2f11acf6-ec32-42e2-cd33-602fdaea44ff"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nN_EPOCHS = 300\\nE_PATIENCE = 50\\nLEARNING_RATE = 0.01\\n\\nmodel_params = {\"hidden_channels\":32, \\'conv\\':SAGEConv}\\n\\nresults, trained_model = train_test(\\n    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 87
        }
      ],
      "source": [
        "'''\n",
        "N_EPOCHS = 300\n",
        "E_PATIENCE = 50\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "model_params = {\"hidden_channels\":32, 'conv':SAGEConv}\n",
        "\n",
        "results, trained_model = train_test(\n",
        "    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "j58QMqIdUcfc"
      },
      "outputs": [],
      "source": [
        "#visualize_loss(results, metric='wrmse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "EUHSNzLmBEYx"
      },
      "outputs": [],
      "source": [
        "#trained_model.encoder(test_data.x_dict, test_data.edge_index_dict)['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "PtRs2Bw7kfOP"
      },
      "outputs": [],
      "source": [
        "#trained_model.state_dict()['encoder.linear2.session.weight']"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HKBFpzXHtgJ"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation"
      ],
      "metadata": {
        "id": "aED_TAobTF6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def recommendation(user_id, model, x_dict, edge_index_dict):\n",
        "  # Get model decoder\n",
        "  #model = Model(**model_params)\n",
        "  with torch.no_grad():\n",
        "    encoder = model.encoder(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "  # Get node representations for users and movies\n",
        "  user_representations = encoder['session']\n",
        "  movie_representations = encoder['aid']\n",
        "\n",
        "  # Compute the dot product between user and movie representations to get edge weights\n",
        "  edge_weights = user_representations.mm(movie_representations.T)\n",
        "\n",
        "  # Make predictions for each user by taking the top k largest edge weights\n",
        "  k = 20  # number of recommendations to make\n",
        "  _, top_k_indices = edge_weights.topk(k, dim=1)\n",
        "  recommendations = top_k_indices.numpy()\n",
        "\n",
        "  # Print recommendations for the first user\n",
        "  print(f'Recommendations for user {user_id}: {recommendations[user_id]}')"
      ],
      "metadata": {
        "id": "9IbcT22JTIFr"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 1\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "WP1SufyhTURW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 2\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "VFmAIGENUV9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 999\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "4H4tCDOyUcVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "uZw_TNkMQRaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission File\n",
        "For each `session` id and `type` combination in the test set, you must predict the `aid` values in the `label` column, which is space delimited. You can predict up to 20 `aid` values per row. The file should contain a header and have the following format:\n",
        "\n",
        "```\n",
        "session_type,labels\n",
        "12906577_clicks,135193 129431 119318 ...\n",
        "12906577_carts,135193 129431 119318 ...\n",
        "12906577_orders,135193 129431 119318 ...\n",
        "12906578_clicks, 135193 129431 119318 ...\n",
        "etc.\n",
        "```"
      ],
      "metadata": {
        "id": "DFOSPOfhOjYr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWyo1qVmOi8E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMssUHrX1Ti7vKpOTu42H5/"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}