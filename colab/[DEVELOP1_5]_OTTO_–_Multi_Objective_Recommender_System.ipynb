{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p4zaa/OTTO-Multi-Objective-Recommender-System/blob/main/%5BDEVELOP1_5%5D_OTTO_%E2%80%93_Multi_Objective_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version Logs\n",
        "* [View in my Github](https://github.com/p4zaa/OTTO-Multi-Objective-Recommender-System)"
      ],
      "metadata": {
        "id": "yf2nIQqrAy8y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZTgGyHWwP0wa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17f194e2-f7ed-477e-c75b-17b8f5053b5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.4 MB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 2.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 873 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 564 kB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 48.5 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "YGBdYwXz-B9e"
      },
      "outputs": [],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv, GAE\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "from torch_geometric.loader import HGTLoader, NeighborLoader, LinkNeighborLoader\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install -q torch torchvision torchaudio"
      ],
      "metadata": {
        "id": "97P3ABJvXkB_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Pytorch CUDA Version is ', torch.version.cuda)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B0nqQodKXs7R",
        "outputId": "56689deb-e81a-4503-f13e-e5a4d8b81599"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pytorch CUDA Version is  11.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5eLnmtjpYCtk",
        "outputId": "2cef930f-a561-43b3-83d8-47b77d2bcfdc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlaViVcbYSGa",
        "outputId": "f730fc2b-6b10-4e87-9005-e3f7beaa2a36"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "Pa5S-Yu9b4OL"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "j7Gsb6xQ98eL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "outputId": "2bcd689d-d61e-47e1-bb9b-0aaf4b459338"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c20c74ed-1d63-408e-be39-ddd411e75c6a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c20c74ed-1d63-408e-be39-ddd411e75c6a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "ref                                                           title                                               size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "------------------------------------------------------------  -------------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                     COVID-19 Dataset                                     5MB  2022-11-13 15:47:17          14756        420  1.0              \n",
            "devrimtuner/list-of-moststreamed-songs-on-spotify             Top 100 Spotify Songs👑🎤🎧🎼                            3KB  2022-12-30 05:42:54            269         24  1.0              \n",
            "thedevastator/analyzing-credit-card-spending-habits-in-india  Credit Card Spending Habits in India               319KB  2022-12-14 07:30:37           1423         51  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset            Fifa World Cup 2022: Complete Dataset                7KB  2022-12-18 22:51:11           3027        110  1.0              \n",
            "michals22/coffee-dataset                                      Coffee dataset                                      24KB  2022-12-15 20:02:12           3572         82  1.0              \n",
            "heemalichaudhari/netflix-movies-and-series                    Netflix Movies and Series                            2MB  2022-12-22 13:34:22            987         29  0.8235294        \n",
            "sejungjenn/spotify-best-songs-of-2022                         Spotify: Winner Tracks Audio Features🎹              38KB  2022-12-28 08:06:49            246         21  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data       E-Commerce Sales Dataset                             6MB  2022-12-03 09:27:17           2794         69  1.0              \n",
            "aklimarimi/qs-world-ranked-universities-20182022              QS World ranked Universities (2018-2022)            51KB  2022-12-28 03:53:39            370         22  1.0              \n",
            "rajeshrampure/black-friday-sale                               Black Friday Sale                                    5MB  2022-12-24 09:37:49            707         25  1.0              \n",
            "devrimtuner/highestpaid-athletes                              HIGHEST-PAID ATHLETES⚽️🏀🏈⚾️🥎🎾                        1KB  2022-12-29 01:29:51            255         23  1.0              \n",
            "heemalichaudhari/shopping                                     Shopping                                            12KB  2022-12-26 14:25:07            332         22  0.9411765        \n",
            "milanvaddoriya/old-car-price-prediction                       Old car price prediction                           105KB  2022-12-24 15:38:56            354         24  1.0              \n",
            "thedevastator/how-does-daily-yoga-impact-screen-time-habits   How Does Daily Yoga Impact Screen Time Habits       742B  2022-12-14 04:10:56            550         21  1.0              \n",
            "thedevastator/uncovering-factors-that-affect-used-car-prices  Used Cars                                           18MB  2022-12-06 13:36:08            978         29  1.0              \n",
            "devrimtuner/list-of-mostfollowed-instagram-accounts           (TOP 50)List of most-followed Instagram accounts👑    2KB  2022-12-30 07:52:00            301         22  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                     Salary Prediction                                    3MB  2022-11-16 13:52:31           8307        178  1.0              \n",
            "dansbecker/melbourne-housing-snapshot                         Melbourne Housing Snapshot                         451KB  2018-06-05 12:52:24         103220       1187  0.7058824        \n",
            "mattop/best-selling-game-boy-video-games                      Best Selling Game Boy Video Games                    2KB  2022-12-17 18:41:38            363         27  0.9705882        \n",
            "rajeshrampure/zomato-dataset                                  Zomato Dataset                                      89MB  2022-12-23 07:38:07            470         28  1.0              \n"
          ]
        }
      ],
      "source": [
        "'''\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "421Djk4r4qJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2d693f3-dc58-4d9a-c7a4-832e744357a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading otto-full-optimized-memory-footprint.zip to /content/kaggle\n",
            " 99% 1.08G/1.09G [00:09<00:00, 69.6MB/s]\n",
            "100% 1.09G/1.09G [00:09<00:00, 121MB/s] \n"
          ]
        }
      ],
      "source": [
        "#!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('/content/kaggle/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "df = df.sample(frac=0.1, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "N-Q_j2wx7Omc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "af5d1e51-1e00-4ee5-bdaa-a01e3ba55121"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            session      aid          ts  type\n",
              "164109176   7601047  1384867  1661646211     0\n",
              "73958132    2228920  1659103  1660079708     0\n",
              "138656819   5684412  1505298  1659991552     0\n",
              "212393819  12367365  1778843  1661546129     0\n",
              "175077530   8565926  1334471  1660504645     0\n",
              "...             ...      ...         ...   ...\n",
              "28209820     656346   836788  1659370158     0\n",
              "159984613   7254975  1208600  1660299182     0\n",
              "159208194   7190899   836040  1660292806     2\n",
              "40880331    1030510  1741753  1659988385     0\n",
              "196691403  10623902  1113339  1661008337     0\n",
              "\n",
              "[21671610 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e51de260-3297-484f-9b4b-510e9f03652f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>164109176</th>\n",
              "      <td>7601047</td>\n",
              "      <td>1384867</td>\n",
              "      <td>1661646211</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73958132</th>\n",
              "      <td>2228920</td>\n",
              "      <td>1659103</td>\n",
              "      <td>1660079708</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138656819</th>\n",
              "      <td>5684412</td>\n",
              "      <td>1505298</td>\n",
              "      <td>1659991552</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212393819</th>\n",
              "      <td>12367365</td>\n",
              "      <td>1778843</td>\n",
              "      <td>1661546129</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175077530</th>\n",
              "      <td>8565926</td>\n",
              "      <td>1334471</td>\n",
              "      <td>1660504645</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28209820</th>\n",
              "      <td>656346</td>\n",
              "      <td>836788</td>\n",
              "      <td>1659370158</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159984613</th>\n",
              "      <td>7254975</td>\n",
              "      <td>1208600</td>\n",
              "      <td>1660299182</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159208194</th>\n",
              "      <td>7190899</td>\n",
              "      <td>836040</td>\n",
              "      <td>1660292806</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40880331</th>\n",
              "      <td>1030510</td>\n",
              "      <td>1741753</td>\n",
              "      <td>1659988385</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196691403</th>\n",
              "      <td>10623902</td>\n",
              "      <td>1113339</td>\n",
              "      <td>1661008337</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>21671610 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e51de260-3297-484f-9b4b-510e9f03652f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e51de260-3297-484f-9b4b-510e9f03652f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e51de260-3297-484f-9b4b-510e9f03652f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "I6SK6ahjEpy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68d055f-e996-4065-93a0-8f5f72f22b2e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session    0\n",
              "aid        0\n",
              "ts         0\n",
              "type       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "h8hFppsb5cAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3055336-a678-4df6-fc88-4234fa24339d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "OFhgeI-OgFEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54dc193f-5c32-4b1c-8ce1-d025a4c7b235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 21671610 entries, 164109176 to 196691403\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Dtype\n",
            "---  ------   -----\n",
            " 0   session  int32\n",
            " 1   aid      int32\n",
            " 2   ts       int32\n",
            " 3   type     uint8\n",
            "dtypes: int32(3), uint8(1)\n",
            "memory usage: 434.0 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FriR71pK-hxH"
      },
      "source": [
        "### [Use new code instead] Construct `edge_index`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Jw0zU0aTMZ-G"
      },
      "outputs": [],
      "source": [
        "#def to_tuple(row):\n",
        "#    return tuple(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "D1eMUs7A8qbA"
      },
      "outputs": [],
      "source": [
        "# also drop the ts and type column\n",
        "#connectivity = df.drop(columns=['ts', 'type']).apply(to_tuple, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "h8KsppDI7dvJ"
      },
      "outputs": [],
      "source": [
        "#connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "p2Yv20LW0Bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "91fa435e-727c-432c-f009-b9c20f299b02"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# session index dict\\n#session = sorted(df['session'].unique())\\nsession = df['session'].unique()\\nsession_nodes_idx = {id:idx for idx, id in enumerate(session)}\\n\\n# aid(article id) index dict\\n#aid = sorted(df['aid'].unique())\\naid = df['aid'].unique()\\naid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "# Old code\n",
        "'''\n",
        "# session index dict\n",
        "#session = sorted(df['session'].unique())\n",
        "session = df['session'].unique()\n",
        "session_nodes_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "#aid = sorted(df['aid'].unique())\n",
        "aid = df['aid'].unique()\n",
        "aid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "xTiXlCrOQYYm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ecf6b80f-59fa-4c2d-a521-969a68498ce4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef get_node_indices(data, key):\\n  for id in data[key].unique():\\n    yield id, next(i for i, v in enumerate(data[key]) if v == id)\\n\\nsession_nodes_idx = dict(get_node_indices(df, 'session'))\\naid_nodes_idx = dict(get_node_indices(df, 'aid'))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "# use this code if the above cause memory crash\n",
        "# very slow but memory good\n",
        "'''\n",
        "def get_node_indices(data, key):\n",
        "  for id in data[key].unique():\n",
        "    yield id, next(i for i, v in enumerate(data[key]) if v == id)\n",
        "\n",
        "session_nodes_idx = dict(get_node_indices(df, 'session'))\n",
        "aid_nodes_idx = dict(get_node_indices(df, 'aid'))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "tpiPnhRYN7X4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7af437d6-cda2-476e-eb51-b75af4c7f595"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni_session = []\\ni_aid = []\\nfor session, aid in connectivity_list:\\n  i_session.append(user_nodes_idx[user])\\n  i_aid.append(item_nodes_idx[item])\\n\\nindice = [i_session, i_aid]\\nedge_index = torch.Tensor(indice).type(torch.long)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "# /!\\ this cause memory crashed in a very large data\n",
        "'''\n",
        "i_session = []\n",
        "i_aid = []\n",
        "for session, aid in connectivity_list:\n",
        "  i_session.append(user_nodes_idx[user])\n",
        "  i_aid.append(item_nodes_idx[item])\n",
        "\n",
        "indice = [i_session, i_aid]\n",
        "edge_index = torch.Tensor(indice).type(torch.long)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "My-fApG4OR-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "c768e524-2da4-4856-e4b0-60826b9969d0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\\n  for user, item in connectivity_list:\\n    yield user_nodes_idx[user], item_nodes_idx[item]\\n\\nedge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# Work but still got memory crash in very large data\n",
        "'''\n",
        "def get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\n",
        "  for user, item in connectivity_list:\n",
        "    yield user_nodes_idx[user], item_nodes_idx[item]\n",
        "\n",
        "edge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ERcykcKRz4Ri"
      },
      "outputs": [],
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "QvTKqD08lNFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00242fcc-d795-48a4-d321-864264a0f437"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-fdbbf2e7eb54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['session'] = connected['session'].map(source_idx)\n",
            "<ipython-input-25-fdbbf2e7eb54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['aid'] = connected['aid'].map(target_idx)\n"
          ]
        }
      ],
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "4L_GWK4hlTWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe525c07-1569-493d-ed5a-3890ab586644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-23961f25841f>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  edge_index = torch.tensor((source.values, target.values))\n"
          ]
        }
      ],
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "edge_index.device"
      ],
      "metadata": {
        "id": "GQjWHCCVhyQ7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050abe3c-66b3-4f2d-be8a-57d42c9109f2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cpu')"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "Dn3bodEPSWNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3c40bf2-d909-4a45-ab46-6d703d11a770"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 2, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "xXl7YIluHxDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66148b1b-01cd-413a-cc89-125187175a75"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[      0,       1,       2,  ..., 2031198,  839438, 6836944],\n",
              "        [      0,       1,       2,  ...,   37880,    3205,  693246]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "edge_index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "zEQRr1JTIMYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b114d9e3-ee88-4b31-ea24-ed2ee796126d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1492642, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "aid_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "TLVPfcmsIThg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3a951d-2067-47ff-bdfd-3e872c527736"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([21671610])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "edge_label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "gGH8Sd8O97x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "88c731b3-630a-4a0b-88d0-77822c0d2667"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ num_nodes=6836945 },\n",
              "  \u001b[1maid\u001b[0m={ x=[1492642, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 21671610],\n",
              "    edge_label=[21671610]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "9F9gevNn-Ms3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbe71c32-3a5d-4a71-d917-62f619d37b8e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "TArUgtyn-OZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2629508f-5df9-4b9b-a628-bae215a1abfa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "wQNhuNgM-Tar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ffac534-4f7d-4491-f8c8-9c3002edb0b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolated nodes? False\n",
            "Self loops? False\n",
            "Undirected graph?  False\n"
          ]
        }
      ],
      "source": [
        "print('Isolated nodes?', data.has_isolated_nodes())\n",
        "print('Self loops?', data.has_self_loops())\n",
        "print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "d50QCHYyKBNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf781a2-2a89-467e-d252-b7952941abd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=6836945,\n",
              "    x=[6836945, 20]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[1492642, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 21671610],\n",
              "    edge_label=[21671610]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 21671610] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKqQxQA0-X44"
      },
      "source": [
        "### Calculate Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5QvT19CNOtUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd1e835b-9ad7-459b-8ab0-dc56690d7bf6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([21671610])"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "data['session', 'aid'].edge_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "Jlz46YER-Uns"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "\n",
        "counts = torch.bincount(data['session', 'aid'].edge_label)\n",
        "\n",
        "# Set weights normalized by (max count/each count)\n",
        "weight = counts.max() / counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "cZEH42kKOl58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98ada9e1-6075-46db-f887-da0e04096ffd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([19472418,  1688679,   510513])"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "Rw__CF6WOife",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc37203d-b9a8-4092-dad2-249e4b9e72b9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5312, 38.1428])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "nLOdlJzR-hDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "25c721dc-6f94-403c-8994-bb9fd8599423"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"c71c5b07-fca9-4452-9ec9-34d3710dbf70\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c71c5b07-fca9-4452-9ec9-34d3710dbf70\")) {                    Plotly.newPlot(                        \"c71c5b07-fca9-4452-9ec9-34d3710dbf70\",                        [{\"line\":{\"color\":\"coral\"},\"name\":\"nb rows\",\"x\":[0,1,2,3,4,5],\"y\":[19472418,1688679,510513],\"type\":\"scatter\"},{\"line\":{\"color\":\"royalblue\"},\"name\":\"weights\",\"x\":[0,1,2,3,4,5],\"y\":[1.0,11.53115463256836,38.142845153808594],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"# rows\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"weights\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('c71c5b07-fca9-4452-9ec9-34d3710dbf70');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dict = {'type': (counts, '# rows','coral'), 'weights': (weight, 'weights','royalblue')}\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=counts.detach().cpu().numpy(),\n",
        "               name = 'nb rows', line_color= 'coral'))\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=weight.detach().cpu().numpy(),\n",
        "               name = 'weights', line_color= 'royalblue'),  secondary_y=True)\n",
        "\n",
        "\n",
        "fig.update_yaxes(title_text=\"# rows\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"weights\", secondary_y=True)\n",
        "fig.update_xaxes(title_text=\"Type\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mini Batch"
      ],
      "metadata": {
        "id": "SV6330E6VmlW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define seed edges:\n",
        "edge_label_index = train_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = train_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "train_loader = LinkNeighborLoader(\n",
        "    data=train_data,  # TODO\n",
        "    num_neighbors=[5, 10],  # TODO\n",
        "    neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=128,\n",
        "    shuffle=True,\n",
        ")\n",
        "\n",
        "# Inspect a sample:\n",
        "sampled_data = next(iter(train_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label_index.size(1) == 128\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.min() == 0\n",
        "#assert sampled_data[\"session\", \"event\", \"aid\"].edge_label.max() == 2"
      ],
      "metadata": {
        "id": "bExrskfWXv8A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a8dc1e9-a4cb-4468-cd4b-e215482dbb03"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    num_nodes=3486,\n",
            "    x=[3486, 20]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={ x=[2607, 300] },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 3564],\n",
            "    edge_label=[128],\n",
            "    edge_label_index=[2, 128],\n",
            "    input_id=[128]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 3410] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "4N6oASmHaoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "431f5a90-01c4-47b6-cc60-03eb00ad5769"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.5262, 38.1500])"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#model = GAE(to_hetero(GNNEncoder(hidden_channels=32, out_channels=32), data.metadata(), aggr='sum')).to(device)"
      ],
      "metadata": {
        "id": "Xx61ClrYxucR"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "ZENXvG8wealJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9aa897be-d682-4076-a136-b08dfb0cbfa0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nwith torch.no_grad():\\n    model.encoder(train_data.x_dict, train_data.edge_index_dict)\\n\\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "'''\n",
        "with torch.no_grad():\n",
        "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "ayGHaB6JegtI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "28cf508c-6f49-4321-fc2f-83d817ed4dbd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train():\\n    model.train()\\n    optimizer.zero_grad()\\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\\n                 train_data['session', 'aid'].edge_label_index)\\n    target = train_data['session', 'aid'].edge_label\\n    loss = weighted_mse_loss(pred, target, weight)\\n    loss.backward()\\n    optimizer.step()\\n    return float(loss)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 60
        }
      ],
      "source": [
        "'''\n",
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "RIjLW5AteiWZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "9bd9cb0c-306d-4594-8ba3-a8ac2bbc667b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef test(data):\\n    model.eval()\\n    pred = model(data.x_dict, data.edge_index_dict,\\n                 data['session', 'aid'].edge_label_index)\\n    pred = pred.clamp(min=-1, max=2)\\n    target = data['session', 'aid'].edge_label.float()\\n    rmse = F.mse_loss(pred, target).sqrt()\\n    return float(rmse)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ],
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=-1, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(train_data=sampled_data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight.to(device))\n",
        "    #loss = F.binary_cross_entropy_with_logits(pred, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss), pred"
      ],
      "metadata": {
        "id": "iG6cTQvOi70X"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def test(data=data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse), pred, target"
      ],
      "metadata": {
        "id": "31EopkIapWVk"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [non-batch] Training Heterogenous Link-level GNN"
      ],
      "metadata": {
        "id": "kos-BVhlm6dR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "7Mt5-wzRekay",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "073f29e9-4d7d-4ac7-ffe9-d4c2c342be5c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nfor epoch in range(0, 30):\\n    loss = train()\\n    train_rmse = test(train_data)\\n    val_rmse = test(val_data)\\n    test_rmse = test(test_data)\\n    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\\n          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 64
        }
      ],
      "source": [
        "'''\n",
        "for epoch in range(0, 30):\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    test_rmse = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### [mini-batch] Training Heterogenous Link-level GNN"
      ],
      "metadata": {
        "id": "iZXrZJEknJAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"Device: '{device}'\")\n",
        "\n",
        "#model = Model(hidden_channels=32).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(0, 10):\n",
        "    total_loss = total_examples = 0\n",
        "    for sampled_data in tqdm.tqdm(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        loss, pred = train(train_data=sampled_data.to(device))\n",
        "        # TODO: Move `sampled_data` to the respective `device`\n",
        "        # TODO: Run `forward` pass of the model\n",
        "        # TODO: Apply binary cross entropy via\n",
        "        # `F.binary_cross_entropy_with_logits(pred, ground_truth)`\n",
        "\n",
        "        #loss.backward()\n",
        "        #optimizer.step()\n",
        "        total_loss += float(loss) * pred.numel()\n",
        "        total_examples += pred.numel()\n",
        "    print(f\"Epoch: {epoch:03d}, Loss: {total_loss / total_examples:.4f}\")"
      ],
      "metadata": {
        "id": "hbuDkO-Nh8kA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d84d447-a160-4060-e0ab-76de97c5ea5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: 'cpu'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135448/135448 [1:49:33<00:00, 20.60it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 1.7999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135448/135448 [1:50:08<00:00, 20.50it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 001, Loss: 1.7996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 135448/135448 [1:49:57<00:00, 20.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 002, Loss: 1.7996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 38465/135448 [31:07<1:18:12, 20.67it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joyCx1zCnzl2"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.encoder(data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433
        },
        "id": "2fbPqjTSINEG",
        "outputId": "ab732d38-b0f8-420e-f0c0-49ca27d1150d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-63-1b0670544fd3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mcompatibility\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_backward_compatible\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    265\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<eval_with_key>.1\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0medge_index__session__event__aid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'session'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'event'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'aid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0medge_index__aid__rev_event__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'aid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rev_event'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'session'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0medge_index_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mconv1__aid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msession__event__aid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__aid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__session__event__aid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mconv1__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maid__rev_event__session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__aid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__aid__rev_event__session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mx__aid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mrelu__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1__session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mconv1__session\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/nn/conv/sage_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, size)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlin_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mx_r\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1189\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1190\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1191\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch_geometric/nn/dense/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mx\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \"\"\"\n\u001b[0;32m--> 136\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_addmm)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Evaluate a Heterogenous Linklevel GNN"
      ],
      "metadata": {
        "id": "QqiZlbCxnOcp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the validation seed edges:\n",
        "edge_label_index = val_data['session', 'event', 'aid'].edge_label_index\n",
        "edge_label = val_data['session', 'event', 'aid'].edge_label\n",
        "\n",
        "val_loader = LinkNeighborLoader(\n",
        "    data=val_data,  # TODO\n",
        "    num_neighbors=[20, 10],  # TODO\n",
        "    #neg_sampling_ratio=0.0,  # TODO\n",
        "    edge_label_index=(('session', 'event', 'aid'), edge_label_index),\n",
        "    edge_label=edge_label,\n",
        "    batch_size=3 * 128,\n",
        "    shuffle=False,\n",
        ")\n",
        "\n",
        "sampled_data = next(iter(val_loader))\n",
        "\n",
        "print(\"Sampled mini-batch:\")\n",
        "print(\"===================\")\n",
        "print(sampled_data)\n",
        "\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label_index.size(1) == 3 * 128\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.min() >= 0\n",
        "assert sampled_data['session', 'event', 'aid'].edge_label.max() <= 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GzCtJihVnWKu",
        "outputId": "89497bce-0b3a-407e-f535-eb7c2e268049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sampled mini-batch:\n",
            "===================\n",
            "HeteroData(\n",
            "  \u001b[1msession\u001b[0m={\n",
            "    num_nodes=5332,\n",
            "    x=[5332, 20]\n",
            "  },\n",
            "  \u001b[1maid\u001b[0m={ x=[2640, 300] },\n",
            "  \u001b[1m(session, event, aid)\u001b[0m={\n",
            "    edge_index=[2, 5200],\n",
            "    edge_label=[384],\n",
            "    edge_label_index=[2, 384],\n",
            "    input_id=[384]\n",
            "  },\n",
            "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 5891] }\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import label_binarize\n",
        "\n",
        "# You need the labels to binarize\n",
        "labels = [0, 1, 2]\n",
        "\n",
        "preds = []\n",
        "ground_truths = []\n",
        "for sampled_data in tqdm.tqdm(val_loader):\n",
        "    with torch.no_grad():\n",
        "        _, pred, ground_truth = test(data=sampled_data.to(device))\n",
        "        preds.append(pred)\n",
        "        ground_truths.append(ground_truth)\n",
        "        # TODO: Collect predictions and ground-truths and write them into\n",
        "        # `preds` and `ground_truths`.\n",
        "        #raise NotImplementedError\n",
        "\n",
        "pred = torch.cat(preds, dim=0).cpu().numpy()\n",
        "ground_truth = torch.cat(ground_truths, dim=0).cpu().numpy()\n",
        "\n",
        "# Binarize `pred` with shape (n_samples, n_classes)\n",
        "pred = label_binarize(pred.astype(int), classes=labels)\n",
        "\n",
        "# Binarize `ground_truth` with shape (n_samples, n_classes)\n",
        "ground_truth = label_binarize(ground_truth, classes=labels)\n",
        "\n",
        "#rmse = _\n",
        "auc = roc_auc_score(ground_truth, pred, multi_class='ovo', average='weighted')\n",
        "print()\n",
        "print(f\"Validation AUC: {auc:.4f}\")\n",
        "#print('RMSE: ', rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFGjR1IWpKqX",
        "outputId": "98c0f099-2f4e-474c-a196-ee766bcecdfb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 565/565 [00:09<00:00, 58.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation AUC: 0.5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test dataset"
      ],
      "metadata": {
        "id": "WLHyzIiNECx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_parquet('/content/kaggle/test.parquet')"
      ],
      "metadata": {
        "id": "WDkdfZnxEB02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df.sample(frac=0.01, replace=False)"
      ],
      "metadata": {
        "id": "AkgwhJjiIyAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df"
      ],
      "metadata": {
        "id": "Q4LGeBz9EPjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct heterogenous graph for test"
      ],
      "metadata": {
        "id": "iY12RhftEWwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ],
      "metadata": {
        "id": "VQwWWWsnEfli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)\n",
        "\n",
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values)).type(torch.int64)\n",
        "'''"
      ],
      "metadata": {
        "id": "BITDjJKVEwpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)\n",
        "'''"
      ],
      "metadata": {
        "id": "WZjCOHTlE0Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label,\n",
        "        'edge_label_index': edge_index\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "uwJLoByFFATA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data = HeteroData({**node_types, **edge_types})"
      ],
      "metadata": {
        "id": "UY3tqA4HFG3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data"
      ],
      "metadata": {
        "id": "OnPMRj27FwbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data"
      ],
      "metadata": {
        "id": "vC_MYbqNFK_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# add sesion features for message passing:\n",
        "Rtest_data['session'].x = torch.rand(Rtest_data['session'].num_nodes, 300)\n",
        "\n",
        "Rtest_data = T.ToUndirected()(Rtest_data)\n",
        "del Rtest_data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label.\n",
        "'''"
      ],
      "metadata": {
        "id": "0ktGWQnnIPbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data"
      ],
      "metadata": {
        "id": "Eb6N2GaqNj_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "1serMeUuEf8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    gg = model(Rtest_data.x_dict, Rtest_data.edge_index_dict, Rtest_data['session', 'aid'].edge_label_index)\n",
        "'''"
      ],
      "metadata": {
        "id": "FsVoiBSqLsrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "id": "-eUS0_0PjKKY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "id": "RilROrFHN-xZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#gg"
      ],
      "metadata": {
        "id": "eW4XhiQHhf7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data"
      ],
      "metadata": {
        "id": "FRQNaMN8fSz8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHNbZyHebUPV"
      },
      "source": [
        "# [TEMPORARY DROP]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NTRQjhLACfe"
      },
      "outputs": [],
      "source": [
        "# Temporary comment\n",
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, conv):\n",
        "        super().__init__()\n",
        "        # conv(#in_channels, #out_channels)\n",
        "        ''''''\n",
        "        in_channels (int or tuple): \n",
        "            Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        ''''''\n",
        "        self.conv1 = conv((-1, -1), hidden_channels)\n",
        "        self.conv2 = conv((-1, -1), out_channels)\n",
        "        self.linear1 = Linear(-1, out_channels)\n",
        "        self.linear2 = Linear(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x0 = self.linear1(x)\n",
        "        x2 = self.conv1(x0, edge_index).relu()\n",
        "        x3 = self.conv2(x2, edge_index)\n",
        "        x4 = self.linear2(x2 + x3)\n",
        "        # Add combined layer to reduce over-smoothing\n",
        "        return x4\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,  conv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsSAc0seAHmq"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def train(train_data, model, optimizer, loss=weighted_mse_loss):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.sqrt())\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxHfcosNAXQT"
      },
      "outputs": [],
      "source": [
        "## set pred.clamp\n",
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data, model, metric=F.mse_loss):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse) # Return RMSE loss\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE1pmW4KAXpe"
      },
      "outputs": [],
      "source": [
        "#from tqdm import tqdm\n",
        "#from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Mc3SOUAiui"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "def train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\n",
        "    t0 = time.time()\n",
        "\n",
        "    model = model(**model_params) # Define the model\n",
        "\n",
        "    # Due to lazy initialization, we need to run one model step so the number\n",
        "    # of parameters can be inferred:\n",
        "    with torch.no_grad():\n",
        "        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    k=0\n",
        "    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\n",
        "    train_wrmse, val_wrmse, test_wrmse = [], [], []\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        # Call train fuction here >> return loss\n",
        "        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\n",
        "        \n",
        "        # Call test function here >> return RMSE loss\n",
        "        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\n",
        "        train_rmse += [test(train_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\n",
        "        val_rmse += [test(val_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\n",
        "        test_rmse += [test(test_data, model, metric=F.mse_loss)]\n",
        "\n",
        "        if epoch+1 %10==0:\n",
        "            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\n",
        "                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'loss': loss,\n",
        "            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\n",
        "            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\n",
        "            'time':(time.time()-t0)/60\n",
        "        })\n",
        "        \n",
        "        ## Debugging\n",
        "        #clear_output()\n",
        "        '''\n",
        "        print('\\nloss: ', loss, \n",
        "              '\\ntrain_rmse: ', train_rmse, \n",
        "              '\\nval_rmse: ', val_rmse, \n",
        "              '\\ntest_rmse: ', test_rmse,\n",
        "              '\\ntrain_wrmse: ', train_wrmse, \n",
        "              '\\nval_wrmse: ', val_wrmse, \n",
        "              '\\ntest_wrmse: ', test_wrmse,\n",
        "              '\\ntime: ', (time.time()-t0)/60)\n",
        "        '''\n",
        "        #visualize_loss(results, metric='wrmse').show()\n",
        "        #print(results.to_string())\n",
        "\n",
        "        # enable early stopping\n",
        "        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\n",
        "            k += 1\n",
        "        if k> e_patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "\n",
        "    return results, model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8edkAihHAmP3"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "def visualize_loss(results, metric='rmse'):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['train_'+metric], name = 'train_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['val_'+metric], name = 'val_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['test_'+metric], name = 'test_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['loss'], name = 'loss'))\n",
        "\n",
        "    fig.update_yaxes(title_text=metric.upper())\n",
        "    fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "    return fig\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bQElhxOkAn_q"
      },
      "outputs": [],
      "source": [
        "'''\n",
        "N_EPOCHS = 300\n",
        "E_PATIENCE = 50\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "model_params = {\"hidden_channels\":32, 'conv':SAGEConv}\n",
        "\n",
        "results, trained_model = train_test(\n",
        "    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j58QMqIdUcfc"
      },
      "outputs": [],
      "source": [
        "#visualize_loss(results, metric='wrmse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUHSNzLmBEYx"
      },
      "outputs": [],
      "source": [
        "#trained_model.encoder(test_data.x_dict, test_data.edge_index_dict)['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtRs2Bw7kfOP"
      },
      "outputs": [],
      "source": [
        "#trained_model.state_dict()['encoder.linear2.session.weight']"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HKBFpzXHtgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation"
      ],
      "metadata": {
        "id": "aED_TAobTF6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def recommendation(user_id, model, x_dict, edge_index_dict):\n",
        "  # Get model decoder\n",
        "  #model = Model(**model_params)\n",
        "  with torch.no_grad():\n",
        "    encoder = model.encoder(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "  # Get node representations for users and movies\n",
        "  user_representations = encoder['session']\n",
        "  movie_representations = encoder['aid']\n",
        "\n",
        "  # Compute the dot product between user and movie representations to get edge weights\n",
        "  edge_weights = user_representations.mm(movie_representations.T)\n",
        "\n",
        "  # Make predictions for each user by taking the top k largest edge weights\n",
        "  k = 20  # number of recommendations to make\n",
        "  _, top_k_indices = edge_weights.topk(k, dim=1)\n",
        "  recommendations = top_k_indices.numpy()\n",
        "\n",
        "  # Print recommendations for the first user\n",
        "  print(f'Recommendations for user {user_id}: {recommendations[user_id]}')\n",
        "'''"
      ],
      "metadata": {
        "id": "9IbcT22JTIFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 1\n",
        "#recommendation(session, model, Rtest_data.x_dict, Rtest_data.edge_index_dict)"
      ],
      "metadata": {
        "id": "WP1SufyhTURW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 2\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "VFmAIGENUV9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 999\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "4H4tCDOyUcVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "uZw_TNkMQRaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission File\n",
        "For each `session` id and `type` combination in the test set, you must predict the `aid` values in the `label` column, which is space delimited. You can predict up to 20 `aid` values per row. The file should contain a header and have the following format:\n",
        "\n",
        "```\n",
        "session_type,labels\n",
        "12906577_clicks,135193 129431 119318 ...\n",
        "12906577_carts,135193 129431 119318 ...\n",
        "12906577_orders,135193 129431 119318 ...\n",
        "12906578_clicks, 135193 129431 119318 ...\n",
        "etc.\n",
        "```"
      ],
      "metadata": {
        "id": "DFOSPOfhOjYr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWyo1qVmOi8E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FriR71pK-hxH",
        "pqgOrM6ak915",
        "fUkcZdZr8seK",
        "VKqQxQA0-X44",
        "XHNbZyHebUPV"
      ],
      "authorship_tag": "ABX9TyMT1HNAVF3kXkvuw0F65PB4",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
