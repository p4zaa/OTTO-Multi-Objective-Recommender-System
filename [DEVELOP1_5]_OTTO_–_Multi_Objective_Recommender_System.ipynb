{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/p4zaa/OTTO-Multi-Objective-Recommender-System/blob/main/%5BDEVELOP1_5%5D_OTTO_%E2%80%93_Multi_Objective_Recommender_System.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Version Logs\n",
        "* [View in my Github](https://github.com/p4zaa/OTTO-Multi-Objective-Recommender-System)"
      ],
      "metadata": {
        "id": "yf2nIQqrAy8y"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tc-Xkz1-2tPy"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RLpky1BB2v5B"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZTgGyHWwP0wa",
        "outputId": "5cee2013-7382-4aaf-8f78-56ce0f66ab61"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 9.4 MB 1.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 6.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 14.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 873 kB 13.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 564 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 280 kB 71.1 MB/s \n",
            "\u001b[?25h  Building wheel for torch-geometric (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "def format_pytorch_version(version):\n",
        "  return version.split('+')[0]\n",
        "\n",
        "TORCH_version = torch.__version__\n",
        "TORCH = format_pytorch_version(TORCH_version)\n",
        "\n",
        "def format_cuda_version(version):\n",
        "  return 'cu' + version.replace('.', '')\n",
        "\n",
        "CUDA_version = torch.version.cuda\n",
        "CUDA = format_cuda_version(CUDA_version)\n",
        "\n",
        "!pip install -q torch-scatter     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-sparse      -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-cluster     -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-spline-conv -f https://pytorch-geometric.com/whl/torch-{TORCH}+{CUDA}.html\n",
        "!pip install -q torch-geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "YGBdYwXz-B9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ad0e71b0-1804-48ce-a99a-a22a1e29da42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 85 kB 2.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 22.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 37.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 182 kB 52.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 7.6 MB 23.5 MB/s \n",
            "\u001b[?25h  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd, numpy as np\n",
        "from itertools import product\n",
        "import io, os, json\n",
        "\n",
        "import time\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "import plotly.io as pio\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "pio.templates.default = \"plotly_white\"\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch_geometric.transforms as T\n",
        "from torch_geometric.datasets import MovieLens\n",
        "from torch_geometric.nn import to_hetero\n",
        "from torch_geometric.nn import HeteroConv, GCNConv, SAGEConv, GATConv, Linear, GraphConv\n",
        "from torch_geometric.data import Data, HeteroData\n",
        "\n",
        "!pip install -q sentence-transformers\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oS4E3Ao91Ch"
      },
      "source": [
        "# Load Competition Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "j7Gsb6xQ98eL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "9ece6504-08fc-4d2d-b3d1-7430f59bbed4"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-23049047-7f08-42fa-b4e5-6f0880cea2db\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-23049047-7f08-42fa-b4e5-6f0880cea2db\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "rm: cannot remove '/root/.kaggle': No such file or directory\n",
            "ref                                                             title                                           size  lastUpdated          downloadCount  voteCount  usabilityRating  \n",
            "--------------------------------------------------------------  ---------------------------------------------  -----  -------------------  -------------  ---------  ---------------  \n",
            "meirnizri/covid19-dataset                                       COVID-19 Dataset                                 5MB  2022-11-13 15:47:17          14622        418  1.0              \n",
            "thedevastator/analyzing-credit-card-spending-habits-in-india    Credit Card Spending Habits in India           319KB  2022-12-14 07:30:37           1366         50  1.0              \n",
            "michals22/coffee-dataset                                        Coffee dataset                                  24KB  2022-12-15 20:02:12           3506         78  1.0              \n",
            "thedevastator/unlock-profits-with-e-commerce-sales-data         E-Commerce Sales Dataset                         6MB  2022-12-03 09:27:17           2756         66  1.0              \n",
            "thedevastator/jobs-dataset-from-glassdoor                       Salary Prediction                                3MB  2022-11-16 13:52:31           8251        178  1.0              \n",
            "die9origephit/fifa-world-cup-2022-complete-dataset              Fifa World Cup 2022: Complete Dataset            7KB  2022-12-18 22:51:11           2971        109  1.0              \n",
            "mattop/highest-grossing-mobile-games                            Highest Grossing Mobile Games                    3KB  2022-12-19 15:20:22            688         31  1.0              \n",
            "thedevastator/uncover-global-trends-in-mental-health-disorder   Global Trends in Mental Health Disorder          1MB  2022-12-14 05:30:38            994         31  1.0              \n",
            "rajkumarpandey02/fifa-world-cup-attendance-19302022             FIFA World Cup Attendance 1930-2022              5KB  2022-12-19 10:04:26            945         25  1.0              \n",
            "devrimtuner/number-of-road-motor-vehicles-turkey                Number of road motor vehicles 🇹🇷                 3KB  2022-12-25 13:04:17            284         23  0.9411765        \n",
            "thedevastator/revealing-insights-from-youtube-video-and-channe  YouTube Videos and Channels Metadata            82MB  2022-12-14 02:48:24            717         35  1.0              \n",
            "thedevastator/uncovering-insights-to-college-majors-and-their   College Majors and their Graduates              39KB  2022-12-06 16:06:52           1461         43  1.0              \n",
            "sejungjenn/spotify-best-songs-of-2022                           Spotify: Winner Tracks Audio Features🎹          38KB  2022-12-28 08:06:49            243         21  1.0              \n",
            "mvieira101/global-cost-of-living                                Global Cost of Living                            1MB  2022-12-03 16:37:53           3946         80  0.9705882        \n",
            "anashamoutni/students-employability-dataset                     Students' Employability Dataset - Philippines   97KB  2022-12-18 15:51:39            839         30  0.88235295       \n",
            "swaptr/fifa-world-cup-2022-statistics                           FIFA World Cup 2022 Team Data                   15KB  2022-12-19 00:29:15           2879         64  0.9705882        \n",
            "thedevastator/the-ultimate-netflix-tv-shows-and-movies-dataset  Netflix TV Shows and Movies (2022 Updated)       2MB  2022-11-27 20:41:41           2881         55  1.0              \n",
            "whenamancodes/predict-diabities                                 Predict Diabetes                                 9KB  2022-11-09 12:18:49           8580        135  1.0              \n",
            "kulturehire/understanding-career-aspirations-of-genz            Understanding Career Aspirations of GenZ         8KB  2022-12-21 13:44:32            388         25  0.9117647        \n",
            "thedevastator/uncovering-wage-disparities-in-pennsylvania-s-hi  Higher Education Wages                         223KB  2022-12-04 15:42:36           1446         46  1.0              \n"
          ]
        }
      ],
      "source": [
        "\n",
        "from google.colab import files\n",
        "files.upload() # expire any previous token(s) and upload recreated token\n",
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "!kaggle datasets list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "421Djk4r4qJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6429d506-1ae6-4149-9752-dcb0b653a335"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading otto-full-optimized-memory-footprint.zip to /content/kaggle\n",
            "100% 1.09G/1.09G [00:48<00:00, 29.9MB/s]\n",
            "100% 1.09G/1.09G [00:48<00:00, 23.9MB/s]\n"
          ]
        }
      ],
      "source": [
        "!kaggle datasets download 'radek1/otto-full-optimized-memory-footprint' -p /content/kaggle/ --unzip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oEHOvYJT5rFN"
      },
      "source": [
        "## Files\n",
        "- **train.jsonl** - the training data, which contains full session data\n",
        "  * `session` - the unique session id\n",
        "  * `events` - the time ordered sequence of events in the session\n",
        "    * `aid` - the article id (product code) of the associated event\n",
        "    * `ts` - the Unix timestamp of the event\n",
        "    * `type` - the event type, i.e., whether a product was clicked, added to the user's cart, or ordered during the session\n",
        "###### {'clicks': 0, 'carts': 1, 'orders': 2}\n",
        "- **test.jsonl** - the test data, which contains truncated session data\n",
        "  * your task is to predict the next `aid` clicked after the session truncation, as well as the the remaining `aids` that are added to `carts` and `orders`; you may predict up to 20 values for each session `type`\n",
        "- **sample_submission.csv** - a sample submission file in the correct format"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4G116qol4MLE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_parquet('/content/kaggle/train.parquet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "FLDf82A-5bMG"
      },
      "outputs": [],
      "source": [
        "# sample 10%(frac=0.1) of data\n",
        "df = df.sample(frac=0.001, replace=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "N-Q_j2wx7Omc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "5c709b91-ed58-4f0f-cb9c-eaa25e7681e0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           session      aid          ts  type\n",
              "178431972  8874432  1666901  1660571057     1\n",
              "168730771  8000950   226839  1660857489     0\n",
              "73797448   2222821  1294636  1659502585     0\n",
              "87901738   2856696    72748  1660476952     0\n",
              "126407384  4927474   335903  1660582578     0\n",
              "...            ...      ...         ...   ...\n",
              "123253187  4751973  1383529  1660335234     0\n",
              "121076270  4625071   226628  1660409032     0\n",
              "143991820  6043013  1236345  1660059941     0\n",
              "31319654    744959   794192  1659695074     0\n",
              "84836289   2710915   275952  1660768530     0\n",
              "\n",
              "[216716 rows x 4 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2548f4d8-f4d5-4c13-bb46-7f9d445fc35b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>session</th>\n",
              "      <th>aid</th>\n",
              "      <th>ts</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>178431972</th>\n",
              "      <td>8874432</td>\n",
              "      <td>1666901</td>\n",
              "      <td>1660571057</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168730771</th>\n",
              "      <td>8000950</td>\n",
              "      <td>226839</td>\n",
              "      <td>1660857489</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73797448</th>\n",
              "      <td>2222821</td>\n",
              "      <td>1294636</td>\n",
              "      <td>1659502585</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87901738</th>\n",
              "      <td>2856696</td>\n",
              "      <td>72748</td>\n",
              "      <td>1660476952</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126407384</th>\n",
              "      <td>4927474</td>\n",
              "      <td>335903</td>\n",
              "      <td>1660582578</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123253187</th>\n",
              "      <td>4751973</td>\n",
              "      <td>1383529</td>\n",
              "      <td>1660335234</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121076270</th>\n",
              "      <td>4625071</td>\n",
              "      <td>226628</td>\n",
              "      <td>1660409032</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143991820</th>\n",
              "      <td>6043013</td>\n",
              "      <td>1236345</td>\n",
              "      <td>1660059941</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31319654</th>\n",
              "      <td>744959</td>\n",
              "      <td>794192</td>\n",
              "      <td>1659695074</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84836289</th>\n",
              "      <td>2710915</td>\n",
              "      <td>275952</td>\n",
              "      <td>1660768530</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>216716 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2548f4d8-f4d5-4c13-bb46-7f9d445fc35b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2548f4d8-f4d5-4c13-bb46-7f9d445fc35b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2548f4d8-f4d5-4c13-bb46-7f9d445fc35b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "I6SK6ahjEpy9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00271d30-a4bf-4f87-932a-9225d1383186"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "session    0\n",
              "aid        0\n",
              "ts         0\n",
              "type       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "h8hFppsb5cAW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7355cdc8-9ba2-4c27-b590-382446b17e4d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 2], dtype=uint8)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "df['type'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "OFhgeI-OgFEz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5559a12-6aae-4673-d478-a60be519adec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 216716 entries, 178431972 to 84836289\n",
            "Data columns (total 4 columns):\n",
            " #   Column   Non-Null Count   Dtype\n",
            "---  ------   --------------   -----\n",
            " 0   session  216716 non-null  int32\n",
            " 1   aid      216716 non-null  int32\n",
            " 2   ts       216716 non-null  int32\n",
            " 3   type     216716 non-null  uint8\n",
            "dtypes: int32(3), uint8(1)\n",
            "memory usage: 4.3 MB\n"
          ]
        }
      ],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49ElfBTh-Zen"
      },
      "source": [
        "# Construct Graph Data (memory-efficient optimized)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FriR71pK-hxH"
      },
      "source": [
        "### [Use new code instead] Construct `edge_index`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Jw0zU0aTMZ-G"
      },
      "outputs": [],
      "source": [
        "#def to_tuple(row):\n",
        "#    return tuple(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "D1eMUs7A8qbA"
      },
      "outputs": [],
      "source": [
        "# also drop the ts and type column\n",
        "#connectivity = df.drop(columns=['ts', 'type']).apply(to_tuple, axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "h8KsppDI7dvJ"
      },
      "outputs": [],
      "source": [
        "#connectivity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "p2Yv20LW0Bad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cfc65f71-e1c0-4240-abcf-bd21df6943ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# session index dict\\n#session = sorted(df['session'].unique())\\nsession = df['session'].unique()\\nsession_nodes_idx = {id:idx for idx, id in enumerate(session)}\\n\\n# aid(article id) index dict\\n#aid = sorted(df['aid'].unique())\\naid = df['aid'].unique()\\naid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "# Old code\n",
        "'''\n",
        "# session index dict\n",
        "#session = sorted(df['session'].unique())\n",
        "session = df['session'].unique()\n",
        "session_nodes_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "#aid = sorted(df['aid'].unique())\n",
        "aid = df['aid'].unique()\n",
        "aid_nodes_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xTiXlCrOQYYm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8bcff932-7ae7-4020-9e08-6012e46a612e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef get_node_indices(data, key):\\n  for id in data[key].unique():\\n    yield id, next(i for i, v in enumerate(data[key]) if v == id)\\n\\nsession_nodes_idx = dict(get_node_indices(df, 'session'))\\naid_nodes_idx = dict(get_node_indices(df, 'aid'))\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# use this code if the above cause memory crash\n",
        "# very slow but memory good\n",
        "'''\n",
        "def get_node_indices(data, key):\n",
        "  for id in data[key].unique():\n",
        "    yield id, next(i for i, v in enumerate(data[key]) if v == id)\n",
        "\n",
        "session_nodes_idx = dict(get_node_indices(df, 'session'))\n",
        "aid_nodes_idx = dict(get_node_indices(df, 'aid'))\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "tpiPnhRYN7X4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0ba7af95-4d36-47d1-e63a-c45fcbd44884"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ni_session = []\\ni_aid = []\\nfor session, aid in connectivity_list:\\n  i_session.append(user_nodes_idx[user])\\n  i_aid.append(item_nodes_idx[item])\\n\\nindice = [i_session, i_aid]\\nedge_index = torch.Tensor(indice).type(torch.long)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "# /!\\ this cause memory crashed in a very large data\n",
        "'''\n",
        "i_session = []\n",
        "i_aid = []\n",
        "for session, aid in connectivity_list:\n",
        "  i_session.append(user_nodes_idx[user])\n",
        "  i_aid.append(item_nodes_idx[item])\n",
        "\n",
        "indice = [i_session, i_aid]\n",
        "edge_index = torch.Tensor(indice).type(torch.long)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "My-fApG4OR-4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8531703f-599d-4020-ac6d-96c8cdc486fe"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\\n  for user, item in connectivity_list:\\n    yield user_nodes_idx[user], item_nodes_idx[item]\\n\\nedge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "# Work but still got memory crash in very large data\n",
        "'''\n",
        "def get_indices(connectivity_list, user_nodes_idx, item_nodes_idx):\n",
        "  for user, item in connectivity_list:\n",
        "    yield user_nodes_idx[user], item_nodes_idx[item]\n",
        "\n",
        "edge_index = torch.Tensor(list(get_indices(connectivity, session_nodes_idx, aid_nodes_idx))).type(torch.int64).t()\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqgOrM6ak915"
      },
      "source": [
        "### `edge_index` new code construct"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ERcykcKRz4Ri"
      },
      "outputs": [],
      "source": [
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "QvTKqD08lNFz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9747e980-034d-4da5-fd2a-cc28689b5640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-fdbbf2e7eb54>:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['session'] = connected['session'].map(source_idx)\n",
            "<ipython-input-20-fdbbf2e7eb54>:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  connected['aid'] = connected['aid'].map(target_idx)\n"
          ]
        }
      ],
      "source": [
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "4L_GWK4hlTWM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e22fbf7-1c59-4054-9e18-3b8f394ecf29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-23961f25841f>:3: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
            "  edge_index = torch.tensor((source.values, target.values))\n"
          ]
        }
      ],
      "source": [
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fUkcZdZr8seK"
      },
      "source": [
        "### Nodes and Edges Attribute"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "RhWwQXMjeeLe"
      },
      "outputs": [],
      "source": [
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Dn3bodEPSWNd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0399306-899d-4ebf-8b42-7fc28a396ef2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "edge_label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "xXl7YIluHxDc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6576e327-bdd4-4f8a-8fad-6a02f900882f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 216716])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "edge_index.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zEQRr1JTIMYo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62cbdda1-cf24-4374-b3e1-98de7a65c32d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([127796, 300])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "aid_features.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "TLVPfcmsIThg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c1655e1-f299-460a-b719-bd915d72cd0b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "edge_label.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5J--mpmD9kvX"
      },
      "source": [
        "### Construct HeteroData"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "thFGYWY19noW"
      },
      "outputs": [],
      "source": [
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "7oqr0nhb94Ml"
      },
      "outputs": [],
      "source": [
        "data = HeteroData({**node_types, **edge_types})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "gGH8Sd8O97x7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f3e1c21-0382-4f96-d393-b9fc5d4c0cea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={ num_nodes=208219 },\n",
              "  \u001b[1maid\u001b[0m={ x=[127796, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "9F9gevNn-Ms3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "203e018b-a494-4070-da88-26f7f3803fc4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['session', 'aid'], [('session', 'event', 'aid')])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "data.metadata()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TArUgtyn-OZV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6113d9c-46f4-47db-cf8d-c3e2b9b118c2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node types: ['session', 'aid']\n",
            "Edge types: [('session', 'event', 'aid')]\n"
          ]
        }
      ],
      "source": [
        "node_types, edge_types = data.metadata()\n",
        "print('Node types:', node_types)\n",
        "print('Edge types:',edge_types)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "wQNhuNgM-Tar",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "641def90-7021-4cea-f827-d821cd7a938a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isolated nodes? False\n",
            "Self loops? False\n",
            "Undirected graph?  False\n"
          ]
        }
      ],
      "source": [
        "print('Isolated nodes?', data.has_isolated_nodes())\n",
        "print('Self loops?', data.has_self_loops())\n",
        "print('Undirected graph? ', data.is_undirected())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ztCYkbwc-z5g"
      },
      "source": [
        "# Graph-based Modeling [follow [this](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py) sample]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "dZHLxib5XVms"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeGH76ns-4pE"
      },
      "source": [
        "### Construct Undirected Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "abuvJ0L1-qcH"
      },
      "outputs": [],
      "source": [
        "# add sesion features for message passing:\n",
        "data['session'].x = torch.rand(data['session'].num_nodes, 300)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "_FgnuDqBXuX5"
      },
      "outputs": [],
      "source": [
        "# Add user node features for message passing:\n",
        "#data['session'].x = torch.eye(data['session'].num_nodes, device=device)\n",
        "#del data['session'].num_nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "r2yFSVWd_Jl8"
      },
      "outputs": [],
      "source": [
        "# Add a reverse ('movie', 'rev_rates', 'user') relation for message passing:\n",
        "data = T.ToUndirected()(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "-gslQ3AmKTUM"
      },
      "outputs": [],
      "source": [
        "del data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "d50QCHYyKBNh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49c46930-b8b2-4ea0-baa7-7cbffab6536a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208219,\n",
              "    x=[208219, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127796, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKqQxQA0-X44"
      },
      "source": [
        "### Calculate Weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5QvT19CNOtUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b90536c5-4519-46ef-9902-58d556b44b33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([216716])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "data['session', 'aid'].edge_label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "Jlz46YER-Uns"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "\n",
        "counts = torch.bincount(data['session', 'aid'].edge_label)\n",
        "\n",
        "# Set weights normalized by (max count/each count)\n",
        "weight = counts.max() / counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "cZEH42kKOl58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e50227d-0061-40c3-b322-0565ffc3a3c6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([194613,  17035,   5068])"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ],
      "source": [
        "counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Rw__CF6WOife",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8834418-9576-47f5-c3a5-373a7b3f98b1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.4243, 38.4004])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "nLOdlJzR-hDm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "b82f5d13-b146-4e11-d741-b428ab4f3a28"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-2.8.3.min.js\"></script>                <div id=\"5f54023f-2d51-45a1-8e98-edd9c073967c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"5f54023f-2d51-45a1-8e98-edd9c073967c\")) {                    Plotly.newPlot(                        \"5f54023f-2d51-45a1-8e98-edd9c073967c\",                        [{\"line\":{\"color\":\"coral\"},\"name\":\"nb rows\",\"x\":[0,1,2,3,4,5],\"y\":[194613,17035,5068],\"type\":\"scatter\"},{\"line\":{\"color\":\"royalblue\"},\"name\":\"weights\",\"x\":[0,1,2,3,4,5],\"y\":[1.0,11.42430305480957,38.40035629272461],\"type\":\"scatter\",\"xaxis\":\"x\",\"yaxis\":\"y2\"}],                        {\"template\":{\"data\":{\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"white\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"#C8D4E3\",\"linecolor\":\"#C8D4E3\",\"minorgridcolor\":\"#C8D4E3\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"choropleth\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"choropleth\"}],\"contour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"contour\"}],\"contourcarpet\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"contourcarpet\"}],\"heatmap\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmap\"}],\"heatmapgl\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"heatmapgl\"}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"histogram2d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2d\"}],\"histogram2dcontour\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"histogram2dcontour\"}],\"mesh3d\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"type\":\"mesh3d\"}],\"parcoords\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"parcoords\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}],\"scatter\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter\"}],\"scatter3d\":[{\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatter3d\"}],\"scattercarpet\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattercarpet\"}],\"scattergeo\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergeo\"}],\"scattergl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattergl\"}],\"scattermapbox\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scattermapbox\"}],\"scatterpolar\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolar\"}],\"scatterpolargl\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterpolargl\"}],\"scatterternary\":[{\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"type\":\"scatterternary\"}],\"surface\":[{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"type\":\"surface\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}]},\"layout\":{\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"autotypenumbers\":\"strict\",\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]],\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]},\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"geo\":{\"bgcolor\":\"white\",\"lakecolor\":\"white\",\"landcolor\":\"white\",\"showlakes\":true,\"showland\":true,\"subunitcolor\":\"#C8D4E3\"},\"hoverlabel\":{\"align\":\"left\"},\"hovermode\":\"closest\",\"mapbox\":{\"style\":\"light\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"white\",\"polar\":{\"angularaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"radialaxis\":{\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\"}},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"yaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"},\"zaxis\":{\"backgroundcolor\":\"white\",\"gridcolor\":\"#DFE8F3\",\"gridwidth\":2,\"linecolor\":\"#EBF0F8\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"#EBF0F8\"}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"ternary\":{\"aaxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"},\"bgcolor\":\"white\",\"caxis\":{\"gridcolor\":\"#DFE8F3\",\"linecolor\":\"#A2B1C6\",\"ticks\":\"\"}},\"title\":{\"x\":0.05},\"xaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2},\"yaxis\":{\"automargin\":true,\"gridcolor\":\"#EBF0F8\",\"linecolor\":\"#EBF0F8\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"#EBF0F8\",\"zerolinewidth\":2}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,0.94],\"title\":{\"text\":\"Type\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"# rows\"}},\"yaxis2\":{\"anchor\":\"x\",\"overlaying\":\"y\",\"side\":\"right\",\"title\":{\"text\":\"weights\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('5f54023f-2d51-45a1-8e98-edd9c073967c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "data_dict = {'type': (counts, '# rows','coral'), 'weights': (weight, 'weights','royalblue')}\n",
        "\n",
        "fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
        "\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=counts.detach().cpu().numpy(),\n",
        "               name = 'nb rows', line_color= 'coral'))\n",
        "fig.add_trace(\n",
        "    go.Scatter(x=np.arange(6), y=weight.detach().cpu().numpy(),\n",
        "               name = 'weights', line_color= 'royalblue'),  secondary_y=True)\n",
        "\n",
        "\n",
        "fig.update_yaxes(title_text=\"# rows\", secondary_y=False)\n",
        "fig.update_yaxes(title_text=\"weights\", secondary_y=True)\n",
        "fig.update_xaxes(title_text=\"Type\")\n",
        "fig"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ef-03GCf_Oxr"
      },
      "source": [
        "### [Follow [this sample](https://github.com/pyg-team/pytorch_geometric/blob/master/examples/hetero/hetero_link_pred.py)] Train/Val/Test Link Level Splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "hvV62Miw_MsX"
      },
      "outputs": [],
      "source": [
        "# Perform a link-level split into training, validation, and test edges:\n",
        "train_data, val_data, test_data = T.RandomLinkSplit(\n",
        "    num_val=0.1,\n",
        "    num_test=0.1,\n",
        "    neg_sampling_ratio=0.0,\n",
        "    edge_types=[('session', 'event', 'aid')],\n",
        "    rev_edge_types=[('aid', 'rev_event', 'session')],\n",
        ")(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "5kq9vMp3Rxeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56e57a2e-8a6f-4d81-8c63-0f8c0ae022bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'edge_index': tensor([[ 62423,   9991,  27914,  ...,  33016, 198085,  23915],\n",
              "        [ 47901,   9226,  23652,  ...,  27468,   6702,   9892]]), 'edge_label': tensor([0, 0, 0,  ..., 0, 0, 0]), 'edge_label_index': tensor([[ 62423,   9991,  27914,  ...,  33016, 198085,  23915],\n",
              "        [ 47901,   9226,  23652,  ...,  27468,   6702,   9892]])}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "train_data['session','aid']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "VzTgyXxUSGfd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71bdd8f1-2cbf-461d-e4e8-331e83098b4c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "train_data['session','aid'].edge_label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hP4jgsOZMOh"
      },
      "source": [
        "### [New weight calculation code]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "W1ybCASOaUKr"
      },
      "outputs": [],
      "source": [
        "# We have an unbalanced dataset with many labels for rating 3 and 4, and very\n",
        "# few for 0 and 1. Therefore we use a weighted MSE loss.\n",
        "weight = torch.bincount(train_data['session', 'aid'].edge_label)\n",
        "weight = weight.max() / weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4N6oASmHaoa5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8cdb96fc-bdc3-4a0f-9a75-84924968f0ba"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 1.0000, 11.4673, 38.6405])"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ],
      "source": [
        "weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDg2LABBDxBt"
      },
      "source": [
        "### Model and loss functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7hz16UUZat_8"
      },
      "source": [
        "#### Loss function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "ZwB6r5v2_9rP"
      },
      "outputs": [],
      "source": [
        "def weighted_mse_loss(pred, target, weight=None):\n",
        "    weight = 1. if weight is None else weight[target].to(pred.dtype)\n",
        "    return (weight * (pred - target.to(pred.dtype)).pow(2)).mean()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRJAlWmZawxE"
      },
      "source": [
        "#### Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "FbXiKVzibBOM"
      },
      "outputs": [],
      "source": [
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels):\n",
        "        super().__init__()\n",
        "        self.conv1 = SAGEConv((-1, -1), hidden_channels)\n",
        "        self.conv2 = SAGEConv((-1, -1), out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index).relu()\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return x\n",
        "\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "\n",
        "        return z.view(-1)\n",
        "\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels)\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels)\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict)\n",
        "        return self.decoder(z_dict, edge_label_index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "tXF-GhlFeWty"
      },
      "outputs": [],
      "source": [
        "model = Model(hidden_channels=32).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "ZENXvG8wealJ"
      },
      "outputs": [],
      "source": [
        "# Due to lazy initialization, we need to run one model step so the number\n",
        "# of parameters can be inferred:\n",
        "with torch.no_grad():\n",
        "    model.encoder(train_data.x_dict, train_data.edge_index_dict)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "ayGHaB6JegtI"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "RIjLW5AteiWZ"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def test(data):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=-1, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Mt5-wzRekay",
        "outputId": "b52c37a6-2f5f-419d-c00e-67e5f84e2c67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 000, Loss: 5.1650, Train: 1.9162, Val: 1.5072, Test: 1.5297\n",
            "Epoch: 001, Loss: 20.5864, Train: 0.4403, Val: 0.4473, Test: 0.4484\n",
            "Epoch: 002, Loss: 4.8751, Train: 0.4503, Val: 0.4562, Test: 0.4571\n",
            "Epoch: 003, Loss: 5.0090, Train: 0.4040, Val: 0.4138, Test: 0.4143\n",
            "Epoch: 004, Loss: 3.4761, Train: 0.5509, Val: 0.4303, Test: 0.4328\n",
            "Epoch: 005, Loss: 2.4483, Train: 0.9131, Val: 0.5743, Test: 0.5816\n",
            "Epoch: 006, Loss: 1.8065, Train: 1.3928, Val: 0.8120, Test: 0.8247\n",
            "Epoch: 007, Loss: 2.3710, Train: 1.4948, Val: 0.8744, Test: 0.8883\n",
            "Epoch: 008, Loss: 2.6646, Train: 1.2891, Val: 0.7669, Test: 0.7787\n",
            "Epoch: 009, Loss: 2.1332, Train: 1.0013, Val: 0.6272, Test: 0.6359\n",
            "Epoch: 010, Loss: 1.8047, Train: 0.7801, Val: 0.5311, Test: 0.5372\n",
            "Epoch: 011, Loss: 1.9093, Train: 0.6687, Val: 0.4862, Test: 0.4909\n",
            "Epoch: 012, Loss: 2.1021, Train: 0.6274, Val: 0.4702, Test: 0.4743\n",
            "Epoch: 013, Loss: 2.2037, Train: 0.6385, Val: 0.4733, Test: 0.4775\n",
            "Epoch: 014, Loss: 2.1745, Train: 0.6949, Val: 0.4937, Test: 0.4986\n",
            "Epoch: 015, Loss: 2.0467, Train: 0.7941, Val: 0.5326, Test: 0.5387\n",
            "Epoch: 016, Loss: 1.8923, Train: 0.9275, Val: 0.5898, Test: 0.5975\n",
            "Epoch: 017, Loss: 1.8024, Train: 1.0702, Val: 0.6556, Test: 0.6649\n",
            "Epoch: 018, Loss: 1.8375, Train: 1.1783, Val: 0.7075, Test: 0.7180\n",
            "Epoch: 019, Loss: 1.9478, Train: 1.2099, Val: 0.7224, Test: 0.7332\n",
            "Epoch: 020, Loss: 1.9933, Train: 1.1593, Val: 0.6964, Test: 0.7066\n",
            "Epoch: 021, Loss: 1.9233, Train: 1.0583, Val: 0.6466, Test: 0.6557\n",
            "Epoch: 022, Loss: 1.8295, Train: 0.9486, Val: 0.5946, Test: 0.6024\n",
            "Epoch: 023, Loss: 1.7991, Train: 0.8599, Val: 0.5545, Test: 0.5612\n",
            "Epoch: 024, Loss: 1.8320, Train: 0.8047, Val: 0.5304, Test: 0.5365\n",
            "Epoch: 025, Loss: 1.8801, Train: 0.7849, Val: 0.5219, Test: 0.5277\n",
            "Epoch: 026, Loss: 1.9028, Train: 0.7985, Val: 0.5271, Test: 0.5331\n",
            "Epoch: 027, Loss: 1.8868, Train: 0.8413, Val: 0.5449, Test: 0.5514\n",
            "Epoch: 028, Loss: 1.8455, Train: 0.9068, Val: 0.5734, Test: 0.5806\n",
            "Epoch: 029, Loss: 1.8077, Train: 0.9828, Val: 0.6078, Test: 0.6159\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(0, 30):\n",
        "    loss = train()\n",
        "    train_rmse = test(train_data)\n",
        "    val_rmse = test(val_data)\n",
        "    test_rmse = test(test_data)\n",
        "    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Train: {train_rmse:.4f}, '\n",
        "          f'Val: {val_rmse:.4f}, Test: {test_rmse:.4f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "joyCx1zCnzl2",
        "outputId": "9931091f-b0d1-488f-d946-f7757773a846"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Model(\n",
              "  (encoder): GraphModule(\n",
              "    (conv1): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "    (conv2): ModuleDict(\n",
              "      (session__event__aid): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "      (aid__rev_event__session): SAGEConv((-1, -1), 32, aggr=mean)\n",
              "    )\n",
              "  )\n",
              "  (decoder): EdgeDecoder(\n",
              "    (lin1): Linear(64, 32, bias=True)\n",
              "    (lin2): Linear(32, 1, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SxYona145IU",
        "outputId": "466e8861-f2c5-4d2c-96f5-9f85a2acb97b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208219,\n",
              "    x=[208219, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[127796, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.encoder(data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fbPqjTSINEG",
        "outputId": "d495c966-66de-4592-c8f8-2bfae4766136"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'session': tensor([[-3.5903, -0.6269,  0.8789,  ..., -0.0389, -3.3460,  2.3984],\n",
              "         [-3.7468, -0.6740,  0.9323,  ..., -0.0577, -3.4996,  2.4976],\n",
              "         [-3.7805, -0.7761,  0.9828,  ..., -0.1320, -3.5745,  2.4874],\n",
              "         ...,\n",
              "         [-3.7491, -0.6924,  0.9406,  ..., -0.0715, -3.5099,  2.4930],\n",
              "         [-3.8528, -0.6636,  0.9506,  ..., -0.0380, -3.5844,  2.5793],\n",
              "         [-3.8346, -0.6761,  0.9520,  ..., -0.0496, -3.5747,  2.5617]],\n",
              "        grad_fn=<AddBackward0>),\n",
              " 'aid': tensor([[ 0.5448, -1.9583, -1.7577,  ...,  2.4216,  1.0269, -1.8583],\n",
              "         [ 0.5748, -2.1003, -1.8678,  ...,  2.5483,  1.0993, -1.9665],\n",
              "         [ 0.5725, -2.0724, -1.8366,  ...,  2.4797,  1.0972, -1.9127],\n",
              "         ...,\n",
              "         [ 0.5617, -2.0295, -1.8080,  ...,  2.4627,  1.0694, -1.8958],\n",
              "         [ 0.5518, -1.9613, -1.7436,  ...,  2.3486,  1.0494, -1.8042],\n",
              "         [ 0.5624, -2.0436, -1.8250,  ...,  2.5031,  1.0689, -1.9273]],\n",
              "        grad_fn=<AddBackward0>)}"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test dataset"
      ],
      "metadata": {
        "id": "WLHyzIiNECx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#df = pd.read_parquet('/content/kaggle/test.parquet')"
      ],
      "metadata": {
        "id": "WDkdfZnxEB02"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df.sample(frac=0.01, replace=False)"
      ],
      "metadata": {
        "id": "AkgwhJjiIyAm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df"
      ],
      "metadata": {
        "id": "Q4LGeBz9EPjh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Construct heterogenous graph for test"
      ],
      "metadata": {
        "id": "iY12RhftEWwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# session index dict\n",
        "session = df['session'].unique()\n",
        "source_idx = {id:idx for idx, id in enumerate(session)}\n",
        "\n",
        "# aid(article id) index dict\n",
        "aid = df['aid'].unique()\n",
        "target_idx = {id:idx for idx, id in enumerate(aid)}\n",
        "'''"
      ],
      "metadata": {
        "id": "VQwWWWsnEfli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "connected = df[['session', 'aid']]\n",
        "connected['session'] = connected['session'].map(source_idx)\n",
        "connected['aid'] = connected['aid'].map(target_idx)\n",
        "\n",
        "source = connected['session']\n",
        "target = connected['aid']\n",
        "edge_index = torch.tensor((source.values, target.values)).type(torch.int64)\n",
        "'''"
      ],
      "metadata": {
        "id": "BITDjJKVEwpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "## Nodes Atrributes\n",
        "session_num_nodes = df['session'].nunique()\n",
        "aid_num_nodes = df['aid'].nunique()\n",
        "aid_features = torch.rand((aid_num_nodes, 300)) # Create (random) article features with shape [num_node_aid, dimensions]\n",
        "\n",
        "## Edges Atrributes\n",
        "edge_index = edge_index\n",
        "edge_label = torch.tensor(df['type'].values).type(torch.int64)\n",
        "'''"
      ],
      "metadata": {
        "id": "WZjCOHTlE0Xf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "node_types = {\n",
        "    'session': {\n",
        "        'num_nodes': session_num_nodes\n",
        "    },\n",
        "    'aid': {\n",
        "        'x': aid_features\n",
        "    }\n",
        "}\n",
        "\n",
        "edge_types = {\n",
        "    ('session', 'event', 'aid'): {\n",
        "        'edge_index': edge_index,\n",
        "        'edge_label': edge_label,\n",
        "        'edge_label_index': edge_index\n",
        "    }#,\n",
        "    #('session', 'cart', 'aid'): {\n",
        "        \n",
        "    #},\n",
        "    #('session', 'buy', 'aid'): {\n",
        "        \n",
        "    #}\n",
        "}\n",
        "'''"
      ],
      "metadata": {
        "id": "uwJLoByFFATA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data = HeteroData({**node_types, **edge_types})"
      ],
      "metadata": {
        "id": "UY3tqA4HFG3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data"
      ],
      "metadata": {
        "id": "OnPMRj27FwbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data"
      ],
      "metadata": {
        "id": "vC_MYbqNFK_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# add sesion features for message passing:\n",
        "Rtest_data['session'].x = torch.rand(Rtest_data['session'].num_nodes, 300)\n",
        "\n",
        "Rtest_data = T.ToUndirected()(Rtest_data)\n",
        "del Rtest_data['aid', 'rev_event', 'session'].edge_label  # Remove \"reverse\" label.\n",
        "'''"
      ],
      "metadata": {
        "id": "0ktGWQnnIPbL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data"
      ],
      "metadata": {
        "id": "Eb6N2GaqNj_e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing"
      ],
      "metadata": {
        "id": "1serMeUuEf8-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    gg = model(Rtest_data.x_dict, Rtest_data.edge_index_dict, Rtest_data['session', 'aid'].edge_label_index)\n",
        "'''"
      ],
      "metadata": {
        "id": "FsVoiBSqLsrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eUS0_0PjKKY",
        "outputId": "a8709273-84c0-49b1-9c81-5b45ad4d4dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Rtest_data['session', 'aid'].edge_label"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RilROrFHN-xZ",
        "outputId": "e3c8438a-b917-4372-8022-250217ccbdf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 0,  ..., 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#gg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eW4XhiQHhf7f",
        "outputId": "40793654-ba8f-4c49-ecae-44252d9ee6f1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.9765, 0.9353, 0.9445,  ..., 0.9290, 0.9750, 0.9879])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRQNaMN8fSz8",
        "outputId": "d2864c0a-b70c-4803-d59e-c9c1dd1c059c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "HeteroData(\n",
              "  \u001b[1msession\u001b[0m={\n",
              "    num_nodes=208318,\n",
              "    x=[208318, 300]\n",
              "  },\n",
              "  \u001b[1maid\u001b[0m={ x=[128140, 300] },\n",
              "  \u001b[1m(session, event, aid)\u001b[0m={\n",
              "    edge_index=[2, 216716],\n",
              "    edge_label=[216716]\n",
              "  },\n",
              "  \u001b[1m(aid, rev_event, session)\u001b[0m={ edge_index=[2, 216716] }\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHNbZyHebUPV"
      },
      "source": [
        "# [TEMPORARY DROP]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NTRQjhLACfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d90c38fc-0055-4bfb-d197-8259d095b44d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nclass GNNEncoder(torch.nn.Module):\\n    def __init__(self, hidden_channels, out_channels, conv):\\n        super().__init__()\\n        # conv(#in_channels, #out_channels)\\n        \\n        in_channels (int or tuple): \\n            Size of each input sample, or :obj:`-1` to\\n            derive the size from the first input(s) to the forward method.\\n            A tuple corresponds to the sizes of source and target\\n            dimensionalities.\\n        \\n        self.conv1 = conv((-1, -1), hidden_channels)\\n        self.conv2 = conv((-1, -1), out_channels)\\n        self.linear1 = Linear(-1, out_channels)\\n        self.linear2 = Linear(-1, out_channels)\\n\\n    def forward(self, x, edge_index):\\n        x0 = self.linear1(x)\\n        x2 = self.conv1(x0, edge_index).relu()\\n        x3 = self.conv2(x2, edge_index)\\n        x4 = self.linear2(x2 + x3)\\n        # Add combined layer to reduce over-smoothing\\n        return x4\\n\\nclass EdgeDecoder(torch.nn.Module):\\n    def __init__(self, hidden_channels):\\n        super().__init__()\\n        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\\n        self.lin2 = Linear(hidden_channels, 1)\\n\\n    def forward(self, z_dict, edge_label_index):\\n        row, col = edge_label_index\\n        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\\n        z = self.lin1(z).relu()\\n        z = self.lin2(z)\\n        return z.view(-1)\\n\\nclass Model(torch.nn.Module):\\n    def __init__(self, hidden_channels,  conv=SAGEConv):\\n        super().__init__()\\n        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\\n        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\\n        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\\n\\n    def forward(self, x_dict, edge_index_dict, edge_label_index):\\n        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\\n        return self.decoder(z_dict, edge_label_index)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 77
        }
      ],
      "source": [
        "# Temporary comment\n",
        "'''\n",
        "class GNNEncoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels, out_channels, conv):\n",
        "        super().__init__()\n",
        "        # conv(#in_channels, #out_channels)\n",
        "        ''''''\n",
        "        in_channels (int or tuple): \n",
        "            Size of each input sample, or :obj:`-1` to\n",
        "            derive the size from the first input(s) to the forward method.\n",
        "            A tuple corresponds to the sizes of source and target\n",
        "            dimensionalities.\n",
        "        ''''''\n",
        "        self.conv1 = conv((-1, -1), hidden_channels)\n",
        "        self.conv2 = conv((-1, -1), out_channels)\n",
        "        self.linear1 = Linear(-1, out_channels)\n",
        "        self.linear2 = Linear(-1, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x0 = self.linear1(x)\n",
        "        x2 = self.conv1(x0, edge_index).relu()\n",
        "        x3 = self.conv2(x2, edge_index)\n",
        "        x4 = self.linear2(x2 + x3)\n",
        "        # Add combined layer to reduce over-smoothing\n",
        "        return x4\n",
        "\n",
        "class EdgeDecoder(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels):\n",
        "        super().__init__()\n",
        "        self.lin1 = Linear(2 * hidden_channels, hidden_channels)\n",
        "        self.lin2 = Linear(hidden_channels, 1)\n",
        "\n",
        "    def forward(self, z_dict, edge_label_index):\n",
        "        row, col = edge_label_index\n",
        "        z = torch.cat([z_dict['session'][row], z_dict['aid'][col]], dim=-1)\n",
        "        z = self.lin1(z).relu()\n",
        "        z = self.lin2(z)\n",
        "        return z.view(-1)\n",
        "\n",
        "class Model(torch.nn.Module):\n",
        "    def __init__(self, hidden_channels,  conv=SAGEConv):\n",
        "        super().__init__()\n",
        "        self.encoder = GNNEncoder(hidden_channels, hidden_channels,  conv) # Initialize GNNEncoder\n",
        "        self.encoder = to_hetero(self.encoder, data.metadata(), aggr='sum')\n",
        "        self.decoder = EdgeDecoder(hidden_channels) # Initialze EdgeDecoder\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_label_index):\n",
        "        z_dict = self.encoder(x_dict, edge_index_dict) # Here the call from model.encoder(...)\n",
        "        return self.decoder(z_dict, edge_label_index)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JsSAc0seAHmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6234991c-830f-483f-8b04-11dbbed764ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train(train_data, model, optimizer, loss=weighted_mse_loss):\\n    model.train()\\n    optimizer.zero_grad()\\n    pred = model(train_data.x_dict, train_data.edge_index_dict,\\n                 train_data['session', 'aid'].edge_label_index)\\n    target = train_data['session', 'aid'].edge_label\\n    loss = weighted_mse_loss(pred, target, weight)\\n    loss.backward()\\n    optimizer.step()\\n    return float(loss.sqrt())\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "'''\n",
        "def train(train_data, model, optimizer, loss=weighted_mse_loss):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    pred = model(train_data.x_dict, train_data.edge_index_dict,\n",
        "                 train_data['session', 'aid'].edge_label_index)\n",
        "    target = train_data['session', 'aid'].edge_label\n",
        "    loss = weighted_mse_loss(pred, target, weight)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return float(loss.sqrt())\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxHfcosNAXQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "25b4bc51-6888-4fbe-a0b4-f6941582d42a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n@torch.no_grad()\\ndef test(data, model, metric=F.mse_loss):\\n    model.eval()\\n    pred = model(data.x_dict, data.edge_index_dict,\\n                 data['session', 'aid'].edge_label_index)\\n    pred = pred.clamp(min=0, max=2)\\n    target = data['session', 'aid'].edge_label.float()\\n    rmse = F.mse_loss(pred, target).sqrt()\\n    return float(rmse) # Return RMSE loss\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "## set pred.clamp\n",
        "'''\n",
        "@torch.no_grad()\n",
        "def test(data, model, metric=F.mse_loss):\n",
        "    model.eval()\n",
        "    pred = model(data.x_dict, data.edge_index_dict,\n",
        "                 data['session', 'aid'].edge_label_index)\n",
        "    pred = pred.clamp(min=0, max=2)\n",
        "    target = data['session', 'aid'].edge_label.float()\n",
        "    rmse = F.mse_loss(pred, target).sqrt()\n",
        "    return float(rmse) # Return RMSE loss\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PE1pmW4KAXpe"
      },
      "outputs": [],
      "source": [
        "#from tqdm import tqdm\n",
        "#from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M2Mc3SOUAiui",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1cdba3aa-550f-4880-b0a3-9b9541c23b55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\\n    t0 = time.time()\\n\\n    model = model(**model_params) # Define the model\\n\\n    # Due to lazy initialization, we need to run one model step so the number\\n    # of parameters can be inferred:\\n    with torch.no_grad():\\n        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\\n\\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\\n\\n    k=0\\n    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\\n    train_wrmse, val_wrmse, test_wrmse = [], [], []\\n    for epoch in tqdm(range(n_epochs)):\\n        # Call train fuction here >> return loss\\n        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\\n        \\n        # Call test function here >> return RMSE loss\\n        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\\n        train_rmse += [test(train_data, model, metric=F.mse_loss)]\\n        \\n        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\\n        val_rmse += [test(val_data, model, metric=F.mse_loss)]\\n        \\n        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\\n        test_rmse += [test(test_data, model, metric=F.mse_loss)]\\n\\n        if epoch+1 %10==0:\\n            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\\n                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\\n\\n        results = pd.DataFrame({\\n            'loss': loss,\\n            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\\n            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\\n            'time':(time.time()-t0)/60\\n        })\\n        \\n        ## Debugging\\n        #clear_output()\\n        '''\\n        print('\\nloss: ', loss, \\n              '\\ntrain_rmse: ', train_rmse, \\n              '\\nval_rmse: ', val_rmse, \\n              '\\ntest_rmse: ', test_rmse,\\n              '\\ntrain_wrmse: ', train_wrmse, \\n              '\\nval_wrmse: ', val_wrmse, \\n              '\\ntest_wrmse: ', test_wrmse,\\n              '\\ntime: ', (time.time()-t0)/60)\\n        '''\\n        #visualize_loss(results, metric='wrmse').show()\\n        #print(results.to_string())\\n\\n        # enable early stopping\\n        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\\n            k += 1\\n        if k> e_patience:\\n            print('Early stopping')\\n            break\\n\\n    return results, model\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ],
      "source": [
        "\"\"\"\n",
        "def train_test(model, model_params, learning_rate=0.01, e_patience = 10, min_acc= 0.05, n_epochs=500):\n",
        "    t0 = time.time()\n",
        "\n",
        "    model = model(**model_params) # Define the model\n",
        "\n",
        "    # Due to lazy initialization, we need to run one model step so the number\n",
        "    # of parameters can be inferred:\n",
        "    with torch.no_grad():\n",
        "        model.encoder(train_data.x_dict, train_data.edge_index_dict) # Run once with torch.no_grad() to get parameter for optimizer below\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "    k=0\n",
        "    loss, train_rmse, val_rmse, test_rmse = [], [], [], []\n",
        "    train_wrmse, val_wrmse, test_wrmse = [], [], []\n",
        "    for epoch in tqdm(range(n_epochs)):\n",
        "        # Call train fuction here >> return loss\n",
        "        loss += [train(train_data, model, optimizer, loss=weighted_mse_loss)]\n",
        "        \n",
        "        # Call test function here >> return RMSE loss\n",
        "        train_wrmse += [test(train_data, model, metric=weighted_mse_loss)]\n",
        "        train_rmse += [test(train_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        val_wrmse += [test(val_data, model, metric=weighted_mse_loss)]\n",
        "        val_rmse += [test(val_data, model, metric=F.mse_loss)]\n",
        "        \n",
        "        test_wrmse += [test(test_data, model, metric=weighted_mse_loss)]\n",
        "        test_rmse += [test(test_data, model, metric=F.mse_loss)]\n",
        "\n",
        "        if epoch+1 %10==0:\n",
        "            print(f'Epoch: {epoch+1:03d}, Loss: {loss[-1]:.4f}, Train: {train_rmse[-1]:.4f}, '\n",
        "                  f'Val: {val_rmse[-1]:.4f}, Test: {test_rmse[-1]:.4f}')\n",
        "\n",
        "        results = pd.DataFrame({\n",
        "            'loss': loss,\n",
        "            'train_rmse': train_rmse, 'val_rmse': val_rmse, 'test_rmse': test_rmse,\n",
        "            'train_wrmse': train_wrmse, 'val_wrmse': val_wrmse, 'test_wrmse': test_wrmse,\n",
        "            'time':(time.time()-t0)/60\n",
        "        })\n",
        "        \n",
        "        ## Debugging\n",
        "        #clear_output()\n",
        "        '''\n",
        "        print('\\nloss: ', loss, \n",
        "              '\\ntrain_rmse: ', train_rmse, \n",
        "              '\\nval_rmse: ', val_rmse, \n",
        "              '\\ntest_rmse: ', test_rmse,\n",
        "              '\\ntrain_wrmse: ', train_wrmse, \n",
        "              '\\nval_wrmse: ', val_wrmse, \n",
        "              '\\ntest_wrmse: ', test_wrmse,\n",
        "              '\\ntime: ', (time.time()-t0)/60)\n",
        "        '''\n",
        "        #visualize_loss(results, metric='wrmse').show()\n",
        "        #print(results.to_string())\n",
        "\n",
        "        # enable early stopping\n",
        "        if (epoch > 1) and abs(loss[-1]/loss[-2]-1) < min_acc :\n",
        "            k += 1\n",
        "        if k> e_patience:\n",
        "            print('Early stopping')\n",
        "            break\n",
        "\n",
        "    return results, model\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8edkAihHAmP3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4714c0bc-bf46-4c2d-e609-721a7d2d7036"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\ndef visualize_loss(results, metric=\\'rmse\\'):\\n    fig = go.Figure()\\n\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'train_\\'+metric], name = \\'train_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'val_\\'+metric], name = \\'val_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'test_\\'+metric], name = \\'test_\\'+metric))\\n    fig.add_trace(go.Scatter(x=results.index, y=results[\\'loss\\'], name = \\'loss\\'))\\n\\n    fig.update_yaxes(title_text=metric.upper())\\n    fig.update_xaxes(title_text=\"Epoch\")\\n\\n    return fig\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ],
      "source": [
        "'''\n",
        "def visualize_loss(results, metric='rmse'):\n",
        "    fig = go.Figure()\n",
        "\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['train_'+metric], name = 'train_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['val_'+metric], name = 'val_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['test_'+metric], name = 'test_'+metric))\n",
        "    fig.add_trace(go.Scatter(x=results.index, y=results['loss'], name = 'loss'))\n",
        "\n",
        "    fig.update_yaxes(title_text=metric.upper())\n",
        "    fig.update_xaxes(title_text=\"Epoch\")\n",
        "\n",
        "    return fig\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQElhxOkAn_q",
        "outputId": "0bb8f0e3-5239-46da-d1ae-74778c8d6f6e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nN_EPOCHS = 300\\nE_PATIENCE = 50\\nLEARNING_RATE = 0.01\\n\\nmodel_params = {\"hidden_channels\":32, \\'conv\\':SAGEConv}\\n\\nresults, trained_model = train_test(\\n    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "'''\n",
        "N_EPOCHS = 300\n",
        "E_PATIENCE = 50\n",
        "LEARNING_RATE = 0.01\n",
        "\n",
        "model_params = {\"hidden_channels\":32, 'conv':SAGEConv}\n",
        "\n",
        "results, trained_model = train_test(\n",
        "    Model, model_params, learning_rate=LEARNING_RATE, e_patience = E_PATIENCE, n_epochs=N_EPOCHS)\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j58QMqIdUcfc"
      },
      "outputs": [],
      "source": [
        "#visualize_loss(results, metric='wrmse')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUHSNzLmBEYx"
      },
      "outputs": [],
      "source": [
        "#trained_model.encoder(test_data.x_dict, test_data.edge_index_dict)['session']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtRs2Bw7kfOP"
      },
      "outputs": [],
      "source": [
        "#trained_model.state_dict()['encoder.linear2.session.weight']"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8HKBFpzXHtgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Recommendation"
      ],
      "metadata": {
        "id": "aED_TAobTF6d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "@torch.no_grad()\n",
        "def recommendation(user_id, model, x_dict, edge_index_dict):\n",
        "  # Get model decoder\n",
        "  #model = Model(**model_params)\n",
        "  with torch.no_grad():\n",
        "    encoder = model.encoder(data.x_dict, data.edge_index_dict)\n",
        "\n",
        "  # Get node representations for users and movies\n",
        "  user_representations = encoder['session']\n",
        "  movie_representations = encoder['aid']\n",
        "\n",
        "  # Compute the dot product between user and movie representations to get edge weights\n",
        "  edge_weights = user_representations.mm(movie_representations.T)\n",
        "\n",
        "  # Make predictions for each user by taking the top k largest edge weights\n",
        "  k = 20  # number of recommendations to make\n",
        "  _, top_k_indices = edge_weights.topk(k, dim=1)\n",
        "  recommendations = top_k_indices.numpy()\n",
        "\n",
        "  # Print recommendations for the first user\n",
        "  print(f'Recommendations for user {user_id}: {recommendations[user_id]}')\n",
        "'''"
      ],
      "metadata": {
        "id": "9IbcT22JTIFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 1\n",
        "#recommendation(session, model, Rtest_data.x_dict, Rtest_data.edge_index_dict)"
      ],
      "metadata": {
        "id": "WP1SufyhTURW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 2\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "VFmAIGENUV9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#session = 999\n",
        "#recommendation(session, model, data.x_dict, data.edge_index_dict)"
      ],
      "metadata": {
        "id": "4H4tCDOyUcVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Submission"
      ],
      "metadata": {
        "id": "uZw_TNkMQRaq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Submission File\n",
        "For each `session` id and `type` combination in the test set, you must predict the `aid` values in the `label` column, which is space delimited. You can predict up to 20 `aid` values per row. The file should contain a header and have the following format:\n",
        "\n",
        "```\n",
        "session_type,labels\n",
        "12906577_clicks,135193 129431 119318 ...\n",
        "12906577_carts,135193 129431 119318 ...\n",
        "12906577_orders,135193 129431 119318 ...\n",
        "12906578_clicks, 135193 129431 119318 ...\n",
        "etc.\n",
        "```"
      ],
      "metadata": {
        "id": "DFOSPOfhOjYr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BWyo1qVmOi8E"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "FriR71pK-hxH",
        "pqgOrM6ak915",
        "fUkcZdZr8seK",
        "VKqQxQA0-X44",
        "XHNbZyHebUPV"
      ],
      "authorship_tag": "ABX9TyPV7Iq1KtH4U9j79EoSwfhU",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}